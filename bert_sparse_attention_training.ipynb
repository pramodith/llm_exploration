{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pramodith/llm_exploration/blob/bert_sparse_attention_training/bert_sparse_attention_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWhWL9msORXO"
      },
      "source": [
        "# Exploring the affects of custom Sparse Attention\n",
        "In our prior notebook, we found that both encoder-only and decoder-only models offload a significant portion of their attention scores to **sink tokens**. We identified that these sink tokens tend to be either special tokens like **[CLS], [SEP]** or tokens corresponding to **punctuations**. The consistence display of this phenomenon across model architectures and inputs makes one question the relevance of dense self-attention.\n",
        "\n",
        "In this notebook we'll explore the performance of BERT by creating custom attention masks, which will be sparse in nature. We'll create a unique mask per each token, where all tokens attend to special tokens and the k tokens in their neighborhood. When visualized the tokens along a diagonal of size 2*k+1 and the first anad last tokens (in the case of BERT) being attended to. We'll also explore the effects of allowing dense attention in some layers and sparse attention in the rest.\n",
        "\n",
        "We'll assess the downstream performance of the models that leverage this type of custom attention mask on some commonly used datasets for benchmarking like [TBD]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBBUafqnJPeP",
        "outputId": "bf5d0492-093a-4357-9b0a-1ba2f39d0986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Collecting overrides\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: overrides\n",
            "Successfully installed overrides-7.4.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets\n",
        "%pip install accelerate -U\n",
        "%pip install scikit-learn\n",
        "%pip install overrides\n",
        "%pip install evaluate\n",
        "%pip install matplotlib\n",
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "53fY5yW9JNUS"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "from functools import partial\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset, load_metric, load_from_disk, Dataset, Metric\n",
        "from transformers import TrainingArguments, Trainer,logging\n",
        "from evaluate import load\n",
        "import torch\n",
        "\n",
        "from transformers import BertModel, BertForSequenceClassification, BertForMaskedLM\n",
        "from transformers.data.data_collator import _torch_collate_batch\n",
        "from transformers.models.bert.modeling_bert import BertEncoder, logger\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, BaseModelOutputWithPoolingAndCrossAttentions\n",
        "from transformers.modeling_utils import ModuleUtilsMixin, warnings\n",
        "from typing import Any, Dict, Optional, Tuple, Union, List, Mapping\n",
        "from overrides import overrides\n",
        "from torch import Tensor\n",
        "from torch.nn.functional import pad\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "H_MITsQuJNUU"
      },
      "outputs": [],
      "source": [
        "# Defining the model, tokenizer and dataset\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "sample_text = \"Every night I lie in bed.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOC7C2dORXR"
      },
      "source": [
        "### Get Dataset Splits and Metrics to Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ihbuJxkbJNUV"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dataset_name: str, subset_name: Optional[str]) -> Tuple[Dataset, Dataset, Dataset, Metric]:\n",
        "    \"\"\"\n",
        "    This function loads the dataset and metric for the given task name.\n",
        "    It also splits the dataset into train, dev and test sets.\n",
        "\n",
        "    Args:\n",
        "        glue_task_name (str): The name of the task to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Dataset, Dataset, Dataset, int]: The train, dev and test datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the dataset and metric\n",
        "    dataset = load_dataset(dataset_name, subset_name)\n",
        "    # Split the dataset\n",
        "    train_dataset = dataset[\"train\"]\n",
        "    if \"validation\" not in dataset or \"test\" not in dataset:\n",
        "        split = train_dataset.train_test_split(test_size=0.1)\n",
        "        if \"validation\" not in dataset:\n",
        "            dev_dataset = split[\"test\"]\n",
        "            test_dataset = dataset[\"test\"]\n",
        "        elif \"test\" not in dataset:\n",
        "            dev_dataset = dataset[\"validation\"]\n",
        "            test_dataset = split[\"test\"]\n",
        "    else:\n",
        "        print(f\"{dataset_name} has already been split into train, dev and test sets.\")\n",
        "        dev_dataset = dataset['validation']\n",
        "        test_dataset = dataset['test']\n",
        "\n",
        "    # Print a description of the dataset\n",
        "    print(\"Dataset Description: \", train_dataset.description)\n",
        "\n",
        "    # Truncate the dataset if it is too large\n",
        "    if train_dataset.num_rows > 30000:\n",
        "        train_dataset = train_dataset.select(range(30000))\n",
        "\n",
        "    # Print the label space\n",
        "    print(\"Label Space: \", train_dataset.features[\"label\"].names)\n",
        "    num_labels = len(train_dataset.features[\"label\"].names)\n",
        "    return train_dataset, dev_dataset, test_dataset, num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT26JWyDJNUW",
        "outputId": "81b95200-9121-40f2-c14c-59197bb571a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dair-ai/emotion has already been split into train, dev and test sets.\n",
            "Dataset Description:  Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.\n",
            "\n",
            "Label Space:  ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
            "Dataset Description:  AG is a collection of more than 1 million news articles. News articles have been\n",
            "gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of\n",
            "activity. ComeToMyHead is an academic news search engine which has been running\n",
            "since July, 2004. The dataset is provided by the academic comunity for research\n",
            "purposes in data mining (clustering, classification, etc), information retrieval\n",
            "(ranking, search, etc), xml, data compression, data streaming, and any other\n",
            "non-commercial activity. For more information, please refer to the link\n",
            "http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\n",
            "\n",
            "The AG's news topic classification dataset is constructed by Xiang Zhang\n",
            "(xiang.zhang@nyu.edu) from the dataset above. It is used as a text\n",
            "classification benchmark in the following paper: Xiang Zhang, Junbo Zhao, Yann\n",
            "LeCun. Character-level Convolutional Networks for Text Classification. Advances\n",
            "in Neural Information Processing Systems 28 (NIPS 2015).\n",
            "\n",
            "Label Space:  ['World', 'Sports', 'Business', 'Sci/Tech']\n",
            "tweet_eval has already been split into train, dev and test sets.\n",
            "Dataset Description:  TweetEval consists of seven heterogenous tasks in Twitter, all framed as multi-class tweet classification. All tasks have been unified into the same benchmark, with each dataset presented in the same format and with fixed training, validation and test splits.\n",
            "\n",
            "Label Space:  ['non-offensive', 'offensive']\n"
          ]
        }
      ],
      "source": [
        "metrics = [load('accuracy'), load(\"f1\"), load(\"precision\"), load(\"recall\")]\n",
        "dataset_names = [(\"dair-ai/emotion\",\"\"),(\"ag_news\",\"\"),(\"tweet_eval\",\"offensive\")]\n",
        "train_datasets, dev_datasets, test_datasets, num_labels, train_datasets_size = [], [], [], [], []\n",
        "for dataset_name, subset_name in dataset_names:\n",
        "    train_dataset, dev_dataset, test_dataset, num_label = get_dataset(dataset_name, subset_name)\n",
        "    train_datasets.append(train_dataset)\n",
        "    dev_datasets.append(dev_dataset)\n",
        "    test_datasets.append(test_dataset)\n",
        "    num_labels.append(num_label)\n",
        "    train_datasets_size.append(train_dataset.num_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "D8BS7cfJ9UNx"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred: Tuple) -> Dict:\n",
        "    \"\"\"\n",
        "    This function computes the metrics for the given task and is used by the Trainer class for evaluation.\n",
        "    \"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "      if metric.name != \"accuracy\":\n",
        "        results.update(metric.compute(predictions=predictions, references=labels, average=\"macro\"))\n",
        "      else:\n",
        "        results.update(metric.compute(predictions=predictions, references=labels))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDU7zJb4ORXS"
      },
      "source": [
        "## Create Custom Bert Model to support 4-D attention masks\n",
        "HF doesn't support custom layerwise attention masks. By default it assumes that all layers use the same attention mask. However,we want to be able to experiment with using sparse attention in all the layers but also a hybrid of dense and sparse self attention split across layers.\n",
        "\n",
        "In order to support this functionality we'll need to override some functions and create Custom Bert Models.\n",
        "\n",
        "First we'll override the `forward` function of `BertEncoder` to accept 5-d attention masks. The 5-d mask corresponds to (Layer, Batch Size, Attention Head, Sequence length (from token), Sequence length (to token)). We assume that all attention heads share the same attention mask in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jk-pBQF5UBlI"
      },
      "outputs": [],
      "source": [
        "class CustomBertEncoder(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "    @overrides\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = True,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
        "\n",
        "        if self.gradient_checkpointing and self.training:\n",
        "            if use_cache:\n",
        "                logger.warning_once(\n",
        "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                )\n",
        "                use_cache = False\n",
        "\n",
        "        attention_mask_is_layerwise = False\n",
        "\n",
        "        # Code added here\n",
        "        if attention_mask.dim() == 5:\n",
        "            attention_mask_is_layerwise = True\n",
        "\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            # Code added here\n",
        "            if attention_mask_is_layerwise:\n",
        "               attention_mask_to_use = attention_mask[i]\n",
        "            else:\n",
        "                attention_mask_to_use = attention_mask\n",
        "\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                layer_outputs = self._gradient_checkpointing_func(\n",
        "                    layer_module.__call__,\n",
        "                    hidden_states,\n",
        "                    attention_mask_to_use,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states,\n",
        "                    attention_mask_to_use,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[-1],)\n",
        "            if output_attentions:\n",
        "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
        "                if self.config.add_cross_attention:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    next_decoder_cache,\n",
        "                    all_hidden_states,\n",
        "                    all_self_attentions,\n",
        "                    all_cross_attentions,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_decoder_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DwTI4fUORXS"
      },
      "source": [
        "Next we'll override `get_extended_attention_mask` of the `BertModel` class to create a new dimension expanding 4-d attention masks to 5-d attention masks. The expanded dimension corresponds to attention heads as mentioned above since we assume that all attention heads use the same mask we just need to add a new dimension to the mask tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5npfO9CfORXS"
      },
      "outputs": [],
      "source": [
        "class CustomBertModel(BertModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.encoder = CustomBertEncoder(config)\n",
        "\n",
        "    @overrides\n",
        "    def get_extended_attention_mask(\n",
        "        self, attention_mask: Tensor, input_shape: Tuple[int], device: torch.device = None, dtype: torch.float = None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            `torch.Tensor` The extended attention mask, with a the same dtype as `attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        if dtype is None:\n",
        "            dtype = self.dtype\n",
        "\n",
        "        if not (attention_mask.dim() == 2 and self.config.is_decoder):\n",
        "            # show warning only if it won't be shown in `create_extended_attention_mask_for_decoder`\n",
        "            if device is not None:\n",
        "                warnings.warn(\n",
        "                    \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
        "                )\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        # Code added here\n",
        "        if attention_mask.dim() == 4:\n",
        "            extended_attention_mask = attention_mask[:, :, None, :, :]\n",
        "        elif attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                extended_attention_mask = ModuleUtilsMixin.create_extended_attention_mask_for_decoder(\n",
        "                    input_shape, attention_mask, device\n",
        "                )\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Wrong shape for input_ids (shape {input_shape}) or attention_mask (shape {attention_mask.shape})\"\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and the dtype's smallest value for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * torch.finfo(dtype).min\n",
        "        return extended_attention_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc-217gbORXT"
      },
      "source": [
        "#### Create a custom bert model for sequence classification that uses the custom bert encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U37R2yvDORXT"
      },
      "outputs": [],
      "source": [
        "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = CustomBertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "o6mABgKyVD-3"
      },
      "outputs": [],
      "source": [
        "def torch_mask_tokens(tokenizer: AutoTokenizer, mlm_probability: float, inputs: Any, special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any]:\n",
        "    \"\"\"\n",
        "    Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    labels = inputs.clone()\n",
        "    # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    if special_tokens_mask is None:\n",
        "        special_tokens_mask = [\n",
        "            tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "        ]\n",
        "        special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
        "    else:\n",
        "        special_tokens_mask = special_tokens_mask.bool()\n",
        "\n",
        "    probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9q8vDZFORXT"
      },
      "source": [
        "The `custom_tokenize` function tokenizes a given text and creates a custom attention mask for the BERT model.\n",
        "\n",
        "The function takes four arguments: a tokenizer, a text string, a distance integer (default is 2), and a batch_mode boolean (default is False).\n",
        "\n",
        "The function tokenizes the text and creates an attention mask with ones on the main diagonal. It then updates the attention mask based on the specified neighborhood distance. The function ensures that the first and last tokens (usually the CLS and SEP tokens in BERT) always attend to all other tokens and are attended to by all other tokens.\n",
        "\n",
        "If `batch_mode` is `True`, the function adds an extra dimension to the attention mask, input ids, and token type ids to accommodate batch processing.\n",
        "\n",
        "The function returns a dictionary containing the tokenized input ids, token type ids, and the custom attention mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qPhmj3Zy9UNy"
      },
      "outputs": [],
      "source": [
        "def custom_tokenize(tokenizer: AutoTokenizer, text: str, distance:int=2, batch_mode=False, special_tokens_attend_to_all: bool = True) -> Dict:\n",
        "    \"\"\"\n",
        "    This function tokenizes the given text and returns the tokenized inputs along with the attention mask.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (AutoTokenizer): The tokenizer to be used for tokenization.\n",
        "        text (str): The text to be tokenized.\n",
        "        distance (int, optional): The number of neigbhoring tokens that should be attended to.\n",
        "        batch_mode (bool, optional): If we need to add an extra dimension for batch processing.\n",
        "\n",
        "    Returns:\n",
        "        Dict: The tokenized inputs along with the attention mask.\n",
        "    \"\"\"\n",
        "    # Tokenize the texts\n",
        "    result = tokenizer(text, truncation=True, padding=False)\n",
        "    # Create attention mask with ones on the main diagonal\n",
        "    attention_mask = torch.eye(len(result[\"input_ids\"]), dtype=torch.long)\n",
        "    # Update attention mask for the specified neighborhood distance\n",
        "    attention_mask[abs(torch.arange(len(attention_mask))[:, None] - torch.arange(len(attention_mask))) <= distance] = 1\n",
        "\n",
        "    if special_tokens_attend_to_all:\n",
        "      # Set the first row to 1 corresponding to the CLS token\n",
        "      attention_mask[0, :] = 1\n",
        "      # Always attend to CLS\n",
        "      attention_mask[:, 0] = 1\n",
        "      # Set the last row to 1 corresponding to the SEP token\n",
        "      attention_mask[-1, :] = 1\n",
        "      # Always attend to SEP\n",
        "      attention_mask[:, -1] = 1\n",
        "      # Add the attention mask to the result\n",
        "\n",
        "    if batch_mode:\n",
        "      result[\"attention_mask\"] = torch.LongTensor(attention_mask.unsqueeze(0))\n",
        "      result[\"input_ids\"] = torch.LongTensor(result[\"input_ids\"]).unsqueeze(0)\n",
        "      result[\"token_type_ids\"] = torch.LongTensor(result[\"token_type_ids\"]).unsqueeze(0)\n",
        "    else:\n",
        "      result[\"attention_mask\"] = torch.LongTensor(attention_mask)\n",
        "      result[\"input_ids\"] = torch.LongTensor(result[\"input_ids\"])\n",
        "      result[\"token_type_ids\"] = torch.LongTensor(result[\"token_type_ids\"])\n",
        "    # Map the labels to the tokenized inputs\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whRhmsDrORXU"
      },
      "source": [
        "Let's make sure our implementation is right by visualizing a heatmap of our attention scores. We should expect to see a sliding window of attention along the diagonal while the **[CLS]** and **[SEP]** tokens are allowed to attend to all tokens and all tokens are allowed to attend to the **[CLS]** and **[SEP]** tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOdvYb8DdHZN",
        "outputId": "ae6bdb12-3742-4962-cce1-18f268f33a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "custom_model = CustomBertForSequenceClassification.from_pretrained(model_name)\n",
        "#inputs = custom_tokenize(tokenizer, sample_text, distance=1, batch_mode=True, special_tokens_attend_to_all=False)\n",
        "inputs = custom_tokenize(tokenizer, sample_text, distance=1, batch_mode=True)\n",
        "output = custom_model(**inputs, output_attentions=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "VDu0KYhMORXU",
        "outputId": "e3c8000d-f988-4846-cd8a-469728c1d258"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get the attention scores for Layer 0, Batch 0, Head 0\n",
        "attention_scores = output.attentions[0][0,0].detach().numpy()\n",
        "\n",
        "# Get the tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(attention_scores, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar(label='Attention Scores')\n",
        "plt.title('Attention Scores Heatmap')\n",
        "plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
        "plt.yticks(range(len(tokens)), tokens)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5VgULswaXY6",
        "outputId": "f7851013-269a-4a85-de08-9cac399cf1a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "inputs[\"attention_mask\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI6jDPGZORXU"
      },
      "source": [
        "Great! That's working, now let's make sure that masking also works when we send in a 4-d tensor. Where dimension 0 is the layer number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "-0xre52RORXU"
      },
      "outputs": [],
      "source": [
        "inputs[\"attention_mask\"] = inputs[\"attention_mask\"].unsqueeze(0).repeat(12,1,1,1)\n",
        "output_layerwise_mask = custom_model(**inputs, output_attentions=True)\n",
        "assert torch.allclose(output.attentions[0], output_layerwise_mask.attentions[0]), \"Attention scores have to be the same for the same attention mask even if it is repeated layerwise\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIdqwo3JORXU"
      },
      "source": [
        "## Creating Layerwise Attention Masks\n",
        "The `get_layerwise_attention_mask` function is designed to create a layer-wise attention mask from a given input attention mask. This function is particularly useful when working with transformer models like BERT, where different layers might require different attention masks.\n",
        "\n",
        "Here are the parameters of the function:\n",
        "\n",
        "- `attention_mask` (Tensor): This is the input attention mask that you want to convert into a layer-wise attention mask. It should be a tensor.\n",
        "\n",
        "- `pad_token_pos` (int): This is the position of the padding token in the attention mask. The function uses this to set the range of full attention.\n",
        "\n",
        "- `total_num_layers` (int, optional): This is the total number of layers in the model. By default, it's set to 12, which is the number of layers in BERT-base models.\n",
        "\n",
        "- `full_attention_layers` (list, optional): This is a list of layer numbers that should have full attention. By default, it's an empty list, meaning no layers have full attention.\n",
        "\n",
        "The function returns a tensor which is the layer-wise attention mask. If `full_attention_layers` is not empty, the function repeats the attention mask for each layer and sets full attention for the specified layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "zFflnnXJu_7B"
      },
      "outputs": [],
      "source": [
        "def get_layerwise_attention_mask(attention_mask: Tensor, pad_token_pos:int, total_num_layers:int=12, full_attention_layers=[]):\n",
        "  \"\"\"\n",
        "  Returns a layer-wise attention mask for a given input attention mask.\n",
        "\n",
        "  Args:\n",
        "    attention_mask (Tensor): The input attention mask.\n",
        "    pad_token_pos (int): The position of the padding token in the attention mask.\n",
        "    total_num_layers (int, optional): The total number of layers in the model. Defaults to 12.\n",
        "    full_attention_layers (list, optional): A list of layer numbers that should have full attention. Defaults to [].\n",
        "\n",
        "  Returns:\n",
        "    Tensor: The layer-wise attention mask.\n",
        "  \"\"\"\n",
        "  attention_mask = attention_mask.unsqueeze(0)\n",
        "  if full_attention_layers:\n",
        "    attention_mask = attention_mask.repeat(total_num_layers, 1, 1, 1)\n",
        "    for layer_num in full_attention_layers:\n",
        "      attention_mask[layer_num, :, : pad_token_pos, : pad_token_pos] = 1\n",
        "  return attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIw-_d_PORXU"
      },
      "source": [
        "Let's make sure that this is working as desired.\n",
        "This test case is validating the `get_layerwise_attention_mask` function. It checks three things:\n",
        "\n",
        "1. The function returns an attention mask of the correct shape (12, 1, 4, 4).\n",
        "2. The attention mask at layer 0 is the same as the input mask (all zeros).\n",
        "3. The attention mask at layer 2 is all ones, indicating full attention.\n",
        "\n",
        "If any of these conditions are not met, the test case fails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "0M2fGF1nv4Lr"
      },
      "outputs": [],
      "source": [
        "dummy_attn_mask = torch.zeros(1, 4, 4)\n",
        "layerwise_attn_mask = get_layerwise_attention_mask(dummy_attn_mask, 4, full_attention_layers=[2])\n",
        "assert layerwise_attn_mask.shape == (12, 1, 4, 4), f\"{layerwise_attn_mask.shape} is the wrong shape\"\n",
        "assert torch.allclose(layerwise_attn_mask[0], dummy_attn_mask), \"Masks at layer 0 should all be 0s\"\n",
        "assert torch.allclose(layerwise_attn_mask[2], torch.ones(1,4,4)), \"Masks at layer 1 should all be 1s\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyRgM3FjORXV"
      },
      "source": [
        "## Padding custom attention Masks\n",
        "\n",
        "The `custom_collate` function is a utility function designed to process a batch of data for training a transformer model like BERT. It performs several key tasks:\n",
        "\n",
        "1. **Padding**: It pads all sequences in the batch to the same length, using the provided `pad_token_id`.\n",
        "\n",
        "2. **Layer-wise Attention Mask**: It creates a layer-wise attention mask for each sequence in the batch. This is useful when different layers of the transformer model require different attention masks.\n",
        "\n",
        "3. **Masked Language Modeling**: If the `is_mlm` flag is set to `True`, it applies masked language modeling to the input sequences. This involves randomly masking some of the tokens in each sequence, with the goal of predicting the original token from its context. The probability of masking a token is controlled by the `mlm_probability` parameter.\n",
        "\n",
        "The function returns a dictionary containing the padded 'input_ids', the layer-wise 'attention_mask', 'token_type_ids', and 'labels' (if present in the batch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Zh1P5ttKfwgy"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch:List, pad_token_id:int, full_attention_layers:List=[], mlm_probability:float=0.15, is_mlm:bool=False):\n",
        "  \"\"\"\n",
        "  Custom collate function for DataLoader that pads sequences and creates layer-wise attention masks.\n",
        "\n",
        "  Args:\n",
        "    batch (list): List of dictionaries containing 'input_ids', 'attention_mask', 'token_type_ids', and optionally 'label'.\n",
        "    pad_token_id (int): The ID of the padding token.\n",
        "    full_attention_layers (list, optional): List of layers that should have full attention. Defaults to [].\n",
        "    mlm_probability (float, optional): Probability of masking a token for masked language modeling. Defaults to 0.15.\n",
        "    is_mlm (bool, optional): Whether to apply masked language modeling. Defaults to False.\n",
        "\n",
        "  Returns:\n",
        "    dict: A dictionary containing 'input_ids', 'attention_mask', 'token_type_ids', and 'labels' (if present in batch).\n",
        "  \"\"\"\n",
        "  input_ids = [torch.LongTensor(batch[i][\"input_ids\"]) for i in range(len(batch))]\n",
        "  attention_mask = [torch.LongTensor(batch[i][\"attention_mask\"]) for i in range(len(batch))]\n",
        "  token_type_ids = [torch.LongTensor(batch[i][\"token_type_ids\"]) for i in range(len(batch))]\n",
        "  if \"labels\" in batch[0]:\n",
        "    label = torch.LongTensor([batch[i][\"labels\"] for i in range(len(batch))])\n",
        "  #idx = [batch[i][\"idx\"] for i in range(len(batch))]\n",
        "  max_len = max([len(inp) for inp in input_ids])\n",
        "  padding_sizes = [max_len - len(inp) for inp in input_ids]\n",
        "  input_ids = pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n",
        "  token_type_ids = pad_sequence(token_type_ids, batch_first=True)\n",
        "  attention_mask = [get_layerwise_attention_mask(pad(attention_mask[i], (0, padding_sizes[i], 0, padding_sizes[i]), value=0), padding_sizes[i], full_attention_layers=full_attention_layers).squeeze(1) for i in range(len(batch))]\n",
        "  attention_mask = torch.stack(attention_mask)\n",
        "  if full_attention_layers:\n",
        "    attention_mask = attention_mask.permute(1,0,2,3)\n",
        "  else:\n",
        "    attention_mask = attention_mask.squeeze(1)\n",
        "\n",
        "  if is_mlm:\n",
        "    input_ids, label = torch_mask_tokens(tokenizer, mlm_probability, input_ids)\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_mask,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"labels\": label,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPjtSFNUVD-5",
        "outputId": "eb5e0025-d001-497e-fa58-0785abc83445"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[1, 2, 3, 4, 0],\n",
              "         [1, 2, 3, 4, 5]]),\n",
              " 'attention_mask': tensor([[[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0]]),\n",
              " 'labels': tensor([[-100, -100, -100, -100, -100],\n",
              "         [-100, -100, -100, -100, -100]])}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "custom_collate([{\"input_ids\":[1,2,3,4], \"attention_mask\":[[1,1,1,0],[1,1,1,0],[1,1,1,0],[1,1,1,0]], \"token_type_ids\":[0,0,0,0], \"label\":1}, {\"input_ids\":[1,2,3,4,5], \"attention_mask\":[[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0]], \"token_type_ids\":[0,0,0,0,0], \"label\":1}], tokenizer.pad_token_id, full_attention_layers=[2,4], is_mlm=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_2ZoHk5RJ9P",
        "outputId": "a8bebd12-41c9-497e-852f-09361289f413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 11916\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpL48wHbORXV"
      },
      "source": [
        "We need to encode the datasets for dense and sparse attention differently since we need to create custom attention masks for the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "gYSzPIq4JNUW"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset, tokenizer, mode=\"sparse\", is_mlm:bool = False,special_tokens_attend_to_all=True):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mode = mode\n",
        "        self.is_mlm = is_mlm\n",
        "        self.special_tokens_attend_to_all = special_tokens_attend_to_all\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      if self.mode == \"sparse\":\n",
        "        inputs = custom_tokenize(self.tokenizer, self.dataset[idx][\"text\"], special_tokens_attend_to_all=self.special_tokens_attend_to_all)\n",
        "      else:\n",
        "        inputs = tokenizer(self.dataset[idx][\"text\"], return_tensors=\"pt\", truncation=True)\n",
        "        inputs = {k:v.squeeze(0) for k,v in inputs.items()}\n",
        "      if not self.is_mlm:\n",
        "        inputs[\"labels\"] = self.dataset[idx][\"label\"]\n",
        "      return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "u36vJQsnQyR9"
      },
      "outputs": [],
      "source": [
        "train_datasets_dense_attention, dev_datasets_dense_attention, test_datasets_dense_attention = [], [], []\n",
        "train_datasets_sparse_attention, dev_datasets_sparse_attention, test_datasets_sparse_attention = [], [], []\n",
        "train_datasets_sparse_no_special_attention, dev_datasets_sparse_no_special_attention, test_datasets_sparse_no_special_attention = [], [], []\n",
        "\n",
        "for i in range(len(train_datasets)):\n",
        "    # Encode the datasets that'll leverage dense attention\n",
        "    train_datasets_dense_attention.append(CustomDataset(train_datasets[i], tokenizer, mode=\"dense\"))\n",
        "    dev_datasets_dense_attention.append(CustomDataset(dev_datasets[i], tokenizer, mode=\"dense\"))\n",
        "    test_datasets_dense_attention.append(CustomDataset(test_datasets[i], tokenizer, mode=\"dense\"))\n",
        "\n",
        "    # Encode the datasets that'll leverage sparse attention\n",
        "    train_datasets_sparse_attention.append(CustomDataset(train_datasets[i], tokenizer, mode=\"sparse\"))\n",
        "    dev_datasets_sparse_attention.append(CustomDataset(dev_datasets[i], tokenizer, mode=\"sparse\"))\n",
        "    test_datasets_sparse_attention.append(CustomDataset(test_datasets[i], tokenizer, mode=\"sparse\"))\n",
        "\n",
        "    # Encode the datasets that'll leverage sparse attention with no special treatment of special tokens\n",
        "    train_datasets_sparse_no_special_attention.append(CustomDataset(train_datasets[i], tokenizer, mode=\"sparse\", special_tokens_attend_to_all=False))\n",
        "    dev_datasets_sparse_no_special_attention.append(CustomDataset(dev_datasets[i], tokenizer, mode=\"sparse\", special_tokens_attend_to_all=False))\n",
        "    test_datasets_sparse_no_special_attention.append(CustomDataset(test_datasets[i], tokenizer, mode=\"sparse\", special_tokens_attend_to_all=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-g-7SVtSs7O",
        "outputId": "2515d803-53fd-4b48-d725-215c5c1d5ed0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101,  1045,  2134,  2102,  2514, 26608,   102]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 0, 0],\n",
              "        [0, 1, 1, 1, 1, 1, 0],\n",
              "        [0, 0, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 1, 1, 1]]), 'labels': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "train_datasets_sparse_no_special_attention[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAD5ncoLiw5q",
        "outputId": "187f592f-d211-41f8-978d-1075d1df8266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[16000, 30000, 11916]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "train_datasets_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trPzkAwFORXW"
      },
      "source": [
        "## Training the models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "FuAngW-DJNUW"
      },
      "outputs": [],
      "source": [
        "logging.set_verbosity_warning()\n",
        "\n",
        "def train_and_evaluate(\n",
        "    train_datasets: List[Dataset],\n",
        "    dev_datasets: List[Dataset],\n",
        "    test_datasets: List[Dataset],\n",
        "    tokenizer: AutoTokenizer,\n",
        "    train_batch_size:int = 64,\n",
        "    num_epochs:int = 5,\n",
        "    is_custom: bool = False,\n",
        "    full_attention_layers = [],\n",
        "    num_training_runs:int = 5,\n",
        "    pretrained_model_name: str = \"bert-base-uncased\",\n",
        ") -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Trains and evaluates a model on multiple datasets, multiple times with a distinct random seed per iteration.\n",
        "\n",
        "    Args:\n",
        "        pretrained_model_name (str): The name of the model to be loaded.\n",
        "        train_datasets (List[Dataset]): List of training datasets.\n",
        "        dev_datasets (List[Dataset]): List of development datasets for evaluation during training.\n",
        "        test_datasets (List[Dataset]): List of test datasets for final evaluation.\n",
        "        tokenizer (AutoTokenizer): The tokenizer to be used.\n",
        "        train_batch_size (int, optional): Batch size for training. Defaults to 64.\n",
        "        num_epochs (int, optional): Number of training epochs. Defaults to 5.\n",
        "        is_custom (bool, optional): Whether to use a custom model or not. Defaults to False.\n",
        "        full_attention_layers (List[int], optional): List of layers to apply full attention to in the custom model. Defaults to an empty list.\n",
        "        num_training_runs (int, optional): Number of times to train the model on each dataset. Defaults to 5.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, List[Dict]]: A dictionary where keys are dataset names and values are lists of dictionaries containing evaluation results for each run.\n",
        "    \"\"\"\n",
        "\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    # We'll train on all datasets\n",
        "    for i in range(len(train_datasets)):\n",
        "        total_num_steps = (num_epochs * train_datasets_size[i])//train_batch_size\n",
        "        # Define the training arguments\n",
        "        training_args = TrainingArguments(\n",
        "                output_dir='./results',          # output directory\n",
        "                num_train_epochs=5,            # total number of training steps\n",
        "                per_device_train_batch_size=train_batch_size,  # batch size per device during training\n",
        "                per_device_eval_batch_size=128,   # batch size for evaluation\n",
        "                warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "                weight_decay=0.01,               # strength of weight decay\n",
        "                logging_dir='./logs',            # directory for storing logs\n",
        "                fp16=True,\n",
        "                gradient_checkpointing=True,\n",
        "                evaluation_strategy=\"steps\",\n",
        "                eval_steps=total_num_steps//10,\n",
        "                load_best_model_at_end=True,\n",
        "                logging_steps=total_num_steps//10,\n",
        "                save_steps=total_num_steps//10,\n",
        "                use_cpu=False\n",
        "            )\n",
        "        print(f\"Training on {dataset_names[i][0]}\")\n",
        "        # We'll train a new model 5 times on each dataset with different random seeds\n",
        "        for j in range(num_training_runs):\n",
        "            training_args.seed = j\n",
        "            print(f\"Training for the {j}th run.\")\n",
        "            if is_custom:\n",
        "                model = CustomBertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_labels[i])\n",
        "                collator = partial(custom_collate, pad_token_id=tokenizer.pad_token_id, full_attention_layers=full_attention_layers)\n",
        "            else:\n",
        "                model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_labels[i])\n",
        "                collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "\n",
        "            # Initialize the trainer\n",
        "            trainer_dense_attention = Trainer(\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "                args=training_args,                  # training arguments, defined above\n",
        "                train_dataset=train_datasets[i],         # training dataset\n",
        "                eval_dataset=dev_datasets[i],       # evaluation dataset\n",
        "                data_collator=collator,\n",
        "                compute_metrics=compute_metrics\n",
        "        )\n",
        "            # Train the model\n",
        "            trainer_dense_attention.train()\n",
        "            # Evaluate the model on the test set\n",
        "            test_results = trainer_dense_attention.evaluate(test_datasets[i])\n",
        "            print(f\"Results on the test set are: {test_results}\")\n",
        "            results[dataset_names[i]].append(test_results)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOfTBCjKrQ_N"
      },
      "source": [
        "### Training the model using regular dense attention\n",
        "\n",
        "We'll train, evaluate and save the results of the best trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "4v4QFQumB6B-",
        "outputId": "a2934899-8678-4c00-d2fa-a336de5acc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on dair-ai/emotion\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  22/1250 00:02 < 02:25, 8.44 it/s, Epoch 0.08/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-0dcfe7a03233>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense_attention_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_datasets_dense_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_datasets_dense_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_datasets_dense_attention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-f1a96d532069>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(train_datasets, dev_datasets, test_datasets, tokenizer, train_batch_size, num_epochs, is_custom, full_attention_layers, num_training_runs, pretrained_model_name)\u001b[0m\n\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtrainer_dense_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;31m# Evaluate the model on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_dense_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2747\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2748\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2749\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2750\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m                 layer_outputs = self._gradient_checkpointing_func(\n\u001b[0m\u001b[1;32m    597\u001b[0m                     \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mdynamic_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/external_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34m\"use_reentrant=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             )\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         gen = _checkpoint_without_reentrant_generator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_SingleLevelFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    197\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2541\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m         )\n\u001b[0;32m-> 2543\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dense_attention_results = train_and_evaluate(train_datasets_dense_attention, dev_datasets_dense_attention, test_datasets_dense_attention, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx0QsLmJY6fg"
      },
      "outputs": [],
      "source": [
        "dense_attention_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iiTWqQlj1VeN"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "def save_results(path: str, results:Dict):\n",
        "  with open(path, 'wb') as f:\n",
        "      pickle.dump(results, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zykybsCQORXW"
      },
      "source": [
        "### Training the model using sparse attention in all layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p7kiaNeRV2Ze",
        "outputId": "53237d13-eb77-4351-c298-8fb2d226c13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on dair-ai/emotion\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:24, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.316100</td>\n",
              "      <td>0.478573</td>\n",
              "      <td>0.859500</td>\n",
              "      <td>0.823165</td>\n",
              "      <td>0.839344</td>\n",
              "      <td>0.814305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.343200</td>\n",
              "      <td>0.227005</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>0.894210</td>\n",
              "      <td>0.885930</td>\n",
              "      <td>0.905533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.189600</td>\n",
              "      <td>0.189075</td>\n",
              "      <td>0.926000</td>\n",
              "      <td>0.900229</td>\n",
              "      <td>0.897057</td>\n",
              "      <td>0.905971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.171100</td>\n",
              "      <td>0.165728</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.905831</td>\n",
              "      <td>0.916356</td>\n",
              "      <td>0.903124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>0.191389</td>\n",
              "      <td>0.925500</td>\n",
              "      <td>0.893942</td>\n",
              "      <td>0.912155</td>\n",
              "      <td>0.880118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.109100</td>\n",
              "      <td>0.170211</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.899587</td>\n",
              "      <td>0.913999</td>\n",
              "      <td>0.893470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.174093</td>\n",
              "      <td>0.927000</td>\n",
              "      <td>0.898711</td>\n",
              "      <td>0.891806</td>\n",
              "      <td>0.906950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.175920</td>\n",
              "      <td>0.935500</td>\n",
              "      <td>0.912322</td>\n",
              "      <td>0.921327</td>\n",
              "      <td>0.904079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>0.190522</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.908610</td>\n",
              "      <td>0.906691</td>\n",
              "      <td>0.910926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.051900</td>\n",
              "      <td>0.189504</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.913905</td>\n",
              "      <td>0.918875</td>\n",
              "      <td>0.909569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.17847631871700287, 'eval_accuracy': 0.922, 'eval_f1': 0.8743260612418546, 'eval_precision': 0.8938048600006353, 'eval_recall': 0.8719245203825721, 'eval_runtime': 1.8591, 'eval_samples_per_second': 1075.771, 'eval_steps_per_second': 8.606, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:32, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.378400</td>\n",
              "      <td>0.532986</td>\n",
              "      <td>0.847500</td>\n",
              "      <td>0.794956</td>\n",
              "      <td>0.818120</td>\n",
              "      <td>0.781382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>0.256838</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.886806</td>\n",
              "      <td>0.895560</td>\n",
              "      <td>0.883334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.191500</td>\n",
              "      <td>0.232863</td>\n",
              "      <td>0.919000</td>\n",
              "      <td>0.894265</td>\n",
              "      <td>0.900066</td>\n",
              "      <td>0.894777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.166653</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>0.893301</td>\n",
              "      <td>0.915068</td>\n",
              "      <td>0.876773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.119400</td>\n",
              "      <td>0.180736</td>\n",
              "      <td>0.923500</td>\n",
              "      <td>0.898120</td>\n",
              "      <td>0.888052</td>\n",
              "      <td>0.912917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.107600</td>\n",
              "      <td>0.170412</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.902053</td>\n",
              "      <td>0.904222</td>\n",
              "      <td>0.900453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.087100</td>\n",
              "      <td>0.180813</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.902720</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.903319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.169617</td>\n",
              "      <td>0.933000</td>\n",
              "      <td>0.906043</td>\n",
              "      <td>0.905221</td>\n",
              "      <td>0.907703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.057800</td>\n",
              "      <td>0.191846</td>\n",
              "      <td>0.929500</td>\n",
              "      <td>0.901041</td>\n",
              "      <td>0.904090</td>\n",
              "      <td>0.898461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.057900</td>\n",
              "      <td>0.191902</td>\n",
              "      <td>0.931000</td>\n",
              "      <td>0.903292</td>\n",
              "      <td>0.906170</td>\n",
              "      <td>0.901404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.17453917860984802, 'eval_accuracy': 0.9225, 'eval_f1': 0.8728442645045379, 'eval_precision': 0.9025337424594381, 'eval_recall': 0.8514768124550852, 'eval_runtime': 1.901, 'eval_samples_per_second': 1052.095, 'eval_steps_per_second': 8.417, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:31, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.307600</td>\n",
              "      <td>0.546856</td>\n",
              "      <td>0.836500</td>\n",
              "      <td>0.739879</td>\n",
              "      <td>0.823939</td>\n",
              "      <td>0.727104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.372600</td>\n",
              "      <td>0.253851</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>0.887530</td>\n",
              "      <td>0.890147</td>\n",
              "      <td>0.886573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.201800</td>\n",
              "      <td>0.233207</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.888587</td>\n",
              "      <td>0.888100</td>\n",
              "      <td>0.892822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.181800</td>\n",
              "      <td>0.179889</td>\n",
              "      <td>0.926500</td>\n",
              "      <td>0.898748</td>\n",
              "      <td>0.911778</td>\n",
              "      <td>0.893495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>0.181659</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.903063</td>\n",
              "      <td>0.908935</td>\n",
              "      <td>0.899454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.110200</td>\n",
              "      <td>0.174840</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.900787</td>\n",
              "      <td>0.926436</td>\n",
              "      <td>0.883052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.175095</td>\n",
              "      <td>0.927000</td>\n",
              "      <td>0.901305</td>\n",
              "      <td>0.901531</td>\n",
              "      <td>0.901635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.174300</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.908637</td>\n",
              "      <td>0.915559</td>\n",
              "      <td>0.904593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>0.188731</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>0.909603</td>\n",
              "      <td>0.917438</td>\n",
              "      <td>0.904053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.054600</td>\n",
              "      <td>0.192733</td>\n",
              "      <td>0.936500</td>\n",
              "      <td>0.914802</td>\n",
              "      <td>0.918294</td>\n",
              "      <td>0.911783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.1664198637008667, 'eval_accuracy': 0.923, 'eval_f1': 0.877071529534987, 'eval_precision': 0.8761924448686415, 'eval_recall': 0.8813261663971786, 'eval_runtime': 1.8488, 'eval_samples_per_second': 1081.755, 'eval_steps_per_second': 8.654, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.346500</td>\n",
              "      <td>0.682162</td>\n",
              "      <td>0.774000</td>\n",
              "      <td>0.546749</td>\n",
              "      <td>0.667144</td>\n",
              "      <td>0.580723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.401400</td>\n",
              "      <td>0.257728</td>\n",
              "      <td>0.910500</td>\n",
              "      <td>0.886176</td>\n",
              "      <td>0.900948</td>\n",
              "      <td>0.878872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.202200</td>\n",
              "      <td>0.209126</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>0.896978</td>\n",
              "      <td>0.890875</td>\n",
              "      <td>0.904994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.172100</td>\n",
              "      <td>0.162846</td>\n",
              "      <td>0.932500</td>\n",
              "      <td>0.907105</td>\n",
              "      <td>0.901808</td>\n",
              "      <td>0.914664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.118400</td>\n",
              "      <td>0.179907</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.904839</td>\n",
              "      <td>0.898270</td>\n",
              "      <td>0.914056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.180987</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.905268</td>\n",
              "      <td>0.918569</td>\n",
              "      <td>0.894170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.079600</td>\n",
              "      <td>0.173363</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.900840</td>\n",
              "      <td>0.902000</td>\n",
              "      <td>0.899775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.180374</td>\n",
              "      <td>0.927000</td>\n",
              "      <td>0.901104</td>\n",
              "      <td>0.902548</td>\n",
              "      <td>0.901719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.059100</td>\n",
              "      <td>0.193162</td>\n",
              "      <td>0.930500</td>\n",
              "      <td>0.903606</td>\n",
              "      <td>0.905249</td>\n",
              "      <td>0.902431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.055200</td>\n",
              "      <td>0.190799</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.911622</td>\n",
              "      <td>0.912374</td>\n",
              "      <td>0.911121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.17260678112506866, 'eval_accuracy': 0.924, 'eval_f1': 0.8835934417345165, 'eval_precision': 0.8791409231543019, 'eval_recall': 0.8969695161316765, 'eval_runtime': 1.7697, 'eval_samples_per_second': 1130.107, 'eval_steps_per_second': 9.041, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.276500</td>\n",
              "      <td>0.503447</td>\n",
              "      <td>0.841000</td>\n",
              "      <td>0.770779</td>\n",
              "      <td>0.858550</td>\n",
              "      <td>0.739927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.344100</td>\n",
              "      <td>0.230967</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.902946</td>\n",
              "      <td>0.901976</td>\n",
              "      <td>0.906352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.195000</td>\n",
              "      <td>0.209398</td>\n",
              "      <td>0.921500</td>\n",
              "      <td>0.898962</td>\n",
              "      <td>0.900873</td>\n",
              "      <td>0.898497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.177333</td>\n",
              "      <td>0.929500</td>\n",
              "      <td>0.899638</td>\n",
              "      <td>0.930716</td>\n",
              "      <td>0.877740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.111900</td>\n",
              "      <td>0.199054</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>0.893705</td>\n",
              "      <td>0.899050</td>\n",
              "      <td>0.889506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.116100</td>\n",
              "      <td>0.167466</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>0.901808</td>\n",
              "      <td>0.903229</td>\n",
              "      <td>0.900924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>0.194174</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.907088</td>\n",
              "      <td>0.904751</td>\n",
              "      <td>0.909764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.172038</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.904614</td>\n",
              "      <td>0.917065</td>\n",
              "      <td>0.895811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.062900</td>\n",
              "      <td>0.206446</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.902054</td>\n",
              "      <td>0.921914</td>\n",
              "      <td>0.887877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.054500</td>\n",
              "      <td>0.204037</td>\n",
              "      <td>0.930500</td>\n",
              "      <td>0.902397</td>\n",
              "      <td>0.906537</td>\n",
              "      <td>0.898890</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.17071475088596344, 'eval_accuracy': 0.922, 'eval_f1': 0.8794891619970198, 'eval_precision': 0.8741028394878129, 'eval_recall': 0.8878727222194222, 'eval_runtime': 1.8323, 'eval_samples_per_second': 1091.512, 'eval_steps_per_second': 8.732, 'epoch': 5.0}\n",
            "Training on ag_news\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:52, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.621600</td>\n",
              "      <td>0.281903</td>\n",
              "      <td>0.906417</td>\n",
              "      <td>0.905716</td>\n",
              "      <td>0.907757</td>\n",
              "      <td>0.906233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.264500</td>\n",
              "      <td>0.220523</td>\n",
              "      <td>0.922083</td>\n",
              "      <td>0.922143</td>\n",
              "      <td>0.922855</td>\n",
              "      <td>0.922018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.178000</td>\n",
              "      <td>0.204443</td>\n",
              "      <td>0.929750</td>\n",
              "      <td>0.929668</td>\n",
              "      <td>0.930694</td>\n",
              "      <td>0.929594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.168100</td>\n",
              "      <td>0.212952</td>\n",
              "      <td>0.927667</td>\n",
              "      <td>0.927788</td>\n",
              "      <td>0.928147</td>\n",
              "      <td>0.927651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.107600</td>\n",
              "      <td>0.229054</td>\n",
              "      <td>0.929167</td>\n",
              "      <td>0.929620</td>\n",
              "      <td>0.932624</td>\n",
              "      <td>0.928803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.098900</td>\n",
              "      <td>0.213581</td>\n",
              "      <td>0.937250</td>\n",
              "      <td>0.937412</td>\n",
              "      <td>0.938419</td>\n",
              "      <td>0.937080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.278376</td>\n",
              "      <td>0.933000</td>\n",
              "      <td>0.932899</td>\n",
              "      <td>0.935033</td>\n",
              "      <td>0.932672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>0.249403</td>\n",
              "      <td>0.934500</td>\n",
              "      <td>0.934751</td>\n",
              "      <td>0.935480</td>\n",
              "      <td>0.934404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.030600</td>\n",
              "      <td>0.290250</td>\n",
              "      <td>0.933750</td>\n",
              "      <td>0.933829</td>\n",
              "      <td>0.934793</td>\n",
              "      <td>0.933576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.031800</td>\n",
              "      <td>0.279559</td>\n",
              "      <td>0.936167</td>\n",
              "      <td>0.936356</td>\n",
              "      <td>0.937128</td>\n",
              "      <td>0.936038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.23304365575313568, 'eval_accuracy': 0.9226315789473685, 'eval_f1': 0.9225109270016038, 'eval_precision': 0.923278097600036, 'eval_recall': 0.9226315789473685, 'eval_runtime': 11.5338, 'eval_samples_per_second': 658.932, 'eval_steps_per_second': 5.202, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:51, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.646600</td>\n",
              "      <td>0.311605</td>\n",
              "      <td>0.889917</td>\n",
              "      <td>0.889684</td>\n",
              "      <td>0.900114</td>\n",
              "      <td>0.889123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.275900</td>\n",
              "      <td>0.237998</td>\n",
              "      <td>0.917333</td>\n",
              "      <td>0.917223</td>\n",
              "      <td>0.920618</td>\n",
              "      <td>0.916876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.189700</td>\n",
              "      <td>0.233450</td>\n",
              "      <td>0.924083</td>\n",
              "      <td>0.924061</td>\n",
              "      <td>0.924632</td>\n",
              "      <td>0.923989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.167100</td>\n",
              "      <td>0.215744</td>\n",
              "      <td>0.928250</td>\n",
              "      <td>0.928310</td>\n",
              "      <td>0.929710</td>\n",
              "      <td>0.928019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.106600</td>\n",
              "      <td>0.218216</td>\n",
              "      <td>0.934250</td>\n",
              "      <td>0.934435</td>\n",
              "      <td>0.935224</td>\n",
              "      <td>0.934104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.105600</td>\n",
              "      <td>0.212658</td>\n",
              "      <td>0.934750</td>\n",
              "      <td>0.934871</td>\n",
              "      <td>0.936645</td>\n",
              "      <td>0.934465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.060400</td>\n",
              "      <td>0.236793</td>\n",
              "      <td>0.935167</td>\n",
              "      <td>0.935402</td>\n",
              "      <td>0.936580</td>\n",
              "      <td>0.934966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.058700</td>\n",
              "      <td>0.247401</td>\n",
              "      <td>0.937333</td>\n",
              "      <td>0.937236</td>\n",
              "      <td>0.939068</td>\n",
              "      <td>0.937062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>0.261102</td>\n",
              "      <td>0.937083</td>\n",
              "      <td>0.937210</td>\n",
              "      <td>0.938214</td>\n",
              "      <td>0.936903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.259842</td>\n",
              "      <td>0.937833</td>\n",
              "      <td>0.937963</td>\n",
              "      <td>0.938681</td>\n",
              "      <td>0.937693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.2617753744125366, 'eval_accuracy': 0.924078947368421, 'eval_f1': 0.9241728518020494, 'eval_precision': 0.9261847338726614, 'eval_recall': 0.9240789473684211, 'eval_runtime': 11.2878, 'eval_samples_per_second': 673.292, 'eval_steps_per_second': 5.315, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.648400</td>\n",
              "      <td>0.324349</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.888108</td>\n",
              "      <td>0.899132</td>\n",
              "      <td>0.886602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.269200</td>\n",
              "      <td>0.235963</td>\n",
              "      <td>0.917833</td>\n",
              "      <td>0.917542</td>\n",
              "      <td>0.921746</td>\n",
              "      <td>0.917376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.178600</td>\n",
              "      <td>0.213188</td>\n",
              "      <td>0.926167</td>\n",
              "      <td>0.926473</td>\n",
              "      <td>0.929321</td>\n",
              "      <td>0.925803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.165700</td>\n",
              "      <td>0.197157</td>\n",
              "      <td>0.931333</td>\n",
              "      <td>0.931545</td>\n",
              "      <td>0.932608</td>\n",
              "      <td>0.931179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.102600</td>\n",
              "      <td>0.210316</td>\n",
              "      <td>0.932250</td>\n",
              "      <td>0.932150</td>\n",
              "      <td>0.933125</td>\n",
              "      <td>0.932087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.105200</td>\n",
              "      <td>0.195247</td>\n",
              "      <td>0.937667</td>\n",
              "      <td>0.937796</td>\n",
              "      <td>0.937959</td>\n",
              "      <td>0.937706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.061900</td>\n",
              "      <td>0.227349</td>\n",
              "      <td>0.937917</td>\n",
              "      <td>0.938145</td>\n",
              "      <td>0.938911</td>\n",
              "      <td>0.937823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.051500</td>\n",
              "      <td>0.265496</td>\n",
              "      <td>0.935083</td>\n",
              "      <td>0.934696</td>\n",
              "      <td>0.936320</td>\n",
              "      <td>0.934912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.029200</td>\n",
              "      <td>0.251709</td>\n",
              "      <td>0.936750</td>\n",
              "      <td>0.936969</td>\n",
              "      <td>0.937222</td>\n",
              "      <td>0.936815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.271193</td>\n",
              "      <td>0.936667</td>\n",
              "      <td>0.936674</td>\n",
              "      <td>0.937955</td>\n",
              "      <td>0.936442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.2339123636484146, 'eval_accuracy': 0.9281578947368421, 'eval_f1': 0.9281760023499399, 'eval_precision': 0.9282312527823355, 'eval_recall': 0.9281578947368421, 'eval_runtime': 11.987, 'eval_samples_per_second': 634.021, 'eval_steps_per_second': 5.005, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 13:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.666900</td>\n",
              "      <td>0.306466</td>\n",
              "      <td>0.896750</td>\n",
              "      <td>0.895894</td>\n",
              "      <td>0.899970</td>\n",
              "      <td>0.896294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.265100</td>\n",
              "      <td>0.229419</td>\n",
              "      <td>0.922000</td>\n",
              "      <td>0.922141</td>\n",
              "      <td>0.925031</td>\n",
              "      <td>0.921590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.173600</td>\n",
              "      <td>0.231561</td>\n",
              "      <td>0.924833</td>\n",
              "      <td>0.924586</td>\n",
              "      <td>0.925657</td>\n",
              "      <td>0.924801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>0.198466</td>\n",
              "      <td>0.934750</td>\n",
              "      <td>0.934922</td>\n",
              "      <td>0.936197</td>\n",
              "      <td>0.934548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.099100</td>\n",
              "      <td>0.227006</td>\n",
              "      <td>0.930167</td>\n",
              "      <td>0.930406</td>\n",
              "      <td>0.933796</td>\n",
              "      <td>0.929742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.103900</td>\n",
              "      <td>0.224822</td>\n",
              "      <td>0.931583</td>\n",
              "      <td>0.931509</td>\n",
              "      <td>0.931820</td>\n",
              "      <td>0.931543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.056100</td>\n",
              "      <td>0.241923</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.936309</td>\n",
              "      <td>0.937149</td>\n",
              "      <td>0.935934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.056500</td>\n",
              "      <td>0.239581</td>\n",
              "      <td>0.936167</td>\n",
              "      <td>0.936301</td>\n",
              "      <td>0.936997</td>\n",
              "      <td>0.936044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.275405</td>\n",
              "      <td>0.937083</td>\n",
              "      <td>0.937044</td>\n",
              "      <td>0.937664</td>\n",
              "      <td>0.936955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.029800</td>\n",
              "      <td>0.277171</td>\n",
              "      <td>0.937750</td>\n",
              "      <td>0.937808</td>\n",
              "      <td>0.938383</td>\n",
              "      <td>0.937639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.22856833040714264, 'eval_accuracy': 0.924078947368421, 'eval_f1': 0.9241249637903068, 'eval_precision': 0.9250407502789031, 'eval_recall': 0.924078947368421, 'eval_runtime': 11.7562, 'eval_samples_per_second': 646.47, 'eval_steps_per_second': 5.104, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 13:08, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.625700</td>\n",
              "      <td>0.272812</td>\n",
              "      <td>0.905583</td>\n",
              "      <td>0.904901</td>\n",
              "      <td>0.906327</td>\n",
              "      <td>0.905326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.264800</td>\n",
              "      <td>0.221658</td>\n",
              "      <td>0.924750</td>\n",
              "      <td>0.924623</td>\n",
              "      <td>0.927461</td>\n",
              "      <td>0.924359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.226216</td>\n",
              "      <td>0.925667</td>\n",
              "      <td>0.925504</td>\n",
              "      <td>0.925776</td>\n",
              "      <td>0.925618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.171700</td>\n",
              "      <td>0.203990</td>\n",
              "      <td>0.932750</td>\n",
              "      <td>0.932938</td>\n",
              "      <td>0.933249</td>\n",
              "      <td>0.932867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>0.230140</td>\n",
              "      <td>0.930667</td>\n",
              "      <td>0.930930</td>\n",
              "      <td>0.931695</td>\n",
              "      <td>0.930558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.101600</td>\n",
              "      <td>0.206086</td>\n",
              "      <td>0.935583</td>\n",
              "      <td>0.935724</td>\n",
              "      <td>0.937339</td>\n",
              "      <td>0.935310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>0.244591</td>\n",
              "      <td>0.933750</td>\n",
              "      <td>0.933966</td>\n",
              "      <td>0.934239</td>\n",
              "      <td>0.933958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.249634</td>\n",
              "      <td>0.935500</td>\n",
              "      <td>0.935713</td>\n",
              "      <td>0.937644</td>\n",
              "      <td>0.935185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.253976</td>\n",
              "      <td>0.938917</td>\n",
              "      <td>0.939063</td>\n",
              "      <td>0.939733</td>\n",
              "      <td>0.938797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.270864</td>\n",
              "      <td>0.938167</td>\n",
              "      <td>0.938323</td>\n",
              "      <td>0.939258</td>\n",
              "      <td>0.937998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:11]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.2296949177980423, 'eval_accuracy': 0.9244736842105263, 'eval_f1': 0.9244982455133841, 'eval_precision': 0.924690852596656, 'eval_recall': 0.9244736842105263, 'eval_runtime': 11.7008, 'eval_samples_per_second': 649.528, 'eval_steps_per_second': 5.128, 'epoch': 5.0}\n",
            "Training on tweet_eval\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.584000</td>\n",
              "      <td>0.448634</td>\n",
              "      <td>0.796828</td>\n",
              "      <td>0.760608</td>\n",
              "      <td>0.788692</td>\n",
              "      <td>0.747875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.452100</td>\n",
              "      <td>0.459075</td>\n",
              "      <td>0.774169</td>\n",
              "      <td>0.754013</td>\n",
              "      <td>0.751159</td>\n",
              "      <td>0.757632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.384900</td>\n",
              "      <td>0.457192</td>\n",
              "      <td>0.791541</td>\n",
              "      <td>0.753866</td>\n",
              "      <td>0.782561</td>\n",
              "      <td>0.741272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.385800</td>\n",
              "      <td>0.443570</td>\n",
              "      <td>0.808157</td>\n",
              "      <td>0.781032</td>\n",
              "      <td>0.793581</td>\n",
              "      <td>0.772907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.270900</td>\n",
              "      <td>0.519578</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.762269</td>\n",
              "      <td>0.757790</td>\n",
              "      <td>0.769348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.251900</td>\n",
              "      <td>0.540624</td>\n",
              "      <td>0.793051</td>\n",
              "      <td>0.767620</td>\n",
              "      <td>0.773030</td>\n",
              "      <td>0.763391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.158700</td>\n",
              "      <td>0.649210</td>\n",
              "      <td>0.783233</td>\n",
              "      <td>0.764545</td>\n",
              "      <td>0.761076</td>\n",
              "      <td>0.769170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.145200</td>\n",
              "      <td>0.707974</td>\n",
              "      <td>0.784743</td>\n",
              "      <td>0.761540</td>\n",
              "      <td>0.762523</td>\n",
              "      <td>0.760612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.092500</td>\n",
              "      <td>0.834718</td>\n",
              "      <td>0.782477</td>\n",
              "      <td>0.761810</td>\n",
              "      <td>0.759906</td>\n",
              "      <td>0.763991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.081700</td>\n",
              "      <td>0.848118</td>\n",
              "      <td>0.781722</td>\n",
              "      <td>0.759434</td>\n",
              "      <td>0.759045</td>\n",
              "      <td>0.759834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3827950358390808, 'eval_accuracy': 0.8418604651162791, 'eval_f1': 0.7917067367626212, 'eval_precision': 0.8140925875064848, 'eval_recall': 0.7766801075268817, 'eval_runtime': 1.7283, 'eval_samples_per_second': 497.594, 'eval_steps_per_second': 4.05, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:43, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.585600</td>\n",
              "      <td>0.459636</td>\n",
              "      <td>0.782477</td>\n",
              "      <td>0.748604</td>\n",
              "      <td>0.765442</td>\n",
              "      <td>0.739449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.458800</td>\n",
              "      <td>0.455227</td>\n",
              "      <td>0.783233</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.762419</td>\n",
              "      <td>0.776328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.371600</td>\n",
              "      <td>0.456884</td>\n",
              "      <td>0.795317</td>\n",
              "      <td>0.773724</td>\n",
              "      <td>0.774153</td>\n",
              "      <td>0.773306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.392100</td>\n",
              "      <td>0.474365</td>\n",
              "      <td>0.780211</td>\n",
              "      <td>0.768064</td>\n",
              "      <td>0.763053</td>\n",
              "      <td>0.783731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.262400</td>\n",
              "      <td>0.516996</td>\n",
              "      <td>0.789275</td>\n",
              "      <td>0.769141</td>\n",
              "      <td>0.767290</td>\n",
              "      <td>0.771238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.256400</td>\n",
              "      <td>0.520290</td>\n",
              "      <td>0.787764</td>\n",
              "      <td>0.757902</td>\n",
              "      <td>0.769259</td>\n",
              "      <td>0.750653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.138800</td>\n",
              "      <td>0.708322</td>\n",
              "      <td>0.771148</td>\n",
              "      <td>0.747781</td>\n",
              "      <td>0.747409</td>\n",
              "      <td>0.748162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>0.702091</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.750652</td>\n",
              "      <td>0.758193</td>\n",
              "      <td>0.745317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.084600</td>\n",
              "      <td>0.822130</td>\n",
              "      <td>0.783988</td>\n",
              "      <td>0.760074</td>\n",
              "      <td>0.761807</td>\n",
              "      <td>0.758500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>0.830640</td>\n",
              "      <td>0.781722</td>\n",
              "      <td>0.760867</td>\n",
              "      <td>0.759074</td>\n",
              "      <td>0.762901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.39685946702957153, 'eval_accuracy': 0.8290697674418605, 'eval_f1': 0.7851019669238575, 'eval_precision': 0.7886461709991122, 'eval_recall': 0.7818548387096774, 'eval_runtime': 0.9904, 'eval_samples_per_second': 868.346, 'eval_steps_per_second': 7.068, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:42, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.559600</td>\n",
              "      <td>0.452185</td>\n",
              "      <td>0.792296</td>\n",
              "      <td>0.760715</td>\n",
              "      <td>0.776707</td>\n",
              "      <td>0.751565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.471600</td>\n",
              "      <td>0.454290</td>\n",
              "      <td>0.782477</td>\n",
              "      <td>0.764266</td>\n",
              "      <td>0.760442</td>\n",
              "      <td>0.769615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.384600</td>\n",
              "      <td>0.458058</td>\n",
              "      <td>0.795317</td>\n",
              "      <td>0.767907</td>\n",
              "      <td>0.777107</td>\n",
              "      <td>0.761546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.457015</td>\n",
              "      <td>0.793051</td>\n",
              "      <td>0.771805</td>\n",
              "      <td>0.771530</td>\n",
              "      <td>0.772083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.241300</td>\n",
              "      <td>0.564478</td>\n",
              "      <td>0.774169</td>\n",
              "      <td>0.756888</td>\n",
              "      <td>0.752386</td>\n",
              "      <td>0.764279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.563945</td>\n",
              "      <td>0.780967</td>\n",
              "      <td>0.744192</td>\n",
              "      <td>0.765975</td>\n",
              "      <td>0.733691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.132100</td>\n",
              "      <td>0.703401</td>\n",
              "      <td>0.774924</td>\n",
              "      <td>0.753779</td>\n",
              "      <td>0.751737</td>\n",
              "      <td>0.756165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.138900</td>\n",
              "      <td>0.708940</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.754780</td>\n",
              "      <td>0.756790</td>\n",
              "      <td>0.752987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.825834</td>\n",
              "      <td>0.771903</td>\n",
              "      <td>0.749987</td>\n",
              "      <td>0.748375</td>\n",
              "      <td>0.751808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.074800</td>\n",
              "      <td>0.854073</td>\n",
              "      <td>0.774924</td>\n",
              "      <td>0.752566</td>\n",
              "      <td>0.751591</td>\n",
              "      <td>0.753609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.39575374126434326, 'eval_accuracy': 0.8372093023255814, 'eval_f1': 0.7842773290523253, 'eval_precision': 0.8090461595616234, 'eval_recall': 0.7683467741935484, 'eval_runtime': 0.9697, 'eval_samples_per_second': 886.889, 'eval_steps_per_second': 7.219, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:39, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.588600</td>\n",
              "      <td>0.550191</td>\n",
              "      <td>0.761329</td>\n",
              "      <td>0.683675</td>\n",
              "      <td>0.794147</td>\n",
              "      <td>0.672646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.446100</td>\n",
              "      <td>0.456626</td>\n",
              "      <td>0.773414</td>\n",
              "      <td>0.756390</td>\n",
              "      <td>0.751783</td>\n",
              "      <td>0.764212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.451412</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.771473</td>\n",
              "      <td>0.766033</td>\n",
              "      <td>0.783175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.391800</td>\n",
              "      <td>0.432387</td>\n",
              "      <td>0.802115</td>\n",
              "      <td>0.773304</td>\n",
              "      <td>0.787241</td>\n",
              "      <td>0.764703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.288400</td>\n",
              "      <td>0.491201</td>\n",
              "      <td>0.795317</td>\n",
              "      <td>0.772537</td>\n",
              "      <td>0.774516</td>\n",
              "      <td>0.770749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.270700</td>\n",
              "      <td>0.507103</td>\n",
              "      <td>0.795317</td>\n",
              "      <td>0.768986</td>\n",
              "      <td>0.776347</td>\n",
              "      <td>0.763591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.162200</td>\n",
              "      <td>0.674980</td>\n",
              "      <td>0.783988</td>\n",
              "      <td>0.757170</td>\n",
              "      <td>0.762777</td>\n",
              "      <td>0.752876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.626215</td>\n",
              "      <td>0.770393</td>\n",
              "      <td>0.747076</td>\n",
              "      <td>0.746585</td>\n",
              "      <td>0.747584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.104900</td>\n",
              "      <td>0.797550</td>\n",
              "      <td>0.774169</td>\n",
              "      <td>0.757098</td>\n",
              "      <td>0.752512</td>\n",
              "      <td>0.764790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.090100</td>\n",
              "      <td>0.810859</td>\n",
              "      <td>0.772659</td>\n",
              "      <td>0.749445</td>\n",
              "      <td>0.749071</td>\n",
              "      <td>0.749829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3743872046470642, 'eval_accuracy': 0.8441860465116279, 'eval_f1': 0.7947698729867002, 'eval_precision': 0.8173731270408007, 'eval_recall': 0.7795698924731183, 'eval_runtime': 1.0105, 'eval_samples_per_second': 851.044, 'eval_steps_per_second': 6.927, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:41, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.592500</td>\n",
              "      <td>0.470200</td>\n",
              "      <td>0.777190</td>\n",
              "      <td>0.754190</td>\n",
              "      <td>0.754061</td>\n",
              "      <td>0.754320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.458200</td>\n",
              "      <td>0.447488</td>\n",
              "      <td>0.790785</td>\n",
              "      <td>0.743392</td>\n",
              "      <td>0.796712</td>\n",
              "      <td>0.727401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.373800</td>\n",
              "      <td>0.498763</td>\n",
              "      <td>0.769637</td>\n",
              "      <td>0.753476</td>\n",
              "      <td>0.748633</td>\n",
              "      <td>0.762856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.391600</td>\n",
              "      <td>0.463277</td>\n",
              "      <td>0.796073</td>\n",
              "      <td>0.759884</td>\n",
              "      <td>0.787493</td>\n",
              "      <td>0.747297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.257800</td>\n",
              "      <td>0.510994</td>\n",
              "      <td>0.799849</td>\n",
              "      <td>0.774359</td>\n",
              "      <td>0.781405</td>\n",
              "      <td>0.769105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.262800</td>\n",
              "      <td>0.507918</td>\n",
              "      <td>0.786254</td>\n",
              "      <td>0.764667</td>\n",
              "      <td>0.764014</td>\n",
              "      <td>0.765347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.150900</td>\n",
              "      <td>0.699258</td>\n",
              "      <td>0.793051</td>\n",
              "      <td>0.761130</td>\n",
              "      <td>0.778072</td>\n",
              "      <td>0.751631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.146300</td>\n",
              "      <td>0.664016</td>\n",
              "      <td>0.793807</td>\n",
              "      <td>0.767548</td>\n",
              "      <td>0.774431</td>\n",
              "      <td>0.762435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.095600</td>\n",
              "      <td>0.825419</td>\n",
              "      <td>0.786254</td>\n",
              "      <td>0.757914</td>\n",
              "      <td>0.766336</td>\n",
              "      <td>0.752053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.091500</td>\n",
              "      <td>0.818591</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.757764</td>\n",
              "      <td>0.765059</td>\n",
              "      <td>0.752498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3768704831600189, 'eval_accuracy': 0.8325581395348837, 'eval_f1': 0.7594984890974202, 'eval_precision': 0.8310502283105023, 'eval_recall': 0.7319220430107527, 'eval_runtime': 1.0551, 'eval_samples_per_second': 815.074, 'eval_steps_per_second': 6.634, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "sparse_attention_results = train_and_evaluate(train_datasets_sparse_attention, dev_datasets_sparse_attention, test_datasets_sparse_attention, tokenizer, is_custom=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsWl0Hj4TXng",
        "outputId": "f7ec3ebf-67f6-4082-b793-9f778fb347d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {('dair-ai/emotion',\n",
              "              ''): [{'eval_loss': 0.17847631871700287,\n",
              "               'eval_accuracy': 0.922,\n",
              "               'eval_f1': 0.8743260612418546,\n",
              "               'eval_precision': 0.8938048600006353,\n",
              "               'eval_recall': 0.8719245203825721,\n",
              "               'eval_runtime': 1.8591,\n",
              "               'eval_samples_per_second': 1075.771,\n",
              "               'eval_steps_per_second': 8.606,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.17453917860984802,\n",
              "               'eval_accuracy': 0.9225,\n",
              "               'eval_f1': 0.8728442645045379,\n",
              "               'eval_precision': 0.9025337424594381,\n",
              "               'eval_recall': 0.8514768124550852,\n",
              "               'eval_runtime': 1.901,\n",
              "               'eval_samples_per_second': 1052.095,\n",
              "               'eval_steps_per_second': 8.417,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.1664198637008667,\n",
              "               'eval_accuracy': 0.923,\n",
              "               'eval_f1': 0.877071529534987,\n",
              "               'eval_precision': 0.8761924448686415,\n",
              "               'eval_recall': 0.8813261663971786,\n",
              "               'eval_runtime': 1.8488,\n",
              "               'eval_samples_per_second': 1081.755,\n",
              "               'eval_steps_per_second': 8.654,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.17260678112506866,\n",
              "               'eval_accuracy': 0.924,\n",
              "               'eval_f1': 0.8835934417345165,\n",
              "               'eval_precision': 0.8791409231543019,\n",
              "               'eval_recall': 0.8969695161316765,\n",
              "               'eval_runtime': 1.7697,\n",
              "               'eval_samples_per_second': 1130.107,\n",
              "               'eval_steps_per_second': 9.041,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.17071475088596344,\n",
              "               'eval_accuracy': 0.922,\n",
              "               'eval_f1': 0.8794891619970198,\n",
              "               'eval_precision': 0.8741028394878129,\n",
              "               'eval_recall': 0.8878727222194222,\n",
              "               'eval_runtime': 1.8323,\n",
              "               'eval_samples_per_second': 1091.512,\n",
              "               'eval_steps_per_second': 8.732,\n",
              "               'epoch': 5.0}],\n",
              "             ('ag_news',\n",
              "              ''): [{'eval_loss': 0.23304365575313568,\n",
              "               'eval_accuracy': 0.9226315789473685,\n",
              "               'eval_f1': 0.9225109270016038,\n",
              "               'eval_precision': 0.923278097600036,\n",
              "               'eval_recall': 0.9226315789473685,\n",
              "               'eval_runtime': 11.5338,\n",
              "               'eval_samples_per_second': 658.932,\n",
              "               'eval_steps_per_second': 5.202,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.2617753744125366,\n",
              "               'eval_accuracy': 0.924078947368421,\n",
              "               'eval_f1': 0.9241728518020494,\n",
              "               'eval_precision': 0.9261847338726614,\n",
              "               'eval_recall': 0.9240789473684211,\n",
              "               'eval_runtime': 11.2878,\n",
              "               'eval_samples_per_second': 673.292,\n",
              "               'eval_steps_per_second': 5.315,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.2339123636484146,\n",
              "               'eval_accuracy': 0.9281578947368421,\n",
              "               'eval_f1': 0.9281760023499399,\n",
              "               'eval_precision': 0.9282312527823355,\n",
              "               'eval_recall': 0.9281578947368421,\n",
              "               'eval_runtime': 11.987,\n",
              "               'eval_samples_per_second': 634.021,\n",
              "               'eval_steps_per_second': 5.005,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.22856833040714264,\n",
              "               'eval_accuracy': 0.924078947368421,\n",
              "               'eval_f1': 0.9241249637903068,\n",
              "               'eval_precision': 0.9250407502789031,\n",
              "               'eval_recall': 0.924078947368421,\n",
              "               'eval_runtime': 11.7562,\n",
              "               'eval_samples_per_second': 646.47,\n",
              "               'eval_steps_per_second': 5.104,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.2296949177980423,\n",
              "               'eval_accuracy': 0.9244736842105263,\n",
              "               'eval_f1': 0.9244982455133841,\n",
              "               'eval_precision': 0.924690852596656,\n",
              "               'eval_recall': 0.9244736842105263,\n",
              "               'eval_runtime': 11.7008,\n",
              "               'eval_samples_per_second': 649.528,\n",
              "               'eval_steps_per_second': 5.128,\n",
              "               'epoch': 5.0}],\n",
              "             ('tweet_eval',\n",
              "              'offensive'): [{'eval_loss': 0.3827950358390808,\n",
              "               'eval_accuracy': 0.8418604651162791,\n",
              "               'eval_f1': 0.7917067367626212,\n",
              "               'eval_precision': 0.8140925875064848,\n",
              "               'eval_recall': 0.7766801075268817,\n",
              "               'eval_runtime': 1.7283,\n",
              "               'eval_samples_per_second': 497.594,\n",
              "               'eval_steps_per_second': 4.05,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.39685946702957153,\n",
              "               'eval_accuracy': 0.8290697674418605,\n",
              "               'eval_f1': 0.7851019669238575,\n",
              "               'eval_precision': 0.7886461709991122,\n",
              "               'eval_recall': 0.7818548387096774,\n",
              "               'eval_runtime': 0.9904,\n",
              "               'eval_samples_per_second': 868.346,\n",
              "               'eval_steps_per_second': 7.068,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.39575374126434326,\n",
              "               'eval_accuracy': 0.8372093023255814,\n",
              "               'eval_f1': 0.7842773290523253,\n",
              "               'eval_precision': 0.8090461595616234,\n",
              "               'eval_recall': 0.7683467741935484,\n",
              "               'eval_runtime': 0.9697,\n",
              "               'eval_samples_per_second': 886.889,\n",
              "               'eval_steps_per_second': 7.219,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.3743872046470642,\n",
              "               'eval_accuracy': 0.8441860465116279,\n",
              "               'eval_f1': 0.7947698729867002,\n",
              "               'eval_precision': 0.8173731270408007,\n",
              "               'eval_recall': 0.7795698924731183,\n",
              "               'eval_runtime': 1.0105,\n",
              "               'eval_samples_per_second': 851.044,\n",
              "               'eval_steps_per_second': 6.927,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.3768704831600189,\n",
              "               'eval_accuracy': 0.8325581395348837,\n",
              "               'eval_f1': 0.7594984890974202,\n",
              "               'eval_precision': 0.8310502283105023,\n",
              "               'eval_recall': 0.7319220430107527,\n",
              "               'eval_runtime': 1.0551,\n",
              "               'eval_samples_per_second': 815.074,\n",
              "               'eval_steps_per_second': 6.634,\n",
              "               'epoch': 5.0}]})"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sparse_attention_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t8YkFgOTZjd"
      },
      "outputs": [],
      "source": [
        "save_results(\"sparse_attention_results.pkl\", sparse_attention_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnlAdT1RORXe"
      },
      "source": [
        "## Training a model with hybrid dense+sparse attention\n",
        "\n",
        "We'll have dense self-attention in the first 4 layers and sparse sliding window attention in the rest. Reminder that `bert-base` has 12 layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PZcSn8k8Kpg"
      },
      "outputs": [],
      "source": [
        "layerwise_sparse_attention_results = train_and_evaluate(train_datasets_sparse_attention, dev_datasets_sparse_attention, test_datasets_sparse_attention, tokenizer, is_custom=True, full_attention_layers=[0,1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elup1bnN877r"
      },
      "outputs": [],
      "source": [
        "save_results(\"layerwise_sparse_attention_results.pkl\", layerwise_sparse_attention_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model without special treatment of special tokens."
      ],
      "metadata": {
        "id": "7tBWdao1pGJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_attention_no_special_results = train_and_evaluate(train_datasets_sparse_no_special_attention, dev_datasets_sparse_no_special_attention, test_datasets_sparse_no_special_attention, tokenizer, is_custom=True)"
      ],
      "metadata": {
        "id": "XyKtqmOMpFZL",
        "outputId": "b8b3e42d-f38b-465b-d4f2-11ea56adca13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on dair-ai/emotion\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.647200</td>\n",
              "      <td>1.582118</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.087900</td>\n",
              "      <td>0.125313</td>\n",
              "      <td>0.166799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.399300</td>\n",
              "      <td>1.217313</td>\n",
              "      <td>0.559000</td>\n",
              "      <td>0.273905</td>\n",
              "      <td>0.330844</td>\n",
              "      <td>0.316210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.005400</td>\n",
              "      <td>0.803985</td>\n",
              "      <td>0.721500</td>\n",
              "      <td>0.633145</td>\n",
              "      <td>0.681179</td>\n",
              "      <td>0.620817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.786400</td>\n",
              "      <td>0.665933</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>0.726625</td>\n",
              "      <td>0.802410</td>\n",
              "      <td>0.691719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.585500</td>\n",
              "      <td>0.565640</td>\n",
              "      <td>0.812000</td>\n",
              "      <td>0.778834</td>\n",
              "      <td>0.838149</td>\n",
              "      <td>0.752019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.546300</td>\n",
              "      <td>0.551526</td>\n",
              "      <td>0.810500</td>\n",
              "      <td>0.782694</td>\n",
              "      <td>0.795447</td>\n",
              "      <td>0.772648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.439600</td>\n",
              "      <td>0.552423</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>0.788891</td>\n",
              "      <td>0.800760</td>\n",
              "      <td>0.779462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.412400</td>\n",
              "      <td>0.471978</td>\n",
              "      <td>0.833000</td>\n",
              "      <td>0.801944</td>\n",
              "      <td>0.833392</td>\n",
              "      <td>0.777472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.354900</td>\n",
              "      <td>0.505721</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.803204</td>\n",
              "      <td>0.813546</td>\n",
              "      <td>0.795017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.336600</td>\n",
              "      <td>0.505171</td>\n",
              "      <td>0.833500</td>\n",
              "      <td>0.805732</td>\n",
              "      <td>0.815350</td>\n",
              "      <td>0.798128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.5170992612838745, 'eval_accuracy': 0.818, 'eval_f1': 0.7671610075379188, 'eval_precision': 0.8069850375884332, 'eval_recall': 0.7392686986693096, 'eval_runtime': 1.6494, 'eval_samples_per_second': 1212.536, 'eval_steps_per_second': 9.7, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:17, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.646100</td>\n",
              "      <td>1.580542</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.086785</td>\n",
              "      <td>0.058667</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.591200</td>\n",
              "      <td>1.602717</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.071895</td>\n",
              "      <td>0.045833</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.561200</td>\n",
              "      <td>1.494887</td>\n",
              "      <td>0.422500</td>\n",
              "      <td>0.175416</td>\n",
              "      <td>0.155096</td>\n",
              "      <td>0.230473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.253400</td>\n",
              "      <td>1.057038</td>\n",
              "      <td>0.646000</td>\n",
              "      <td>0.421145</td>\n",
              "      <td>0.569679</td>\n",
              "      <td>0.442683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.885300</td>\n",
              "      <td>0.795026</td>\n",
              "      <td>0.730500</td>\n",
              "      <td>0.613308</td>\n",
              "      <td>0.627965</td>\n",
              "      <td>0.610469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.724800</td>\n",
              "      <td>0.652769</td>\n",
              "      <td>0.761500</td>\n",
              "      <td>0.659157</td>\n",
              "      <td>0.811173</td>\n",
              "      <td>0.648672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.595200</td>\n",
              "      <td>0.649982</td>\n",
              "      <td>0.779500</td>\n",
              "      <td>0.729712</td>\n",
              "      <td>0.771038</td>\n",
              "      <td>0.704171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.566700</td>\n",
              "      <td>0.568322</td>\n",
              "      <td>0.795500</td>\n",
              "      <td>0.761908</td>\n",
              "      <td>0.795871</td>\n",
              "      <td>0.738611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.485000</td>\n",
              "      <td>0.593621</td>\n",
              "      <td>0.798500</td>\n",
              "      <td>0.756867</td>\n",
              "      <td>0.791066</td>\n",
              "      <td>0.737291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.460300</td>\n",
              "      <td>0.560731</td>\n",
              "      <td>0.799500</td>\n",
              "      <td>0.768725</td>\n",
              "      <td>0.799651</td>\n",
              "      <td>0.746074</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.6109445095062256, 'eval_accuracy': 0.792, 'eval_f1': 0.7527378131977422, 'eval_precision': 0.7804022450695318, 'eval_recall': 0.7308769520786272, 'eval_runtime': 1.6483, 'eval_samples_per_second': 1213.336, 'eval_steps_per_second': 9.707, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:14, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.617000</td>\n",
              "      <td>1.579596</td>\n",
              "      <td>0.354000</td>\n",
              "      <td>0.093803</td>\n",
              "      <td>0.113147</td>\n",
              "      <td>0.168409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.447100</td>\n",
              "      <td>1.254540</td>\n",
              "      <td>0.534000</td>\n",
              "      <td>0.216639</td>\n",
              "      <td>0.176333</td>\n",
              "      <td>0.281212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.090800</td>\n",
              "      <td>0.917363</td>\n",
              "      <td>0.650500</td>\n",
              "      <td>0.430355</td>\n",
              "      <td>0.589284</td>\n",
              "      <td>0.440718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.818900</td>\n",
              "      <td>0.699068</td>\n",
              "      <td>0.759500</td>\n",
              "      <td>0.708098</td>\n",
              "      <td>0.766038</td>\n",
              "      <td>0.676002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.605700</td>\n",
              "      <td>0.622775</td>\n",
              "      <td>0.783000</td>\n",
              "      <td>0.747618</td>\n",
              "      <td>0.796996</td>\n",
              "      <td>0.715083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.567600</td>\n",
              "      <td>0.556531</td>\n",
              "      <td>0.805500</td>\n",
              "      <td>0.772055</td>\n",
              "      <td>0.827602</td>\n",
              "      <td>0.736177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.451100</td>\n",
              "      <td>0.521708</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>0.797067</td>\n",
              "      <td>0.822762</td>\n",
              "      <td>0.776500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.428600</td>\n",
              "      <td>0.494986</td>\n",
              "      <td>0.818500</td>\n",
              "      <td>0.799681</td>\n",
              "      <td>0.820818</td>\n",
              "      <td>0.784069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>0.515151</td>\n",
              "      <td>0.821000</td>\n",
              "      <td>0.792163</td>\n",
              "      <td>0.813267</td>\n",
              "      <td>0.774731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.353500</td>\n",
              "      <td>0.508905</td>\n",
              "      <td>0.822500</td>\n",
              "      <td>0.793687</td>\n",
              "      <td>0.811381</td>\n",
              "      <td>0.778539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.5356423854827881, 'eval_accuracy': 0.8085, 'eval_f1': 0.7694921737070621, 'eval_precision': 0.7892207799046361, 'eval_recall': 0.7554867661964936, 'eval_runtime': 1.6615, 'eval_samples_per_second': 1203.755, 'eval_steps_per_second': 9.63, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:15, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.631500</td>\n",
              "      <td>1.590623</td>\n",
              "      <td>0.293000</td>\n",
              "      <td>0.095902</td>\n",
              "      <td>0.123099</td>\n",
              "      <td>0.173731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.457200</td>\n",
              "      <td>1.248936</td>\n",
              "      <td>0.548500</td>\n",
              "      <td>0.286962</td>\n",
              "      <td>0.257207</td>\n",
              "      <td>0.336827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.100600</td>\n",
              "      <td>0.930061</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.463078</td>\n",
              "      <td>0.569678</td>\n",
              "      <td>0.460698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.836500</td>\n",
              "      <td>0.724359</td>\n",
              "      <td>0.745500</td>\n",
              "      <td>0.661636</td>\n",
              "      <td>0.787233</td>\n",
              "      <td>0.627316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.641000</td>\n",
              "      <td>0.675518</td>\n",
              "      <td>0.772000</td>\n",
              "      <td>0.734663</td>\n",
              "      <td>0.754943</td>\n",
              "      <td>0.720559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.571100</td>\n",
              "      <td>0.567825</td>\n",
              "      <td>0.801000</td>\n",
              "      <td>0.767233</td>\n",
              "      <td>0.824782</td>\n",
              "      <td>0.728682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.476300</td>\n",
              "      <td>0.573661</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>0.784011</td>\n",
              "      <td>0.800094</td>\n",
              "      <td>0.773217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.466800</td>\n",
              "      <td>0.530352</td>\n",
              "      <td>0.812000</td>\n",
              "      <td>0.784845</td>\n",
              "      <td>0.806186</td>\n",
              "      <td>0.768311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.395000</td>\n",
              "      <td>0.537209</td>\n",
              "      <td>0.817000</td>\n",
              "      <td>0.790051</td>\n",
              "      <td>0.815071</td>\n",
              "      <td>0.769959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.379900</td>\n",
              "      <td>0.532926</td>\n",
              "      <td>0.819500</td>\n",
              "      <td>0.792362</td>\n",
              "      <td>0.824536</td>\n",
              "      <td>0.767952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.5855228304862976, 'eval_accuracy': 0.8015, 'eval_f1': 0.763542066223536, 'eval_precision': 0.7782646245023553, 'eval_recall': 0.752646438080506, 'eval_runtime': 1.674, 'eval_samples_per_second': 1194.722, 'eval_steps_per_second': 9.558, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:15, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.613600</td>\n",
              "      <td>1.575608</td>\n",
              "      <td>0.352500</td>\n",
              "      <td>0.090856</td>\n",
              "      <td>0.109568</td>\n",
              "      <td>0.167367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.439500</td>\n",
              "      <td>1.150613</td>\n",
              "      <td>0.572000</td>\n",
              "      <td>0.341414</td>\n",
              "      <td>0.359870</td>\n",
              "      <td>0.355143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.037100</td>\n",
              "      <td>0.818919</td>\n",
              "      <td>0.717500</td>\n",
              "      <td>0.631947</td>\n",
              "      <td>0.711622</td>\n",
              "      <td>0.600790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.779700</td>\n",
              "      <td>0.673343</td>\n",
              "      <td>0.779000</td>\n",
              "      <td>0.710121</td>\n",
              "      <td>0.825974</td>\n",
              "      <td>0.668765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.602400</td>\n",
              "      <td>0.598956</td>\n",
              "      <td>0.801000</td>\n",
              "      <td>0.763566</td>\n",
              "      <td>0.798850</td>\n",
              "      <td>0.738586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.527000</td>\n",
              "      <td>0.497315</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>0.794120</td>\n",
              "      <td>0.831629</td>\n",
              "      <td>0.767723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.432500</td>\n",
              "      <td>0.478411</td>\n",
              "      <td>0.830500</td>\n",
              "      <td>0.799656</td>\n",
              "      <td>0.832546</td>\n",
              "      <td>0.776447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.411500</td>\n",
              "      <td>0.494330</td>\n",
              "      <td>0.832500</td>\n",
              "      <td>0.799015</td>\n",
              "      <td>0.826414</td>\n",
              "      <td>0.779135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.351700</td>\n",
              "      <td>0.503179</td>\n",
              "      <td>0.837000</td>\n",
              "      <td>0.801706</td>\n",
              "      <td>0.820476</td>\n",
              "      <td>0.785859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.329000</td>\n",
              "      <td>0.482658</td>\n",
              "      <td>0.834500</td>\n",
              "      <td>0.802439</td>\n",
              "      <td>0.822212</td>\n",
              "      <td>0.786092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.5209266543388367, 'eval_accuracy': 0.8205, 'eval_f1': 0.7737810004351577, 'eval_precision': 0.8008575943767795, 'eval_recall': 0.7536158792341546, 'eval_runtime': 1.6612, 'eval_samples_per_second': 1203.984, 'eval_steps_per_second': 9.632, 'epoch': 5.0}\n",
            "Training on ag_news\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.183700</td>\n",
              "      <td>0.650287</td>\n",
              "      <td>0.758417</td>\n",
              "      <td>0.760830</td>\n",
              "      <td>0.767319</td>\n",
              "      <td>0.758767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.561500</td>\n",
              "      <td>0.441120</td>\n",
              "      <td>0.852333</td>\n",
              "      <td>0.852454</td>\n",
              "      <td>0.852247</td>\n",
              "      <td>0.852737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.389800</td>\n",
              "      <td>0.449176</td>\n",
              "      <td>0.857583</td>\n",
              "      <td>0.858329</td>\n",
              "      <td>0.859216</td>\n",
              "      <td>0.857900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.367200</td>\n",
              "      <td>0.380422</td>\n",
              "      <td>0.873583</td>\n",
              "      <td>0.873604</td>\n",
              "      <td>0.874418</td>\n",
              "      <td>0.873998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.261100</td>\n",
              "      <td>0.407125</td>\n",
              "      <td>0.871250</td>\n",
              "      <td>0.871781</td>\n",
              "      <td>0.874797</td>\n",
              "      <td>0.871698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.248900</td>\n",
              "      <td>0.362854</td>\n",
              "      <td>0.883167</td>\n",
              "      <td>0.883428</td>\n",
              "      <td>0.884672</td>\n",
              "      <td>0.883469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.176400</td>\n",
              "      <td>0.406798</td>\n",
              "      <td>0.880750</td>\n",
              "      <td>0.880972</td>\n",
              "      <td>0.883108</td>\n",
              "      <td>0.881074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.177200</td>\n",
              "      <td>0.425883</td>\n",
              "      <td>0.881333</td>\n",
              "      <td>0.881798</td>\n",
              "      <td>0.882421</td>\n",
              "      <td>0.881463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.131400</td>\n",
              "      <td>0.437366</td>\n",
              "      <td>0.882833</td>\n",
              "      <td>0.883312</td>\n",
              "      <td>0.884188</td>\n",
              "      <td>0.883159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.121600</td>\n",
              "      <td>0.439585</td>\n",
              "      <td>0.882833</td>\n",
              "      <td>0.883331</td>\n",
              "      <td>0.884404</td>\n",
              "      <td>0.883138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.41128718852996826, 'eval_accuracy': 0.8657894736842106, 'eval_f1': 0.8657784293834323, 'eval_precision': 0.8671952183967491, 'eval_recall': 0.8657894736842104, 'eval_runtime': 11.0565, 'eval_samples_per_second': 687.376, 'eval_steps_per_second': 5.427, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.151000</td>\n",
              "      <td>0.608390</td>\n",
              "      <td>0.787750</td>\n",
              "      <td>0.788311</td>\n",
              "      <td>0.792352</td>\n",
              "      <td>0.788360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.542900</td>\n",
              "      <td>0.460470</td>\n",
              "      <td>0.846583</td>\n",
              "      <td>0.846106</td>\n",
              "      <td>0.848468</td>\n",
              "      <td>0.846806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.385600</td>\n",
              "      <td>0.424722</td>\n",
              "      <td>0.864167</td>\n",
              "      <td>0.864576</td>\n",
              "      <td>0.867410</td>\n",
              "      <td>0.864356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.366900</td>\n",
              "      <td>0.410943</td>\n",
              "      <td>0.866583</td>\n",
              "      <td>0.867059</td>\n",
              "      <td>0.871745</td>\n",
              "      <td>0.867023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.254800</td>\n",
              "      <td>0.406946</td>\n",
              "      <td>0.876500</td>\n",
              "      <td>0.876674</td>\n",
              "      <td>0.878227</td>\n",
              "      <td>0.876815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.250500</td>\n",
              "      <td>0.377310</td>\n",
              "      <td>0.884333</td>\n",
              "      <td>0.884798</td>\n",
              "      <td>0.887170</td>\n",
              "      <td>0.884613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.448925</td>\n",
              "      <td>0.870500</td>\n",
              "      <td>0.871359</td>\n",
              "      <td>0.873414</td>\n",
              "      <td>0.870739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.395589</td>\n",
              "      <td>0.884417</td>\n",
              "      <td>0.884573</td>\n",
              "      <td>0.886551</td>\n",
              "      <td>0.884849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.125500</td>\n",
              "      <td>0.453943</td>\n",
              "      <td>0.884667</td>\n",
              "      <td>0.885202</td>\n",
              "      <td>0.886852</td>\n",
              "      <td>0.884943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.121100</td>\n",
              "      <td>0.428341</td>\n",
              "      <td>0.889250</td>\n",
              "      <td>0.889565</td>\n",
              "      <td>0.890369</td>\n",
              "      <td>0.889564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.42717432975769043, 'eval_accuracy': 0.8648684210526316, 'eval_f1': 0.8649986377679448, 'eval_precision': 0.8676272308634365, 'eval_recall': 0.8648684210526316, 'eval_runtime': 10.9475, 'eval_samples_per_second': 694.225, 'eval_steps_per_second': 5.481, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.138900</td>\n",
              "      <td>0.636934</td>\n",
              "      <td>0.778417</td>\n",
              "      <td>0.777206</td>\n",
              "      <td>0.782837</td>\n",
              "      <td>0.778934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.541000</td>\n",
              "      <td>0.474340</td>\n",
              "      <td>0.846500</td>\n",
              "      <td>0.845901</td>\n",
              "      <td>0.850829</td>\n",
              "      <td>0.847057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.386600</td>\n",
              "      <td>0.403314</td>\n",
              "      <td>0.865833</td>\n",
              "      <td>0.865895</td>\n",
              "      <td>0.869424</td>\n",
              "      <td>0.865920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.357600</td>\n",
              "      <td>0.388425</td>\n",
              "      <td>0.869833</td>\n",
              "      <td>0.870601</td>\n",
              "      <td>0.873622</td>\n",
              "      <td>0.870145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.244700</td>\n",
              "      <td>0.404903</td>\n",
              "      <td>0.872167</td>\n",
              "      <td>0.872322</td>\n",
              "      <td>0.876412</td>\n",
              "      <td>0.872541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.248200</td>\n",
              "      <td>0.390026</td>\n",
              "      <td>0.877500</td>\n",
              "      <td>0.878123</td>\n",
              "      <td>0.878702</td>\n",
              "      <td>0.877736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.178800</td>\n",
              "      <td>0.407607</td>\n",
              "      <td>0.879250</td>\n",
              "      <td>0.880184</td>\n",
              "      <td>0.883412</td>\n",
              "      <td>0.879504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.160500</td>\n",
              "      <td>0.408582</td>\n",
              "      <td>0.887583</td>\n",
              "      <td>0.888164</td>\n",
              "      <td>0.889375</td>\n",
              "      <td>0.887852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>0.432015</td>\n",
              "      <td>0.886583</td>\n",
              "      <td>0.887167</td>\n",
              "      <td>0.887748</td>\n",
              "      <td>0.886862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.113400</td>\n",
              "      <td>0.439516</td>\n",
              "      <td>0.885083</td>\n",
              "      <td>0.885447</td>\n",
              "      <td>0.886577</td>\n",
              "      <td>0.885501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.4203161597251892, 'eval_accuracy': 0.8581578947368421, 'eval_f1': 0.8586344314492481, 'eval_precision': 0.8614302552568383, 'eval_recall': 0.8581578947368421, 'eval_runtime': 10.9513, 'eval_samples_per_second': 693.984, 'eval_steps_per_second': 5.479, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:37, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.176900</td>\n",
              "      <td>0.772572</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.702819</td>\n",
              "      <td>0.724440</td>\n",
              "      <td>0.708203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.606400</td>\n",
              "      <td>0.494835</td>\n",
              "      <td>0.839083</td>\n",
              "      <td>0.839024</td>\n",
              "      <td>0.841024</td>\n",
              "      <td>0.839545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.415900</td>\n",
              "      <td>0.437880</td>\n",
              "      <td>0.856833</td>\n",
              "      <td>0.856634</td>\n",
              "      <td>0.856599</td>\n",
              "      <td>0.857250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.376000</td>\n",
              "      <td>0.394896</td>\n",
              "      <td>0.866917</td>\n",
              "      <td>0.867366</td>\n",
              "      <td>0.871842</td>\n",
              "      <td>0.867047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.261300</td>\n",
              "      <td>0.410247</td>\n",
              "      <td>0.863833</td>\n",
              "      <td>0.863154</td>\n",
              "      <td>0.868266</td>\n",
              "      <td>0.864479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.261200</td>\n",
              "      <td>0.388162</td>\n",
              "      <td>0.879583</td>\n",
              "      <td>0.879840</td>\n",
              "      <td>0.881135</td>\n",
              "      <td>0.879942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.174600</td>\n",
              "      <td>0.442161</td>\n",
              "      <td>0.873583</td>\n",
              "      <td>0.874882</td>\n",
              "      <td>0.877886</td>\n",
              "      <td>0.873555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>0.417459</td>\n",
              "      <td>0.878833</td>\n",
              "      <td>0.879407</td>\n",
              "      <td>0.882276</td>\n",
              "      <td>0.879195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.455692</td>\n",
              "      <td>0.883083</td>\n",
              "      <td>0.883224</td>\n",
              "      <td>0.885259</td>\n",
              "      <td>0.883568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.126000</td>\n",
              "      <td>0.440656</td>\n",
              "      <td>0.884000</td>\n",
              "      <td>0.884367</td>\n",
              "      <td>0.885345</td>\n",
              "      <td>0.884341</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.44503527879714966, 'eval_accuracy': 0.8621052631578947, 'eval_f1': 0.862040447551675, 'eval_precision': 0.8629080341994689, 'eval_recall': 0.8621052631578947, 'eval_runtime': 11.0313, 'eval_samples_per_second': 688.95, 'eval_steps_per_second': 5.439, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 12:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.140500</td>\n",
              "      <td>0.637815</td>\n",
              "      <td>0.769750</td>\n",
              "      <td>0.768764</td>\n",
              "      <td>0.776582</td>\n",
              "      <td>0.770027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.536800</td>\n",
              "      <td>0.465737</td>\n",
              "      <td>0.845667</td>\n",
              "      <td>0.847001</td>\n",
              "      <td>0.851925</td>\n",
              "      <td>0.845605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.387800</td>\n",
              "      <td>0.432929</td>\n",
              "      <td>0.858583</td>\n",
              "      <td>0.859163</td>\n",
              "      <td>0.862984</td>\n",
              "      <td>0.858977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.360500</td>\n",
              "      <td>0.380342</td>\n",
              "      <td>0.875917</td>\n",
              "      <td>0.876179</td>\n",
              "      <td>0.879237</td>\n",
              "      <td>0.876157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.256500</td>\n",
              "      <td>0.410598</td>\n",
              "      <td>0.870750</td>\n",
              "      <td>0.871516</td>\n",
              "      <td>0.873736</td>\n",
              "      <td>0.870794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.234100</td>\n",
              "      <td>0.431631</td>\n",
              "      <td>0.866917</td>\n",
              "      <td>0.867387</td>\n",
              "      <td>0.876545</td>\n",
              "      <td>0.867643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.168600</td>\n",
              "      <td>0.421543</td>\n",
              "      <td>0.885750</td>\n",
              "      <td>0.885889</td>\n",
              "      <td>0.886506</td>\n",
              "      <td>0.886032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.163000</td>\n",
              "      <td>0.407854</td>\n",
              "      <td>0.881833</td>\n",
              "      <td>0.882354</td>\n",
              "      <td>0.884873</td>\n",
              "      <td>0.882244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.117300</td>\n",
              "      <td>0.424399</td>\n",
              "      <td>0.889833</td>\n",
              "      <td>0.890257</td>\n",
              "      <td>0.891313</td>\n",
              "      <td>0.890096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>0.428993</td>\n",
              "      <td>0.890500</td>\n",
              "      <td>0.890914</td>\n",
              "      <td>0.891750</td>\n",
              "      <td>0.890740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.4179319441318512, 'eval_accuracy': 0.8630263157894736, 'eval_f1': 0.8627777751279201, 'eval_precision': 0.8652272292272936, 'eval_recall': 0.8630263157894738, 'eval_runtime': 10.9796, 'eval_samples_per_second': 692.194, 'eval_steps_per_second': 5.465, 'epoch': 5.0}\n",
            "Training on tweet_eval\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:31, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.641100</td>\n",
              "      <td>0.644888</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.642200</td>\n",
              "      <td>0.643642</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.634800</td>\n",
              "      <td>0.636432</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>0.597347</td>\n",
              "      <td>0.712991</td>\n",
              "      <td>0.580538</td>\n",
              "      <td>0.764013</td>\n",
              "      <td>0.596794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.573100</td>\n",
              "      <td>0.556487</td>\n",
              "      <td>0.732628</td>\n",
              "      <td>0.675382</td>\n",
              "      <td>0.710814</td>\n",
              "      <td>0.666531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.543780</td>\n",
              "      <td>0.737160</td>\n",
              "      <td>0.658318</td>\n",
              "      <td>0.739216</td>\n",
              "      <td>0.651081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.493700</td>\n",
              "      <td>0.540149</td>\n",
              "      <td>0.748489</td>\n",
              "      <td>0.700712</td>\n",
              "      <td>0.728365</td>\n",
              "      <td>0.690940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.498700</td>\n",
              "      <td>0.530790</td>\n",
              "      <td>0.742447</td>\n",
              "      <td>0.702149</td>\n",
              "      <td>0.716520</td>\n",
              "      <td>0.695008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.458300</td>\n",
              "      <td>0.536707</td>\n",
              "      <td>0.747734</td>\n",
              "      <td>0.708076</td>\n",
              "      <td>0.723071</td>\n",
              "      <td>0.700588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.462700</td>\n",
              "      <td>0.534847</td>\n",
              "      <td>0.745468</td>\n",
              "      <td>0.708230</td>\n",
              "      <td>0.719437</td>\n",
              "      <td>0.701922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.48413121700286865, 'eval_accuracy': 0.7767441860465116, 'eval_f1': 0.6894279093562852, 'eval_precision': 0.7269063638912252, 'eval_recall': 0.6740591397849462, 'eval_runtime': 0.8985, 'eval_samples_per_second': 957.136, 'eval_steps_per_second': 7.791, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.650400</td>\n",
              "      <td>0.654616</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.643700</td>\n",
              "      <td>0.646442</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.631100</td>\n",
              "      <td>0.629496</td>\n",
              "      <td>0.691088</td>\n",
              "      <td>0.528808</td>\n",
              "      <td>0.734278</td>\n",
              "      <td>0.564181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.588800</td>\n",
              "      <td>0.578473</td>\n",
              "      <td>0.693353</td>\n",
              "      <td>0.667071</td>\n",
              "      <td>0.664963</td>\n",
              "      <td>0.670218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.522300</td>\n",
              "      <td>0.580893</td>\n",
              "      <td>0.728852</td>\n",
              "      <td>0.653007</td>\n",
              "      <td>0.718973</td>\n",
              "      <td>0.646257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.518600</td>\n",
              "      <td>0.541573</td>\n",
              "      <td>0.731118</td>\n",
              "      <td>0.695646</td>\n",
              "      <td>0.702030</td>\n",
              "      <td>0.691450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.443500</td>\n",
              "      <td>0.569621</td>\n",
              "      <td>0.740937</td>\n",
              "      <td>0.696831</td>\n",
              "      <td>0.715929</td>\n",
              "      <td>0.688739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.455500</td>\n",
              "      <td>0.570852</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.698546</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.688006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.391800</td>\n",
              "      <td>0.587855</td>\n",
              "      <td>0.741692</td>\n",
              "      <td>0.704084</td>\n",
              "      <td>0.714868</td>\n",
              "      <td>0.698009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.398200</td>\n",
              "      <td>0.580590</td>\n",
              "      <td>0.741692</td>\n",
              "      <td>0.704810</td>\n",
              "      <td>0.714724</td>\n",
              "      <td>0.699032</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.4760294258594513, 'eval_accuracy': 0.8058139534883721, 'eval_f1': 0.7390506472859414, 'eval_precision': 0.7664264264264264, 'eval_recall': 0.7235887096774194, 'eval_runtime': 0.9038, 'eval_samples_per_second': 951.52, 'eval_steps_per_second': 7.745, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.641500</td>\n",
              "      <td>0.655054</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.651600</td>\n",
              "      <td>0.647240</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.647300</td>\n",
              "      <td>0.644997</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.635200</td>\n",
              "      <td>0.645821</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.637700</td>\n",
              "      <td>0.640649</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.622000</td>\n",
              "      <td>0.605956</td>\n",
              "      <td>0.691088</td>\n",
              "      <td>0.598803</td>\n",
              "      <td>0.658553</td>\n",
              "      <td>0.600482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.573900</td>\n",
              "      <td>0.572564</td>\n",
              "      <td>0.722054</td>\n",
              "      <td>0.635916</td>\n",
              "      <td>0.715589</td>\n",
              "      <td>0.632362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.541400</td>\n",
              "      <td>0.559035</td>\n",
              "      <td>0.722054</td>\n",
              "      <td>0.671821</td>\n",
              "      <td>0.692737</td>\n",
              "      <td>0.664574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.505300</td>\n",
              "      <td>0.565657</td>\n",
              "      <td>0.725831</td>\n",
              "      <td>0.665314</td>\n",
              "      <td>0.702269</td>\n",
              "      <td>0.657238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.489500</td>\n",
              "      <td>0.556286</td>\n",
              "      <td>0.724320</td>\n",
              "      <td>0.670523</td>\n",
              "      <td>0.696967</td>\n",
              "      <td>0.662729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.4995497465133667, 'eval_accuracy': 0.7930232558139535, 'eval_f1': 0.703801739884214, 'eval_precision': 0.7599263589432128, 'eval_recall': 0.6840725806451613, 'eval_runtime': 0.8677, 'eval_samples_per_second': 991.138, 'eval_steps_per_second': 8.067, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.653100</td>\n",
              "      <td>0.657757</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.636500</td>\n",
              "      <td>0.646240</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.639400</td>\n",
              "      <td>0.652885</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.640900</td>\n",
              "      <td>0.642667</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.622900</td>\n",
              "      <td>0.624092</td>\n",
              "      <td>0.656344</td>\n",
              "      <td>0.412484</td>\n",
              "      <td>0.661458</td>\n",
              "      <td>0.506402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.601700</td>\n",
              "      <td>0.596597</td>\n",
              "      <td>0.716012</td>\n",
              "      <td>0.623613</td>\n",
              "      <td>0.708924</td>\n",
              "      <td>0.622625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.530600</td>\n",
              "      <td>0.594960</td>\n",
              "      <td>0.723565</td>\n",
              "      <td>0.653314</td>\n",
              "      <td>0.704678</td>\n",
              "      <td>0.646301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.521200</td>\n",
              "      <td>0.558746</td>\n",
              "      <td>0.731118</td>\n",
              "      <td>0.645733</td>\n",
              "      <td>0.734510</td>\n",
              "      <td>0.640833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.478800</td>\n",
              "      <td>0.585851</td>\n",
              "      <td>0.724320</td>\n",
              "      <td>0.681595</td>\n",
              "      <td>0.694257</td>\n",
              "      <td>0.675511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.448300</td>\n",
              "      <td>0.579877</td>\n",
              "      <td>0.730363</td>\n",
              "      <td>0.677273</td>\n",
              "      <td>0.705254</td>\n",
              "      <td>0.668887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.5365700125694275, 'eval_accuracy': 0.786046511627907, 'eval_f1': 0.6534202410989628, 'eval_precision': 0.8002826189354687, 'eval_recall': 0.6370967741935484, 'eval_runtime': 0.8948, 'eval_samples_per_second': 961.104, 'eval_steps_per_second': 7.823, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.657700</td>\n",
              "      <td>0.643603</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.637800</td>\n",
              "      <td>0.634881</td>\n",
              "      <td>0.653323</td>\n",
              "      <td>0.395158</td>\n",
              "      <td>0.326662</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.574700</td>\n",
              "      <td>0.570942</td>\n",
              "      <td>0.709970</td>\n",
              "      <td>0.685401</td>\n",
              "      <td>0.682933</td>\n",
              "      <td>0.689070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.554400</td>\n",
              "      <td>0.538140</td>\n",
              "      <td>0.747734</td>\n",
              "      <td>0.695124</td>\n",
              "      <td>0.730772</td>\n",
              "      <td>0.684738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.483100</td>\n",
              "      <td>0.544026</td>\n",
              "      <td>0.730363</td>\n",
              "      <td>0.697397</td>\n",
              "      <td>0.701321</td>\n",
              "      <td>0.694451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.486000</td>\n",
              "      <td>0.522268</td>\n",
              "      <td>0.752266</td>\n",
              "      <td>0.709894</td>\n",
              "      <td>0.730345</td>\n",
              "      <td>0.700989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.416600</td>\n",
              "      <td>0.576708</td>\n",
              "      <td>0.762840</td>\n",
              "      <td>0.716766</td>\n",
              "      <td>0.748238</td>\n",
              "      <td>0.705502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.417600</td>\n",
              "      <td>0.543984</td>\n",
              "      <td>0.743958</td>\n",
              "      <td>0.714852</td>\n",
              "      <td>0.716966</td>\n",
              "      <td>0.713037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.366000</td>\n",
              "      <td>0.591232</td>\n",
              "      <td>0.740937</td>\n",
              "      <td>0.713901</td>\n",
              "      <td>0.714012</td>\n",
              "      <td>0.713792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.340500</td>\n",
              "      <td>0.611698</td>\n",
              "      <td>0.739426</td>\n",
              "      <td>0.712819</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.713147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.47421202063560486, 'eval_accuracy': 0.7895348837209303, 'eval_f1': 0.7162756023629726, 'eval_precision': 0.7427133528666328, 'eval_recall': 0.7020833333333334, 'eval_runtime': 0.8932, 'eval_samples_per_second': 962.862, 'eval_steps_per_second': 7.837, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_results(\"sparse_attention_no_special_results.pkl\", sparse_attention_no_special_results)"
      ],
      "metadata": {
        "id": "nZaDDI2-pYQg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_X10Kq0ddln"
      },
      "source": [
        "## BERT Pre-training with Sparse Attention\n",
        "\n",
        "Let's pre-train a Bert model with sparse attention to validate if pre-training with sparse attention gives a boost to finetuning when using the same strategy rather than solely finetuning with sparse attention.\n",
        "\n",
        "We'll use the **openwebtext** dataset for pre-training, the original model wasn't pre-trained on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpk9ss5CVD-8"
      },
      "outputs": [],
      "source": [
        "def get_pretraining_dataset(dataset_name):\n",
        "    ds = load_dataset(dataset_name, split='train', streaming=True)\n",
        "    return ds.take(136000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP-UME59ORXe"
      },
      "source": [
        "Since the dataset is too large to load into memory, we'll use the streaming API to load a subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIt2jspSXWIC"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from datasets import Dataset\n",
        "\n",
        "def gen_from_iterable_dataset(iterable_ds):\n",
        "    yield from iterable_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8f4e690c40d2409cbc2b9e1b9bc68197",
            "1dcd91e880ee4832b7962ee8688b6edf",
            "79cedae2143441ae95ec3f030a009dcf",
            "9e666b0c8d3c41cfa5dc6324e0dd1bc8",
            "dda305cbe2c94d0d9ffa6f957625563e",
            "797d2111640d41e2b0dcab1c04cd9fe0",
            "472cb9b31c994f3d880edcf82bd70302",
            "686648128d9943c6a837bdc821bea265",
            "b1306c6ba2f446fdb964aa45514c29ec",
            "12346b0c2ccb45e79109d97bf69a82b0",
            "7f7432ac557f44c6adb65f9921a55ba6",
            "3a1c392f686d42099a5bbe37d8658796",
            "738b23e7b2b34c3fbfdf405f82121359",
            "204eb9d928964480b0e80847d3b0101e",
            "03a315af0e0d44e283a82b2f0c0b91c6",
            "b3291aa83cc8420cac97ffb86af6998a",
            "22376d55f2b4421b952620da45595202",
            "54421b8d09d14a27a39af103b50773c1",
            "0bb0d88c4b514c038542e4f31c178a85",
            "27b5d8fd955344f18e41eaaf39458f82",
            "0e39fd615e1346678fffacaf312864a0",
            "f8353bdfe5a24f029dd4d6dfbf7f711c"
          ]
        },
        "id": "MMr1yCxSVD-8",
        "outputId": "ee907ff7-c88a-47ed-efad-cad0384075cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f4e690c40d2409cbc2b9e1b9bc68197",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.73k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a1c392f686d42099a5bbe37d8658796",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.33k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pretraining_train_dataset = get_pretraining_dataset(\"Skylion007/openwebtext\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PufAnAMIORXf"
      },
      "source": [
        "Convert an `IterableDataset` to `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "66060f99364d4a9aa9b604211d81c6b3",
            "290b5ee84a4140648401353fca759ab7",
            "299df810851c4d619bc2a1cb38ee3e46",
            "6d2e15b49cb4435aaed4d51c281687af",
            "6302fe29e429420eae12e8da744634f2",
            "feb72dc50c4848f2a80f606b46918d49",
            "28608b35b72648c8b1ead99488ba2ec4",
            "423989c647084d4eb9a69efaec4c89ff",
            "b15388e9eb2041f4b419323cd824ccb5",
            "64017558f71248ac8bfe0c5344b6ed1a",
            "89222b51d4734faea784262dbadec5a0"
          ]
        },
        "id": "nNfz66C-Xf78",
        "outputId": "2b89b7d3-ccde-4c70-ce06-bd019dfe2ad4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66060f99364d4a9aa9b604211d81c6b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pretraining_train_dataset = Dataset.from_generator(partial(gen_from_iterable_dataset, pretraining_train_dataset), features=pretraining_train_dataset.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikDNn8zdK4qu"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = pretraining_train_dataset.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3hZW_PrLNMp"
      },
      "outputs": [],
      "source": [
        "pretraining_dev_dataset = pretraining_train_dataset[\"test\"]\n",
        "pretraining_train_dataset = pretraining_train_dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjJZl8j4ORXf"
      },
      "source": [
        "### Optional: Save the dataset to memory for faster loading in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ae3d3c7833794226bbb2e954f211e99f",
            "3e7162ca2a294c29ae4eedd8813e05a0",
            "5e0d42f8b64d4d498f1872550fa03858",
            "249a10b9a27743b6bf5c0a7044a6b594",
            "38d431b89c3841d1a2be7490a1932578",
            "775e34bb596540eb8fd9026d2ff9894b",
            "60751a78708f4638bd3f1d584283059d",
            "becc1894cb024917b7c5d3196192fea4",
            "5727c402c4584a25a51645ad3ace9b5a",
            "9768ea891e9548b4abc8061e9a41642f",
            "d86ea8a6c29641f9a239e74eb69363ef",
            "19c16c85030847ad95cd7196a3e565b5",
            "79c310abfe7443e99d7bde6060099f2f",
            "8c7d79202e264969a0abff6b2ea4c2ef",
            "cbfbbd42afb74f66b8e908972fbc6dc2",
            "ab597e456de841a29f3b1ee212370619",
            "f853a28a6bdf4914bcc1169db0b49606",
            "9a9cf10ed7384d01b4724efe5c640fc2",
            "ea53c31589b54f49b42dcd0f7e1d259f",
            "ead918248cbf43edbe030d55dc415748",
            "a4641f214bb04f9d957265a3f55235b0",
            "a9af72a1d5504a6b9f1aa6cbe76f0054"
          ]
        },
        "id": "D_sKiTa-35r7",
        "outputId": "1bf3b719-99a5-42ed-f30c-1905945aebc0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae3d3c7833794226bbb2e954f211e99f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/2 shards):   0%|          | 0/122400 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c16c85030847ad95cd7196a3e565b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/13600 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pretraining_train_dataset.save_to_disk(\"./datasets/pretraining_train\")\n",
        "pretraining_dev_dataset.save_to_disk(\"./datasets/pretraining_dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBcFcwwq35r7"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = load_from_disk(\"./datasets/pretraining_train\")\n",
        "pretraining_dev_dataset = load_from_disk(\"./datasets/pretraining_dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULTf7G4AVD-8",
        "outputId": "6e91ac06-e03e-45db-ddaf-63df4d98461c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 122400\n",
              "})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretraining_train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPuq8rvNORXf"
      },
      "source": [
        "Since the dataset is large we don't want to vectorize all of it into memory as we did for our downstream tasks. We'll create a custom Pytorch Dataset that vectorizes only the required items of the batch into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYwoZ1-u35r8"
      },
      "outputs": [],
      "source": [
        "pretraining_train_torch_dataset = CustomDataset(pretraining_train_dataset, tokenizer, mode=\"sparse\", is_mlm=True)\n",
        "pretraining_dev_torch_dataset = CustomDataset(pretraining_dev_dataset, tokenizer, mode=\"sparse\", is_mlm=True)\n",
        "\n",
        "pretraining_train_torch_dense_dataset = CustomDataset(pretraining_train_dataset, tokenizer, mode=\"dense\", is_mlm=True)\n",
        "pretraining_dev_torch_dense_dataset = CustomDataset(pretraining_dev_dataset, tokenizer, mode=\"dense\", is_mlm=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kB0H56_ORXf"
      },
      "source": [
        "We'll continue pre-training the original Bert Model using a Masked Language Modeling head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69Tx1ud-YN3",
        "outputId": "43e16e34-c005-48b5-8386-1ac35bd5dd87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "mlm_model = BertForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g555z0ldsVTt",
        "outputId": "bc314e56-b584-4e6b-896b-d238a5775fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y11X8-BqORXg"
      },
      "source": [
        "We'll train for 500 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U27PvFr8VD-8"
      },
      "outputs": [],
      "source": [
        "pretraining_args = TrainingArguments(\n",
        "    output_dir='./bert-hybrid-sparse-sliding-window-attention',          # output directory\n",
        "    max_steps=500,            # total number of training steps\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=100,\n",
        "    gradient_accumulation_steps=8,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "pretrainer_dense_attention = Trainer(\n",
        "    model=mlm_model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=pretraining_args,                  # training arguments, defined above\n",
        "    train_dataset=pretraining_train_torch_dense_dataset,         # training dataset\n",
        "    eval_dataset=pretraining_dev_torch_dense_dataset,           # evaluation dataset\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldss1YJAORXg"
      },
      "source": [
        "Let's examine the loss of the original Bert Model on the dev dataset. Note that this is the model that uses **dense attention**. If you want to obtain a perplexity style metric for MLM just exponentiate the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "h6mbUl615DE1",
        "outputId": "4fccf0c8-5628-4e0b-c148-ec3141ce45d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 01:49]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.708167314529419,\n",
              " 'eval_runtime': 110.4806,\n",
              " 'eval_samples_per_second': 123.098,\n",
              " 'eval_steps_per_second': 1.928}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrainer_dense_attention.evaluate(pretraining_dev_torch_dense_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mWjQvqyORXg"
      },
      "source": [
        "Let's now create a CustomBertModel that uses the CustomBertEncoder that we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht2Bp2RTWHrm"
      },
      "outputs": [],
      "source": [
        "class CustomBertForMaskedLM(BertForMaskedLM):\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.bert = CustomBertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEt-_3hGWIF8"
      },
      "outputs": [],
      "source": [
        "custom_mlm_model = CustomBertForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWPfr2FxWXcO"
      },
      "outputs": [],
      "source": [
        "pretrainer_sparse_layerwise_attention = Trainer(\n",
        "    model=custom_mlm_model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=pretraining_args,                  # training arguments, defined above\n",
        "    train_dataset=pretraining_train_torch_dataset,         # training dataset\n",
        "    eval_dataset=pretraining_dev_torch_dataset,           # evaluation dataset\n",
        "    data_collator = partial(custom_collate, pad_token_id=tokenizer.pad_token_id, is_mlm=True, full_attention_layers=[0,1,2,3]),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "HVv7X6fc2bFC",
        "outputId": "d539bfe4-414a-4363-9bfd-cde3b7e62ba7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 04:31]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss before training : {'eval_loss': 4.836398124694824, 'eval_runtime': 275.7754, 'eval_samples_per_second': 49.315, 'eval_steps_per_second': 0.772}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loss before training : {pretrainer_sparse_layerwise_attention.evaluate(pretraining_dev_torch_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXEzExXMyRHO"
      },
      "source": [
        "We see that the MLM (Masked Language Modeling) loss for the hybrid-sparse sliding window attention model is almost twice as that of the original BERT MLM model. Let's see if continued pre-training the original BERT MLM model, using our custom layerwise attention mask improves MLM loss and subsequently, finetuning this model on our tasks above leads to improved performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "vLM-HsqzWwWb",
        "outputId": "5472469a-67eb-4ad7-8c78-4c23ed460fc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 56:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.607000</td>\n",
              "      <td>3.008602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.095800</td>\n",
              "      <td>2.876977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.995800</td>\n",
              "      <td>2.813109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.933900</td>\n",
              "      <td>2.787358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.909500</td>\n",
              "      <td>2.766676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='426' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 15:56]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=3.108405578613281, metrics={'train_runtime': 3418.613, 'train_samples_per_second': 18.721, 'train_steps_per_second': 0.146, 'total_flos': 1.6961223131136e+16, 'train_loss': 3.108405578613281, 'epoch': 0.52})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrainer_sparse_layerwise_attention.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "YTBwgQu2ElPH",
        "outputId": "9fdd8d23-263d-4881-898a-777eaaa657a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 04:34]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity after training : {'eval_loss': 2.777672290802002, 'eval_runtime': 276.4276, 'eval_samples_per_second': 49.199, 'eval_steps_per_second': 0.771, 'epoch': 0.52}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Perplexity after training : {pretrainer_sparse_layerwise_attention.evaluate(pretraining_dev_torch_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LN-RjQOH-ym"
      },
      "source": [
        "Looks like we managed to get the MLM loss  of the model using hybrid attention to a similar level as that of the model that uses dense attention. Now let's finetune this model on our 3 tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "McIoDHoaH-ym",
        "outputId": "44a84ea4-e58e-43a1-c7e1-bb8b9fb41552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7dca08e0018b4472b74aadf2a03c2316",
            "f6fc846b91644da2841abbc2f7ab5697",
            "4d11f8588cbc48aab724d849f62efd68",
            "454dfb4ef4ba4c509a6d0fcdde470563",
            "217ff7b01794405cbafbc0639e34b752",
            "e0bd43b0a4b3424193d17e26eb75d15b",
            "2d4b6e63f199465fbc50306e4d5fddca",
            "4c68a992107c4df18c9fdd46cc7290eb",
            "46a3a226d31a436180eaad37668af43a",
            "f5724ec35fa943ef824a753bc3514f1c",
            "752a4a178be04d3dbbea32c2f19470a6",
            "89ff1ec5547f45c9be372b5dfa83e49b",
            "48602ebc959c4aa1bfdbdc6d98ae866f",
            "1fdedcc94d4f4094b2434cb8ef5a44fa",
            "d5c3509488a84c68894515bdbfeaaa5c",
            "6efbd2b0c1974c33b9075bbe55b8e41a",
            "8db819d3a7364a1c95d22ca268086f1e",
            "76b46ad52b544b75aca5b433493d2c07",
            "59297c0fec6f44a5bc5e892d269c7c6a",
            "050b7f4b669041c5bcc8e55f2f7c84c4",
            "3ad23a0f1b1f44058bcc11fa28939f59",
            "097486830644436b93c10ac181de332f"
          ]
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on dair-ai/emotion\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dca08e0018b4472b74aadf2a03c2316",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89ff1ec5547f45c9be372b5dfa83e49b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.193500</td>\n",
              "      <td>0.426642</td>\n",
              "      <td>0.865500</td>\n",
              "      <td>0.822801</td>\n",
              "      <td>0.837816</td>\n",
              "      <td>0.813876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.315400</td>\n",
              "      <td>0.223521</td>\n",
              "      <td>0.921500</td>\n",
              "      <td>0.900956</td>\n",
              "      <td>0.890621</td>\n",
              "      <td>0.915957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.187800</td>\n",
              "      <td>0.182770</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.905273</td>\n",
              "      <td>0.931252</td>\n",
              "      <td>0.884910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.159440</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.905393</td>\n",
              "      <td>0.918356</td>\n",
              "      <td>0.894889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.110700</td>\n",
              "      <td>0.169327</td>\n",
              "      <td>0.935500</td>\n",
              "      <td>0.908806</td>\n",
              "      <td>0.921932</td>\n",
              "      <td>0.900451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.111900</td>\n",
              "      <td>0.147799</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.910225</td>\n",
              "      <td>0.914512</td>\n",
              "      <td>0.910684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.152653</td>\n",
              "      <td>0.934500</td>\n",
              "      <td>0.912555</td>\n",
              "      <td>0.899063</td>\n",
              "      <td>0.929979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.149352</td>\n",
              "      <td>0.933000</td>\n",
              "      <td>0.908866</td>\n",
              "      <td>0.913019</td>\n",
              "      <td>0.905326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.061800</td>\n",
              "      <td>0.163740</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.909141</td>\n",
              "      <td>0.907676</td>\n",
              "      <td>0.911508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.057200</td>\n",
              "      <td>0.166056</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.905763</td>\n",
              "      <td>0.908420</td>\n",
              "      <td>0.903286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.16094623506069183, 'eval_accuracy': 0.929, 'eval_f1': 0.882377635587576, 'eval_precision': 0.8896033348945437, 'eval_recall': 0.8846356554972364, 'eval_runtime': 2.0114, 'eval_samples_per_second': 994.338, 'eval_steps_per_second': 7.955, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.317300</td>\n",
              "      <td>0.510308</td>\n",
              "      <td>0.852500</td>\n",
              "      <td>0.806324</td>\n",
              "      <td>0.832475</td>\n",
              "      <td>0.788788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.347400</td>\n",
              "      <td>0.267336</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.887341</td>\n",
              "      <td>0.902397</td>\n",
              "      <td>0.882407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.188300</td>\n",
              "      <td>0.246153</td>\n",
              "      <td>0.919000</td>\n",
              "      <td>0.878743</td>\n",
              "      <td>0.892992</td>\n",
              "      <td>0.879489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.158900</td>\n",
              "      <td>0.164783</td>\n",
              "      <td>0.930500</td>\n",
              "      <td>0.902096</td>\n",
              "      <td>0.906523</td>\n",
              "      <td>0.899358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.118800</td>\n",
              "      <td>0.195190</td>\n",
              "      <td>0.926500</td>\n",
              "      <td>0.903678</td>\n",
              "      <td>0.897569</td>\n",
              "      <td>0.913077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.104100</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>0.935500</td>\n",
              "      <td>0.912163</td>\n",
              "      <td>0.909264</td>\n",
              "      <td>0.915443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.173016</td>\n",
              "      <td>0.926500</td>\n",
              "      <td>0.899281</td>\n",
              "      <td>0.899605</td>\n",
              "      <td>0.901104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>0.176678</td>\n",
              "      <td>0.931000</td>\n",
              "      <td>0.908375</td>\n",
              "      <td>0.917938</td>\n",
              "      <td>0.902028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.194254</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>0.909404</td>\n",
              "      <td>0.916842</td>\n",
              "      <td>0.902853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.055900</td>\n",
              "      <td>0.193039</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.902790</td>\n",
              "      <td>0.907252</td>\n",
              "      <td>0.899996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.17029298841953278, 'eval_accuracy': 0.923, 'eval_f1': 0.8765414137248344, 'eval_precision': 0.8859609311917499, 'eval_recall': 0.8685277108612498, 'eval_runtime': 2.0661, 'eval_samples_per_second': 968.028, 'eval_steps_per_second': 7.744, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.260600</td>\n",
              "      <td>0.524501</td>\n",
              "      <td>0.856500</td>\n",
              "      <td>0.756084</td>\n",
              "      <td>0.836792</td>\n",
              "      <td>0.740559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.349000</td>\n",
              "      <td>0.239003</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>0.891142</td>\n",
              "      <td>0.882158</td>\n",
              "      <td>0.903925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.186400</td>\n",
              "      <td>0.223867</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.891382</td>\n",
              "      <td>0.899760</td>\n",
              "      <td>0.885280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.171300</td>\n",
              "      <td>0.158407</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.909807</td>\n",
              "      <td>0.912342</td>\n",
              "      <td>0.911102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.109500</td>\n",
              "      <td>0.147689</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.911296</td>\n",
              "      <td>0.910073</td>\n",
              "      <td>0.914228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.107800</td>\n",
              "      <td>0.144453</td>\n",
              "      <td>0.934500</td>\n",
              "      <td>0.909165</td>\n",
              "      <td>0.928767</td>\n",
              "      <td>0.892677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.081700</td>\n",
              "      <td>0.150557</td>\n",
              "      <td>0.935000</td>\n",
              "      <td>0.906846</td>\n",
              "      <td>0.923494</td>\n",
              "      <td>0.893302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.079800</td>\n",
              "      <td>0.134954</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.920805</td>\n",
              "      <td>0.926215</td>\n",
              "      <td>0.915832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.063900</td>\n",
              "      <td>0.143207</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.908847</td>\n",
              "      <td>0.920964</td>\n",
              "      <td>0.899858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.059200</td>\n",
              "      <td>0.151639</td>\n",
              "      <td>0.939500</td>\n",
              "      <td>0.914972</td>\n",
              "      <td>0.921702</td>\n",
              "      <td>0.908864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.16021579504013062, 'eval_accuracy': 0.929, 'eval_f1': 0.8822137454512632, 'eval_precision': 0.8883649399609862, 'eval_recall': 0.8767553085715813, 'eval_runtime': 2.0647, 'eval_samples_per_second': 968.685, 'eval_steps_per_second': 7.749, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:37, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.224800</td>\n",
              "      <td>0.527948</td>\n",
              "      <td>0.838000</td>\n",
              "      <td>0.691742</td>\n",
              "      <td>0.850630</td>\n",
              "      <td>0.683921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.336400</td>\n",
              "      <td>0.221252</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.903206</td>\n",
              "      <td>0.895790</td>\n",
              "      <td>0.914406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.188700</td>\n",
              "      <td>0.171669</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.904318</td>\n",
              "      <td>0.894902</td>\n",
              "      <td>0.916854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.151400</td>\n",
              "      <td>0.154524</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>0.910375</td>\n",
              "      <td>0.914142</td>\n",
              "      <td>0.908460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.114800</td>\n",
              "      <td>0.159199</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.910586</td>\n",
              "      <td>0.903850</td>\n",
              "      <td>0.920667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.152532</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.907423</td>\n",
              "      <td>0.910770</td>\n",
              "      <td>0.906901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.125436</td>\n",
              "      <td>0.942500</td>\n",
              "      <td>0.919226</td>\n",
              "      <td>0.917084</td>\n",
              "      <td>0.922901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.128603</td>\n",
              "      <td>0.940500</td>\n",
              "      <td>0.915019</td>\n",
              "      <td>0.914243</td>\n",
              "      <td>0.916407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.060900</td>\n",
              "      <td>0.144691</td>\n",
              "      <td>0.941000</td>\n",
              "      <td>0.915667</td>\n",
              "      <td>0.912024</td>\n",
              "      <td>0.919692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.140044</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.921796</td>\n",
              "      <td>0.926236</td>\n",
              "      <td>0.918679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.1722239851951599, 'eval_accuracy': 0.9235, 'eval_f1': 0.8763370440498436, 'eval_precision': 0.8752611468662267, 'eval_recall': 0.8792167335486215, 'eval_runtime': 2.6448, 'eval_samples_per_second': 756.209, 'eval_steps_per_second': 6.05, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:37, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.185700</td>\n",
              "      <td>0.420806</td>\n",
              "      <td>0.876000</td>\n",
              "      <td>0.825325</td>\n",
              "      <td>0.842327</td>\n",
              "      <td>0.815501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.305500</td>\n",
              "      <td>0.239001</td>\n",
              "      <td>0.917000</td>\n",
              "      <td>0.892767</td>\n",
              "      <td>0.899068</td>\n",
              "      <td>0.888920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>0.177069</td>\n",
              "      <td>0.934000</td>\n",
              "      <td>0.911067</td>\n",
              "      <td>0.908880</td>\n",
              "      <td>0.917250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.160300</td>\n",
              "      <td>0.161827</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>0.910731</td>\n",
              "      <td>0.931646</td>\n",
              "      <td>0.899297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.168946</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.904222</td>\n",
              "      <td>0.919917</td>\n",
              "      <td>0.895721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.112200</td>\n",
              "      <td>0.145341</td>\n",
              "      <td>0.935500</td>\n",
              "      <td>0.911718</td>\n",
              "      <td>0.906402</td>\n",
              "      <td>0.918034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.084800</td>\n",
              "      <td>0.149258</td>\n",
              "      <td>0.939500</td>\n",
              "      <td>0.916947</td>\n",
              "      <td>0.912062</td>\n",
              "      <td>0.923012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.079400</td>\n",
              "      <td>0.164329</td>\n",
              "      <td>0.932000</td>\n",
              "      <td>0.909858</td>\n",
              "      <td>0.915685</td>\n",
              "      <td>0.907268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.068500</td>\n",
              "      <td>0.162726</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.913481</td>\n",
              "      <td>0.924747</td>\n",
              "      <td>0.905027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.055200</td>\n",
              "      <td>0.163327</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>0.915884</td>\n",
              "      <td>0.920216</td>\n",
              "      <td>0.912800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.1564135104417801, 'eval_accuracy': 0.9235, 'eval_f1': 0.8805331208098023, 'eval_precision': 0.8716844237308572, 'eval_recall': 0.8921555839987155, 'eval_runtime': 2.0653, 'eval_samples_per_second': 968.379, 'eval_steps_per_second': 7.747, 'epoch': 5.0}\n",
            "Training on ag_news\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 16:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.293328</td>\n",
              "      <td>0.899583</td>\n",
              "      <td>0.899213</td>\n",
              "      <td>0.902356</td>\n",
              "      <td>0.899075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.251200</td>\n",
              "      <td>0.229930</td>\n",
              "      <td>0.921167</td>\n",
              "      <td>0.920809</td>\n",
              "      <td>0.921078</td>\n",
              "      <td>0.920776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.174900</td>\n",
              "      <td>0.228145</td>\n",
              "      <td>0.924000</td>\n",
              "      <td>0.923246</td>\n",
              "      <td>0.926756</td>\n",
              "      <td>0.923401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.161800</td>\n",
              "      <td>0.220159</td>\n",
              "      <td>0.927583</td>\n",
              "      <td>0.927557</td>\n",
              "      <td>0.928487</td>\n",
              "      <td>0.927356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>0.252473</td>\n",
              "      <td>0.927500</td>\n",
              "      <td>0.927243</td>\n",
              "      <td>0.930875</td>\n",
              "      <td>0.927029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.094000</td>\n",
              "      <td>0.228402</td>\n",
              "      <td>0.931917</td>\n",
              "      <td>0.931490</td>\n",
              "      <td>0.934669</td>\n",
              "      <td>0.931411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>0.247697</td>\n",
              "      <td>0.935833</td>\n",
              "      <td>0.935459</td>\n",
              "      <td>0.936405</td>\n",
              "      <td>0.935417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.058600</td>\n",
              "      <td>0.245754</td>\n",
              "      <td>0.937250</td>\n",
              "      <td>0.937128</td>\n",
              "      <td>0.938096</td>\n",
              "      <td>0.936958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.275517</td>\n",
              "      <td>0.938917</td>\n",
              "      <td>0.938683</td>\n",
              "      <td>0.939930</td>\n",
              "      <td>0.938558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.030300</td>\n",
              "      <td>0.275042</td>\n",
              "      <td>0.937583</td>\n",
              "      <td>0.937420</td>\n",
              "      <td>0.938184</td>\n",
              "      <td>0.937266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.2391701638698578, 'eval_accuracy': 0.9232894736842105, 'eval_f1': 0.9236187349537566, 'eval_precision': 0.9245260751280724, 'eval_recall': 0.9232894736842105, 'eval_runtime': 18.2298, 'eval_samples_per_second': 416.9, 'eval_steps_per_second': 3.291, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 17:00, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.605600</td>\n",
              "      <td>0.260719</td>\n",
              "      <td>0.909000</td>\n",
              "      <td>0.908665</td>\n",
              "      <td>0.909439</td>\n",
              "      <td>0.908598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.252300</td>\n",
              "      <td>0.239058</td>\n",
              "      <td>0.914333</td>\n",
              "      <td>0.913863</td>\n",
              "      <td>0.918594</td>\n",
              "      <td>0.913802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.221414</td>\n",
              "      <td>0.929000</td>\n",
              "      <td>0.928643</td>\n",
              "      <td>0.929045</td>\n",
              "      <td>0.928600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>0.207807</td>\n",
              "      <td>0.933083</td>\n",
              "      <td>0.933075</td>\n",
              "      <td>0.934239</td>\n",
              "      <td>0.932834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.096600</td>\n",
              "      <td>0.219022</td>\n",
              "      <td>0.934333</td>\n",
              "      <td>0.934267</td>\n",
              "      <td>0.935194</td>\n",
              "      <td>0.934139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.098600</td>\n",
              "      <td>0.216163</td>\n",
              "      <td>0.936167</td>\n",
              "      <td>0.935747</td>\n",
              "      <td>0.936908</td>\n",
              "      <td>0.935765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>0.261257</td>\n",
              "      <td>0.931667</td>\n",
              "      <td>0.931470</td>\n",
              "      <td>0.932918</td>\n",
              "      <td>0.931327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.265872</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>0.936674</td>\n",
              "      <td>0.937915</td>\n",
              "      <td>0.936630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.026100</td>\n",
              "      <td>0.300291</td>\n",
              "      <td>0.935167</td>\n",
              "      <td>0.934763</td>\n",
              "      <td>0.936180</td>\n",
              "      <td>0.934746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.024300</td>\n",
              "      <td>0.301879</td>\n",
              "      <td>0.935417</td>\n",
              "      <td>0.935143</td>\n",
              "      <td>0.936444</td>\n",
              "      <td>0.935060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.23012344539165497, 'eval_accuracy': 0.9251315789473684, 'eval_f1': 0.9254993966585893, 'eval_precision': 0.9266811396059501, 'eval_recall': 0.9251315789473684, 'eval_runtime': 18.0433, 'eval_samples_per_second': 421.209, 'eval_steps_per_second': 3.325, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 16:45, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.598900</td>\n",
              "      <td>0.287261</td>\n",
              "      <td>0.907167</td>\n",
              "      <td>0.906415</td>\n",
              "      <td>0.909632</td>\n",
              "      <td>0.906598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>0.270815</td>\n",
              "      <td>0.908333</td>\n",
              "      <td>0.908031</td>\n",
              "      <td>0.914203</td>\n",
              "      <td>0.907824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.172400</td>\n",
              "      <td>0.227755</td>\n",
              "      <td>0.923417</td>\n",
              "      <td>0.923027</td>\n",
              "      <td>0.924479</td>\n",
              "      <td>0.922976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.161500</td>\n",
              "      <td>0.219322</td>\n",
              "      <td>0.927667</td>\n",
              "      <td>0.927341</td>\n",
              "      <td>0.929289</td>\n",
              "      <td>0.927281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.103300</td>\n",
              "      <td>0.234140</td>\n",
              "      <td>0.926083</td>\n",
              "      <td>0.925630</td>\n",
              "      <td>0.929200</td>\n",
              "      <td>0.925575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.101000</td>\n",
              "      <td>0.208179</td>\n",
              "      <td>0.935833</td>\n",
              "      <td>0.935742</td>\n",
              "      <td>0.936532</td>\n",
              "      <td>0.935606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.062200</td>\n",
              "      <td>0.243446</td>\n",
              "      <td>0.937583</td>\n",
              "      <td>0.937429</td>\n",
              "      <td>0.937991</td>\n",
              "      <td>0.937318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.053600</td>\n",
              "      <td>0.264555</td>\n",
              "      <td>0.938000</td>\n",
              "      <td>0.937561</td>\n",
              "      <td>0.938690</td>\n",
              "      <td>0.937585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.029100</td>\n",
              "      <td>0.280631</td>\n",
              "      <td>0.937250</td>\n",
              "      <td>0.937111</td>\n",
              "      <td>0.937777</td>\n",
              "      <td>0.936973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>0.290248</td>\n",
              "      <td>0.937750</td>\n",
              "      <td>0.937436</td>\n",
              "      <td>0.938322</td>\n",
              "      <td>0.937385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.2387235313653946, 'eval_accuracy': 0.9244736842105263, 'eval_f1': 0.9247333016108108, 'eval_precision': 0.925465872188768, 'eval_recall': 0.9244736842105263, 'eval_runtime': 17.8451, 'eval_samples_per_second': 425.887, 'eval_steps_per_second': 3.362, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 17:05, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.585100</td>\n",
              "      <td>0.339750</td>\n",
              "      <td>0.886917</td>\n",
              "      <td>0.885538</td>\n",
              "      <td>0.898414</td>\n",
              "      <td>0.886262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.244669</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.916476</td>\n",
              "      <td>0.919757</td>\n",
              "      <td>0.916301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.238746</td>\n",
              "      <td>0.921750</td>\n",
              "      <td>0.921209</td>\n",
              "      <td>0.922332</td>\n",
              "      <td>0.921239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.168900</td>\n",
              "      <td>0.208841</td>\n",
              "      <td>0.931333</td>\n",
              "      <td>0.930959</td>\n",
              "      <td>0.932583</td>\n",
              "      <td>0.930937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.098800</td>\n",
              "      <td>0.237313</td>\n",
              "      <td>0.930417</td>\n",
              "      <td>0.930232</td>\n",
              "      <td>0.932944</td>\n",
              "      <td>0.930016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.105100</td>\n",
              "      <td>0.231696</td>\n",
              "      <td>0.931500</td>\n",
              "      <td>0.931125</td>\n",
              "      <td>0.932647</td>\n",
              "      <td>0.931084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.060700</td>\n",
              "      <td>0.237692</td>\n",
              "      <td>0.934833</td>\n",
              "      <td>0.934609</td>\n",
              "      <td>0.934894</td>\n",
              "      <td>0.934533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.059700</td>\n",
              "      <td>0.247934</td>\n",
              "      <td>0.936417</td>\n",
              "      <td>0.936349</td>\n",
              "      <td>0.937405</td>\n",
              "      <td>0.936163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.028600</td>\n",
              "      <td>0.297875</td>\n",
              "      <td>0.935667</td>\n",
              "      <td>0.935348</td>\n",
              "      <td>0.936332</td>\n",
              "      <td>0.935285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.286441</td>\n",
              "      <td>0.937000</td>\n",
              "      <td>0.936761</td>\n",
              "      <td>0.937427</td>\n",
              "      <td>0.936671</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results on the test set are: {'eval_loss': 0.23599393665790558, 'eval_accuracy': 0.9217105263157894, 'eval_f1': 0.9215913642663511, 'eval_precision': 0.9229899195451634, 'eval_recall': 0.9217105263157894, 'eval_runtime': 18.2483, 'eval_samples_per_second': 416.477, 'eval_steps_per_second': 3.288, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 105/2345 00:30 < 10:55, 3.42 it/s, Epoch 0.22/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2345' max='2345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2345/2345 16:59, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.574900</td>\n",
              "      <td>0.290320</td>\n",
              "      <td>0.901500</td>\n",
              "      <td>0.901322</td>\n",
              "      <td>0.906893</td>\n",
              "      <td>0.901018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.239305</td>\n",
              "      <td>0.917917</td>\n",
              "      <td>0.917510</td>\n",
              "      <td>0.919130</td>\n",
              "      <td>0.917515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>702</td>\n",
              "      <td>0.175500</td>\n",
              "      <td>0.227234</td>\n",
              "      <td>0.927583</td>\n",
              "      <td>0.927361</td>\n",
              "      <td>0.928531</td>\n",
              "      <td>0.927228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.168500</td>\n",
              "      <td>0.198907</td>\n",
              "      <td>0.933500</td>\n",
              "      <td>0.933347</td>\n",
              "      <td>0.934033</td>\n",
              "      <td>0.933262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.236027</td>\n",
              "      <td>0.930250</td>\n",
              "      <td>0.930119</td>\n",
              "      <td>0.931656</td>\n",
              "      <td>0.929944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1404</td>\n",
              "      <td>0.103400</td>\n",
              "      <td>0.205042</td>\n",
              "      <td>0.938333</td>\n",
              "      <td>0.938149</td>\n",
              "      <td>0.938402</td>\n",
              "      <td>0.938083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1638</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.245382</td>\n",
              "      <td>0.935083</td>\n",
              "      <td>0.934784</td>\n",
              "      <td>0.934818</td>\n",
              "      <td>0.934759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.059100</td>\n",
              "      <td>0.244713</td>\n",
              "      <td>0.936750</td>\n",
              "      <td>0.936584</td>\n",
              "      <td>0.937903</td>\n",
              "      <td>0.936456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2106</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.264010</td>\n",
              "      <td>0.937417</td>\n",
              "      <td>0.937136</td>\n",
              "      <td>0.937590</td>\n",
              "      <td>0.937074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.028700</td>\n",
              "      <td>0.272134</td>\n",
              "      <td>0.938667</td>\n",
              "      <td>0.938491</td>\n",
              "      <td>0.939262</td>\n",
              "      <td>0.938380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:17]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.21575021743774414, 'eval_accuracy': 0.9246052631578947, 'eval_f1': 0.9248441667162735, 'eval_precision': 0.925827346146759, 'eval_recall': 0.9246052631578948, 'eval_runtime': 18.3443, 'eval_samples_per_second': 414.298, 'eval_steps_per_second': 3.271, 'epoch': 5.0}\n",
            "Training on tweet_eval\n",
            "Training for the 0th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 03:57, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.569200</td>\n",
              "      <td>0.442828</td>\n",
              "      <td>0.791541</td>\n",
              "      <td>0.758143</td>\n",
              "      <td>0.777491</td>\n",
              "      <td>0.747919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.441157</td>\n",
              "      <td>0.796828</td>\n",
              "      <td>0.770159</td>\n",
              "      <td>0.778471</td>\n",
              "      <td>0.764236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.375300</td>\n",
              "      <td>0.448816</td>\n",
              "      <td>0.805136</td>\n",
              "      <td>0.775931</td>\n",
              "      <td>0.791798</td>\n",
              "      <td>0.766504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.377900</td>\n",
              "      <td>0.454297</td>\n",
              "      <td>0.800604</td>\n",
              "      <td>0.776847</td>\n",
              "      <td>0.781217</td>\n",
              "      <td>0.773262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.269500</td>\n",
              "      <td>0.533234</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.771290</td>\n",
              "      <td>0.765869</td>\n",
              "      <td>0.782664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.252300</td>\n",
              "      <td>0.537929</td>\n",
              "      <td>0.792296</td>\n",
              "      <td>0.767162</td>\n",
              "      <td>0.771966</td>\n",
              "      <td>0.763324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.154600</td>\n",
              "      <td>0.680425</td>\n",
              "      <td>0.782477</td>\n",
              "      <td>0.767313</td>\n",
              "      <td>0.762111</td>\n",
              "      <td>0.777284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.140400</td>\n",
              "      <td>0.718286</td>\n",
              "      <td>0.783988</td>\n",
              "      <td>0.763465</td>\n",
              "      <td>0.761547</td>\n",
              "      <td>0.765658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.083600</td>\n",
              "      <td>0.826673</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.759201</td>\n",
              "      <td>0.756727</td>\n",
              "      <td>0.762190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.844131</td>\n",
              "      <td>0.776435</td>\n",
              "      <td>0.757274</td>\n",
              "      <td>0.753837</td>\n",
              "      <td>0.761923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3906966745853424, 'eval_accuracy': 0.8302325581395349, 'eval_f1': 0.7833678398895791, 'eval_precision': 0.7919744318181818, 'eval_recall': 0.7762768817204302, 'eval_runtime': 1.2196, 'eval_samples_per_second': 705.17, 'eval_steps_per_second': 5.74, 'epoch': 5.0}\n",
            "Training for the 1th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 04:12, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.564500</td>\n",
              "      <td>0.470762</td>\n",
              "      <td>0.782477</td>\n",
              "      <td>0.769861</td>\n",
              "      <td>0.764608</td>\n",
              "      <td>0.784442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.452000</td>\n",
              "      <td>0.439101</td>\n",
              "      <td>0.799094</td>\n",
              "      <td>0.778014</td>\n",
              "      <td>0.778302</td>\n",
              "      <td>0.777730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.363400</td>\n",
              "      <td>0.462205</td>\n",
              "      <td>0.799849</td>\n",
              "      <td>0.775127</td>\n",
              "      <td>0.780888</td>\n",
              "      <td>0.770639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.386000</td>\n",
              "      <td>0.452457</td>\n",
              "      <td>0.790030</td>\n",
              "      <td>0.775206</td>\n",
              "      <td>0.769858</td>\n",
              "      <td>0.785110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.255400</td>\n",
              "      <td>0.520193</td>\n",
              "      <td>0.791541</td>\n",
              "      <td>0.765395</td>\n",
              "      <td>0.771586</td>\n",
              "      <td>0.760701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.247000</td>\n",
              "      <td>0.503619</td>\n",
              "      <td>0.784743</td>\n",
              "      <td>0.760786</td>\n",
              "      <td>0.762682</td>\n",
              "      <td>0.759078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.144800</td>\n",
              "      <td>0.642218</td>\n",
              "      <td>0.783988</td>\n",
              "      <td>0.761077</td>\n",
              "      <td>0.761626</td>\n",
              "      <td>0.760545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.144000</td>\n",
              "      <td>0.695946</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.752906</td>\n",
              "      <td>0.757282</td>\n",
              "      <td>0.749407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.087700</td>\n",
              "      <td>0.836164</td>\n",
              "      <td>0.780211</td>\n",
              "      <td>0.756774</td>\n",
              "      <td>0.757454</td>\n",
              "      <td>0.756121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.074900</td>\n",
              "      <td>0.860955</td>\n",
              "      <td>0.775680</td>\n",
              "      <td>0.752015</td>\n",
              "      <td>0.752410</td>\n",
              "      <td>0.751630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3827888071537018, 'eval_accuracy': 0.8302325581395349, 'eval_f1': 0.7857103847519182, 'eval_precision': 0.7905701754385965, 'eval_recall': 0.7813844086021505, 'eval_runtime': 1.1854, 'eval_samples_per_second': 725.504, 'eval_steps_per_second': 5.905, 'epoch': 5.0}\n",
            "Training for the 2th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 04:20, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.538600</td>\n",
              "      <td>0.443336</td>\n",
              "      <td>0.792296</td>\n",
              "      <td>0.770385</td>\n",
              "      <td>0.770808</td>\n",
              "      <td>0.769971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.467200</td>\n",
              "      <td>0.473631</td>\n",
              "      <td>0.789275</td>\n",
              "      <td>0.775940</td>\n",
              "      <td>0.770366</td>\n",
              "      <td>0.788622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.388100</td>\n",
              "      <td>0.443704</td>\n",
              "      <td>0.799849</td>\n",
              "      <td>0.768533</td>\n",
              "      <td>0.786869</td>\n",
              "      <td>0.758368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.468192</td>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.761991</td>\n",
              "      <td>0.788977</td>\n",
              "      <td>0.749475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.248200</td>\n",
              "      <td>0.572424</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.763291</td>\n",
              "      <td>0.758393</td>\n",
              "      <td>0.771904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.251600</td>\n",
              "      <td>0.521425</td>\n",
              "      <td>0.786254</td>\n",
              "      <td>0.755285</td>\n",
              "      <td>0.768127</td>\n",
              "      <td>0.747452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.141200</td>\n",
              "      <td>0.665808</td>\n",
              "      <td>0.781722</td>\n",
              "      <td>0.759190</td>\n",
              "      <td>0.759058</td>\n",
              "      <td>0.759322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.133100</td>\n",
              "      <td>0.706746</td>\n",
              "      <td>0.783233</td>\n",
              "      <td>0.758331</td>\n",
              "      <td>0.761189</td>\n",
              "      <td>0.755877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.080500</td>\n",
              "      <td>0.784676</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.766243</td>\n",
              "      <td>0.763329</td>\n",
              "      <td>0.769882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>0.803251</td>\n",
              "      <td>0.787009</td>\n",
              "      <td>0.766084</td>\n",
              "      <td>0.764818</td>\n",
              "      <td>0.767459</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.382394939661026, 'eval_accuracy': 0.8418604651162791, 'eval_f1': 0.7959297618715278, 'eval_precision': 0.8093699044956906, 'eval_recall': 0.7856182795698925, 'eval_runtime': 1.1274, 'eval_samples_per_second': 762.793, 'eval_steps_per_second': 6.209, 'epoch': 5.0}\n",
            "Training for the 3th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 04:10, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.556500</td>\n",
              "      <td>0.538728</td>\n",
              "      <td>0.764350</td>\n",
              "      <td>0.685166</td>\n",
              "      <td>0.805944</td>\n",
              "      <td>0.673936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.442000</td>\n",
              "      <td>0.431683</td>\n",
              "      <td>0.799094</td>\n",
              "      <td>0.778692</td>\n",
              "      <td>0.778137</td>\n",
              "      <td>0.779264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.383900</td>\n",
              "      <td>0.447574</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.768579</td>\n",
              "      <td>0.764076</td>\n",
              "      <td>0.775506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.372100</td>\n",
              "      <td>0.434206</td>\n",
              "      <td>0.799094</td>\n",
              "      <td>0.766295</td>\n",
              "      <td>0.787565</td>\n",
              "      <td>0.755233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.257500</td>\n",
              "      <td>0.505231</td>\n",
              "      <td>0.796828</td>\n",
              "      <td>0.775625</td>\n",
              "      <td>0.775767</td>\n",
              "      <td>0.775485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.246500</td>\n",
              "      <td>0.530621</td>\n",
              "      <td>0.790785</td>\n",
              "      <td>0.764142</td>\n",
              "      <td>0.770944</td>\n",
              "      <td>0.759101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.137900</td>\n",
              "      <td>0.655621</td>\n",
              "      <td>0.790030</td>\n",
              "      <td>0.768237</td>\n",
              "      <td>0.768237</td>\n",
              "      <td>0.768237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.140900</td>\n",
              "      <td>0.670926</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.762501</td>\n",
              "      <td>0.763341</td>\n",
              "      <td>0.761701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.886764</td>\n",
              "      <td>0.786254</td>\n",
              "      <td>0.761956</td>\n",
              "      <td>0.764513</td>\n",
              "      <td>0.759723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.072900</td>\n",
              "      <td>0.878593</td>\n",
              "      <td>0.785498</td>\n",
              "      <td>0.762003</td>\n",
              "      <td>0.763439</td>\n",
              "      <td>0.760679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3902819752693176, 'eval_accuracy': 0.8395348837209302, 'eval_f1': 0.8011114164862346, 'eval_precision': 0.8003557195966728, 'eval_recall': 0.8018817204301075, 'eval_runtime': 1.1638, 'eval_samples_per_second': 738.99, 'eval_steps_per_second': 6.015, 'epoch': 5.0}\n",
            "Training for the 4th run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at Pramodith/bert-hybrid-sparse-sliding-window-attention and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='935' max='935' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [935/935 04:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.604600</td>\n",
              "      <td>0.505506</td>\n",
              "      <td>0.740937</td>\n",
              "      <td>0.734700</td>\n",
              "      <td>0.740937</td>\n",
              "      <td>0.765944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.453400</td>\n",
              "      <td>0.460157</td>\n",
              "      <td>0.786254</td>\n",
              "      <td>0.732616</td>\n",
              "      <td>0.800073</td>\n",
              "      <td>0.716263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.376900</td>\n",
              "      <td>0.479239</td>\n",
              "      <td>0.771148</td>\n",
              "      <td>0.757601</td>\n",
              "      <td>0.752647</td>\n",
              "      <td>0.771170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.378700</td>\n",
              "      <td>0.434564</td>\n",
              "      <td>0.790030</td>\n",
              "      <td>0.763155</td>\n",
              "      <td>0.770150</td>\n",
              "      <td>0.758011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>0.257600</td>\n",
              "      <td>0.507677</td>\n",
              "      <td>0.796828</td>\n",
              "      <td>0.774928</td>\n",
              "      <td>0.775960</td>\n",
              "      <td>0.773951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>558</td>\n",
              "      <td>0.251900</td>\n",
              "      <td>0.553290</td>\n",
              "      <td>0.777946</td>\n",
              "      <td>0.758012</td>\n",
              "      <td>0.755195</td>\n",
              "      <td>0.761545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>651</td>\n",
              "      <td>0.141600</td>\n",
              "      <td>0.689100</td>\n",
              "      <td>0.796828</td>\n",
              "      <td>0.773488</td>\n",
              "      <td>0.776507</td>\n",
              "      <td>0.770883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.139200</td>\n",
              "      <td>0.679673</td>\n",
              "      <td>0.771903</td>\n",
              "      <td>0.756002</td>\n",
              "      <td>0.751078</td>\n",
              "      <td>0.765613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>837</td>\n",
              "      <td>0.085700</td>\n",
              "      <td>0.843770</td>\n",
              "      <td>0.779456</td>\n",
              "      <td>0.760109</td>\n",
              "      <td>0.756935</td>\n",
              "      <td>0.764235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.066600</td>\n",
              "      <td>0.902826</td>\n",
              "      <td>0.783988</td>\n",
              "      <td>0.761811</td>\n",
              "      <td>0.761547</td>\n",
              "      <td>0.762079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results on the test set are: {'eval_loss': 0.3759879767894745, 'eval_accuracy': 0.8534883720930233, 'eval_f1': 0.8046511627906978, 'eval_precision': 0.8343283582089552, 'eval_recall': 0.7860215053763441, 'eval_runtime': 1.2215, 'eval_samples_per_second': 704.072, 'eval_steps_per_second': 5.731, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "custom_pretrained_layerwise_sparse_attention_results = train_and_evaluate(train_datasets_sparse_attention, dev_datasets_sparse_attention, test_datasets_sparse_attention, tokenizer, is_custom=True, full_attention_layers=[0,1,2,3], pretrained_model_name=\"Pramodith/bert-hybrid-sparse-sliding-window-attention\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "9i2o78YTH-yn"
      },
      "outputs": [],
      "source": [
        "save_results(\"custom_pretrained_layerwise_sparse_attention_results.pkl\", custom_pretrained_layerwise_sparse_attention_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3yQAwurrQ_X"
      },
      "source": [
        "## Performance Comparison\n",
        "Let's summarize our results by comparing the performances of all of our experiments. We'll focus on the means of accuracy and macro-f1 across experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1qpbx64rQ_Y"
      },
      "outputs": [],
      "source": [
        "def load_experiment_results(path: str) -> Dict:\n",
        "   \"\"\"\n",
        "   This function loads the results of an experiment from a pickle file.\n",
        "\n",
        "   args:\n",
        "      path (str): The path to the pickle file.\n",
        "   returns:\n",
        "      Dict: The results of the experiment.\n",
        "   \"\"\"\n",
        "   with open(path, 'rb') as f:\n",
        "      return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkdsQJMPrQ_Y"
      },
      "outputs": [],
      "source": [
        "dense_attention_results = load_experiment_results(\"results/dense_attention_results.pkl\")\n",
        "sparse_attention_results = load_experiment_results(\"results/sparse_attention_results.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMRt4zjyrQ_Y",
        "outputId": "1f827bdb-446a-4aa0-867d-2ac123484db9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {('dair-ai/emotion',\n",
              "              ''): [{'eval_loss': 0.13807015120983124,\n",
              "               'eval_accuracy': 0.936,\n",
              "               'eval_f1': 0.8918817242216576,\n",
              "               'eval_precision': 0.916948905143263,\n",
              "               'eval_recall': 0.882673481802767,\n",
              "               'eval_runtime': 1.5035,\n",
              "               'eval_samples_per_second': 1330.271,\n",
              "               'eval_steps_per_second': 10.642,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.1356077343225479,\n",
              "               'eval_accuracy': 0.9335,\n",
              "               'eval_f1': 0.8850426414566795,\n",
              "               'eval_precision': 0.8872851926238968,\n",
              "               'eval_recall': 0.8831655366743235,\n",
              "               'eval_runtime': 1.584,\n",
              "               'eval_samples_per_second': 1262.598,\n",
              "               'eval_steps_per_second': 10.101,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.14952251315116882,\n",
              "               'eval_accuracy': 0.9305,\n",
              "               'eval_f1': 0.8893978747451242,\n",
              "               'eval_precision': 0.8754485732155328,\n",
              "               'eval_recall': 0.906653211100224,\n",
              "               'eval_runtime': 1.5185,\n",
              "               'eval_samples_per_second': 1317.117,\n",
              "               'eval_steps_per_second': 10.537,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.14555521309375763,\n",
              "               'eval_accuracy': 0.932,\n",
              "               'eval_f1': 0.8889118020378873,\n",
              "               'eval_precision': 0.9059066315274792,\n",
              "               'eval_recall': 0.8765481553241065,\n",
              "               'eval_runtime': 1.5929,\n",
              "               'eval_samples_per_second': 1255.539,\n",
              "               'eval_steps_per_second': 10.044,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.14565882086753845,\n",
              "               'eval_accuracy': 0.9285,\n",
              "               'eval_f1': 0.8810087549397553,\n",
              "               'eval_precision': 0.8909614101580966,\n",
              "               'eval_recall': 0.8769330454558304,\n",
              "               'eval_runtime': 1.5626,\n",
              "               'eval_samples_per_second': 1279.884,\n",
              "               'eval_steps_per_second': 10.239,\n",
              "               'epoch': 5.0}],\n",
              "             ('ag_news',\n",
              "              ''): [{'eval_loss': 0.22670432925224304,\n",
              "               'eval_accuracy': 0.9277631578947368,\n",
              "               'eval_f1': 0.9279398677432116,\n",
              "               'eval_precision': 0.9285273319223295,\n",
              "               'eval_recall': 0.9277631578947368,\n",
              "               'eval_runtime': 10.5343,\n",
              "               'eval_samples_per_second': 721.451,\n",
              "               'eval_steps_per_second': 5.696,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.22469675540924072,\n",
              "               'eval_accuracy': 0.9282894736842106,\n",
              "               'eval_f1': 0.9284999411004765,\n",
              "               'eval_precision': 0.9295071454765513,\n",
              "               'eval_recall': 0.9282894736842104,\n",
              "               'eval_runtime': 10.4939,\n",
              "               'eval_samples_per_second': 724.233,\n",
              "               'eval_steps_per_second': 5.718,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.23604968190193176,\n",
              "               'eval_accuracy': 0.9286842105263158,\n",
              "               'eval_f1': 0.9287620489022419,\n",
              "               'eval_precision': 0.928946497637089,\n",
              "               'eval_recall': 0.9286842105263158,\n",
              "               'eval_runtime': 10.8631,\n",
              "               'eval_samples_per_second': 699.618,\n",
              "               'eval_steps_per_second': 5.523,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.22290992736816406,\n",
              "               'eval_accuracy': 0.925921052631579,\n",
              "               'eval_f1': 0.9258494859141256,\n",
              "               'eval_precision': 0.9267599826379374,\n",
              "               'eval_recall': 0.925921052631579,\n",
              "               'eval_runtime': 10.5795,\n",
              "               'eval_samples_per_second': 718.368,\n",
              "               'eval_steps_per_second': 5.671,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.21263617277145386,\n",
              "               'eval_accuracy': 0.9281578947368421,\n",
              "               'eval_f1': 0.928290325081341,\n",
              "               'eval_precision': 0.9287163023997925,\n",
              "               'eval_recall': 0.9281578947368421,\n",
              "               'eval_runtime': 10.7295,\n",
              "               'eval_samples_per_second': 708.324,\n",
              "               'eval_steps_per_second': 5.592,\n",
              "               'epoch': 5.0}],\n",
              "             ('tweet_eval',\n",
              "              'offensive'): [{'eval_loss': 0.38447633385658264,\n",
              "               'eval_accuracy': 0.8406976744186047,\n",
              "               'eval_f1': 0.7872666966392761,\n",
              "               'eval_precision': 0.8161986768544145,\n",
              "               'eval_recall': 0.769489247311828,\n",
              "               'eval_runtime': 0.8705,\n",
              "               'eval_samples_per_second': 987.96,\n",
              "               'eval_steps_per_second': 8.042,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.37019121646881104,\n",
              "               'eval_accuracy': 0.8534883720930233,\n",
              "               'eval_f1': 0.8015384615384615,\n",
              "               'eval_precision': 0.8399509803921569,\n",
              "               'eval_recall': 0.7796370967741936,\n",
              "               'eval_runtime': 0.924,\n",
              "               'eval_samples_per_second': 930.736,\n",
              "               'eval_steps_per_second': 7.576,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.3884630799293518,\n",
              "               'eval_accuracy': 0.8441860465116279,\n",
              "               'eval_f1': 0.7971855178773821,\n",
              "               'eval_precision': 0.8144205932127906,\n",
              "               'eval_recall': 0.7846774193548387,\n",
              "               'eval_runtime': 0.8889,\n",
              "               'eval_samples_per_second': 967.463,\n",
              "               'eval_steps_per_second': 7.875,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.3591267764568329,\n",
              "               'eval_accuracy': 0.8441860465116279,\n",
              "               'eval_f1': 0.8033232298408017,\n",
              "               'eval_precision': 0.8084749056184766,\n",
              "               'eval_recall': 0.7987231182795699,\n",
              "               'eval_runtime': 0.8854,\n",
              "               'eval_samples_per_second': 971.333,\n",
              "               'eval_steps_per_second': 7.906,\n",
              "               'epoch': 5.0}, {'eval_loss': 0.36777380108833313,\n",
              "               'eval_accuracy': 0.8395348837209302,\n",
              "               'eval_f1': 0.7728368973516779,\n",
              "               'eval_precision': 0.8362643022699681,\n",
              "               'eval_recall': 0.7456989247311827,\n",
              "               'eval_runtime': 0.8968,\n",
              "               'eval_samples_per_second': 958.956,\n",
              "               'eval_steps_per_second': 7.805,\n",
              "               'epoch': 5.0}]})"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_attention_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO8TDAtYrQ_Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def create_dataframe(results: Dict, expt_name: str) -> pd.DataFrame:\n",
        "   \"\"\"\n",
        "   This function creates a dataframe from the results of an experiment.\n",
        "\n",
        "   args:\n",
        "      results (Dict): The results of the experiment.\n",
        "   returns:\n",
        "      pd.DataFrame: The dataframe containing the results of the experiment.\n",
        "   \"\"\"\n",
        "   df = pd.DataFrame()\n",
        "   r = defaultdict(list)\n",
        "   for dataset_name, dataset_results in results.items():\n",
        "      dataset_name = dataset_name[0]\n",
        "      for i, run_results in enumerate(dataset_results):\n",
        "         for metric_name, metric_value in run_results.items():\n",
        "            r[\"Dataset\"].append(dataset_name)\n",
        "            r[\"Run\"].append(i)\n",
        "            r[\"Metric\"].append(metric_name)\n",
        "            r[\"Value\"].append(metric_value)\n",
        "            r[\"Experiment\"].append(expt_name)\n",
        "   df = pd.DataFrame.from_dict(r, orient=\"columns\")\n",
        "   return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUIO4T12rQ_Y",
        "outputId": "1532bfe9-9f51-4f9c-a319-87608db4d4fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Run</th>\n",
              "      <th>Metric</th>\n",
              "      <th>Value</th>\n",
              "      <th>Experiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dair-ai/emotion</td>\n",
              "      <td>0</td>\n",
              "      <td>eval_loss</td>\n",
              "      <td>0.138070</td>\n",
              "      <td>Dense Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dair-ai/emotion</td>\n",
              "      <td>0</td>\n",
              "      <td>eval_accuracy</td>\n",
              "      <td>0.936000</td>\n",
              "      <td>Dense Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dair-ai/emotion</td>\n",
              "      <td>0</td>\n",
              "      <td>eval_f1</td>\n",
              "      <td>0.891882</td>\n",
              "      <td>Dense Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dair-ai/emotion</td>\n",
              "      <td>0</td>\n",
              "      <td>eval_precision</td>\n",
              "      <td>0.916949</td>\n",
              "      <td>Dense Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dair-ai/emotion</td>\n",
              "      <td>0</td>\n",
              "      <td>eval_recall</td>\n",
              "      <td>0.882673</td>\n",
              "      <td>Dense Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>tweet_eval</td>\n",
              "      <td>4</td>\n",
              "      <td>eval_recall</td>\n",
              "      <td>0.731922</td>\n",
              "      <td>Sparse Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>tweet_eval</td>\n",
              "      <td>4</td>\n",
              "      <td>eval_runtime</td>\n",
              "      <td>1.055100</td>\n",
              "      <td>Sparse Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>tweet_eval</td>\n",
              "      <td>4</td>\n",
              "      <td>eval_samples_per_second</td>\n",
              "      <td>815.074000</td>\n",
              "      <td>Sparse Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>tweet_eval</td>\n",
              "      <td>4</td>\n",
              "      <td>eval_steps_per_second</td>\n",
              "      <td>6.634000</td>\n",
              "      <td>Sparse Attention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>tweet_eval</td>\n",
              "      <td>4</td>\n",
              "      <td>epoch</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>Sparse Attention</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>270 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Dataset  Run                   Metric       Value  \\\n",
              "0    dair-ai/emotion    0                eval_loss    0.138070   \n",
              "1    dair-ai/emotion    0            eval_accuracy    0.936000   \n",
              "2    dair-ai/emotion    0                  eval_f1    0.891882   \n",
              "3    dair-ai/emotion    0           eval_precision    0.916949   \n",
              "4    dair-ai/emotion    0              eval_recall    0.882673   \n",
              "..               ...  ...                      ...         ...   \n",
              "265       tweet_eval    4              eval_recall    0.731922   \n",
              "266       tweet_eval    4             eval_runtime    1.055100   \n",
              "267       tweet_eval    4  eval_samples_per_second  815.074000   \n",
              "268       tweet_eval    4    eval_steps_per_second    6.634000   \n",
              "269       tweet_eval    4                    epoch    5.000000   \n",
              "\n",
              "           Experiment  \n",
              "0     Dense Attention  \n",
              "1     Dense Attention  \n",
              "2     Dense Attention  \n",
              "3     Dense Attention  \n",
              "4     Dense Attention  \n",
              "..                ...  \n",
              "265  Sparse Attention  \n",
              "266  Sparse Attention  \n",
              "267  Sparse Attention  \n",
              "268  Sparse Attention  \n",
              "269  Sparse Attention  \n",
              "\n",
              "[270 rows x 5 columns]"
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense_attention_results_df = create_dataframe(dense_attention_results, \"Dense Attention\")\n",
        "sparse_attention_results_df = create_dataframe(sparse_attention_results, \"Sparse Attention\")\n",
        "all_results_df = pd.concat([dense_attention_results_df, sparse_attention_results_df], ignore_index=True)\n",
        "all_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFKk8gm7rQ_Y"
      },
      "outputs": [],
      "source": [
        "all_results_df = all_results_df[all_results_df[\"Metric\"].str.contains(\"f1|accuracy\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpAlT-KprQ_Z",
        "outputId": "265364c1-9cf7-4efa-b526-51a110765fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Dataset', 'Run', 'Metric', 'Value', 'Experiment'], dtype='object')"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_results_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdZm-89ErQ_Z",
        "outputId": "95ce7cd2-86e1-44e5-b04a-6fe97ae2c364"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Experiment</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Metric</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">Dense Attention</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">ag_news</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.927763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.927868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">dair-ai/emotion</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.932100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.887249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">tweet_eval</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.844419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.792430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">Sparse Attention</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">ag_news</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.924684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.924697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">dair-ai/emotion</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.922700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.877465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">tweet_eval</th>\n",
              "      <th>eval_accuracy</th>\n",
              "      <td>0.836977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1</th>\n",
              "      <td>0.783071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Value\n",
              "Experiment       Dataset         Metric                 \n",
              "Dense Attention  ag_news         eval_accuracy  0.927763\n",
              "                                 eval_f1        0.927868\n",
              "                 dair-ai/emotion eval_accuracy  0.932100\n",
              "                                 eval_f1        0.887249\n",
              "                 tweet_eval      eval_accuracy  0.844419\n",
              "                                 eval_f1        0.792430\n",
              "Sparse Attention ag_news         eval_accuracy  0.924684\n",
              "                                 eval_f1        0.924697\n",
              "                 dair-ai/emotion eval_accuracy  0.922700\n",
              "                                 eval_f1        0.877465\n",
              "                 tweet_eval      eval_accuracy  0.836977\n",
              "                                 eval_f1        0.783071"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_results_df[[\"Experiment\",\"Dataset\",\"Metric\",\"Value\"]].groupby([\"Experiment\",\"Dataset\", \"Metric\"]).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpvobw5crQ_Z"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_results(agg_df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    This function plots the results of an experiment.\n",
        "    args:\n",
        "        df (pd.DataFrame): The dataframe containing the results of the experiment.\n",
        "    \"\"\"\n",
        "    # Get unique datasets\n",
        "    datasets = agg_df['Dataset'].unique()\n",
        "\n",
        "    # Create a subplot for each dataset\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=len(datasets), figsize=(20, 7))\n",
        "\n",
        "    for i, dataset in enumerate(datasets):\n",
        "        df = agg_df[agg_df['Dataset'] == dataset]\n",
        "        bar_plot = sns.barplot(x='Metric', y='Value', hue='Experiment', data=df, ax=axs[i])\n",
        "        axs[i].set_title(f'Mean Values of Metrics for each Experiment on {dataset}')\n",
        "        axs[i].legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
        "\n",
        "        # Annotate the value of the metric on the bar\n",
        "        for p in bar_plot.patches:\n",
        "            bar_plot.annotate(format(p.get_height(), '.2f'),\n",
        "                            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                            ha = 'center', va = 'center',\n",
        "                            xytext = (0, 10),\n",
        "                            textcoords = 'offset points')\n",
        "    # Place the legend at the bottom\n",
        "\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZLNlWPQrQ_Z",
        "outputId": "2536ac4d-d4d3-4f02-ecec-770c1a098853"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x700 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "mean_df = all_results_df[[\"Experiment\",\"Dataset\",\"Metric\",\"Value\"]].groupby([\"Experiment\",\"Dataset\", \"Metric\"]).mean().reset_index()\n",
        "plot_results(mean_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4o1sJB6rQ_Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03a315af0e0d44e283a82b2f0c0b91c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e39fd615e1346678fffacaf312864a0",
            "placeholder": "​",
            "style": "IPY_MODEL_f8353bdfe5a24f029dd4d6dfbf7f711c",
            "value": " 7.33k/7.33k [00:00&lt;00:00, 598kB/s]"
          }
        },
        "0bb0d88c4b514c038542e4f31c178a85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e39fd615e1346678fffacaf312864a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12346b0c2ccb45e79109d97bf69a82b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c16c85030847ad95cd7196a3e565b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79c310abfe7443e99d7bde6060099f2f",
              "IPY_MODEL_8c7d79202e264969a0abff6b2ea4c2ef",
              "IPY_MODEL_cbfbbd42afb74f66b8e908972fbc6dc2"
            ],
            "layout": "IPY_MODEL_ab597e456de841a29f3b1ee212370619"
          }
        },
        "1dcd91e880ee4832b7962ee8688b6edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_797d2111640d41e2b0dcab1c04cd9fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_472cb9b31c994f3d880edcf82bd70302",
            "value": "Downloading builder script: 100%"
          }
        },
        "204eb9d928964480b0e80847d3b0101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb0d88c4b514c038542e4f31c178a85",
            "max": 7327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27b5d8fd955344f18e41eaaf39458f82",
            "value": 7327
          }
        },
        "22376d55f2b4421b952620da45595202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249a10b9a27743b6bf5c0a7044a6b594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9768ea891e9548b4abc8061e9a41642f",
            "placeholder": "​",
            "style": "IPY_MODEL_d86ea8a6c29641f9a239e74eb69363ef",
            "value": " 122400/122400 [00:01&lt;00:00, 116049.26 examples/s]"
          }
        },
        "27b5d8fd955344f18e41eaaf39458f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28608b35b72648c8b1ead99488ba2ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "290b5ee84a4140648401353fca759ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb72dc50c4848f2a80f606b46918d49",
            "placeholder": "​",
            "style": "IPY_MODEL_28608b35b72648c8b1ead99488ba2ec4",
            "value": "Generating train split: "
          }
        },
        "299df810851c4d619bc2a1cb38ee3e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423989c647084d4eb9a69efaec4c89ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b15388e9eb2041f4b419323cd824ccb5",
            "value": 1
          }
        },
        "38d431b89c3841d1a2be7490a1932578": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1c392f686d42099a5bbe37d8658796": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_738b23e7b2b34c3fbfdf405f82121359",
              "IPY_MODEL_204eb9d928964480b0e80847d3b0101e",
              "IPY_MODEL_03a315af0e0d44e283a82b2f0c0b91c6"
            ],
            "layout": "IPY_MODEL_b3291aa83cc8420cac97ffb86af6998a"
          }
        },
        "3e7162ca2a294c29ae4eedd8813e05a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775e34bb596540eb8fd9026d2ff9894b",
            "placeholder": "​",
            "style": "IPY_MODEL_60751a78708f4638bd3f1d584283059d",
            "value": "Saving the dataset (2/2 shards): 100%"
          }
        },
        "423989c647084d4eb9a69efaec4c89ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "472cb9b31c994f3d880edcf82bd70302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54421b8d09d14a27a39af103b50773c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5727c402c4584a25a51645ad3ace9b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e0d42f8b64d4d498f1872550fa03858": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_becc1894cb024917b7c5d3196192fea4",
            "max": 122400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5727c402c4584a25a51645ad3ace9b5a",
            "value": 122400
          }
        },
        "60751a78708f4638bd3f1d584283059d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6302fe29e429420eae12e8da744634f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64017558f71248ac8bfe0c5344b6ed1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66060f99364d4a9aa9b604211d81c6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_290b5ee84a4140648401353fca759ab7",
              "IPY_MODEL_299df810851c4d619bc2a1cb38ee3e46",
              "IPY_MODEL_6d2e15b49cb4435aaed4d51c281687af"
            ],
            "layout": "IPY_MODEL_6302fe29e429420eae12e8da744634f2"
          }
        },
        "686648128d9943c6a837bdc821bea265": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2e15b49cb4435aaed4d51c281687af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64017558f71248ac8bfe0c5344b6ed1a",
            "placeholder": "​",
            "style": "IPY_MODEL_89222b51d4734faea784262dbadec5a0",
            "value": " 136000/0 [00:53&lt;00:00, 2930.71 examples/s]"
          }
        },
        "738b23e7b2b34c3fbfdf405f82121359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22376d55f2b4421b952620da45595202",
            "placeholder": "​",
            "style": "IPY_MODEL_54421b8d09d14a27a39af103b50773c1",
            "value": "Downloading readme: 100%"
          }
        },
        "775e34bb596540eb8fd9026d2ff9894b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797d2111640d41e2b0dcab1c04cd9fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c310abfe7443e99d7bde6060099f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f853a28a6bdf4914bcc1169db0b49606",
            "placeholder": "​",
            "style": "IPY_MODEL_9a9cf10ed7384d01b4724efe5c640fc2",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "79cedae2143441ae95ec3f030a009dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686648128d9943c6a837bdc821bea265",
            "max": 2726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1306c6ba2f446fdb964aa45514c29ec",
            "value": 2726
          }
        },
        "7f7432ac557f44c6adb65f9921a55ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89222b51d4734faea784262dbadec5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c7d79202e264969a0abff6b2ea4c2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea53c31589b54f49b42dcd0f7e1d259f",
            "max": 13600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ead918248cbf43edbe030d55dc415748",
            "value": 13600
          }
        },
        "8f4e690c40d2409cbc2b9e1b9bc68197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dcd91e880ee4832b7962ee8688b6edf",
              "IPY_MODEL_79cedae2143441ae95ec3f030a009dcf",
              "IPY_MODEL_9e666b0c8d3c41cfa5dc6324e0dd1bc8"
            ],
            "layout": "IPY_MODEL_dda305cbe2c94d0d9ffa6f957625563e"
          }
        },
        "9768ea891e9548b4abc8061e9a41642f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9cf10ed7384d01b4724efe5c640fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e666b0c8d3c41cfa5dc6324e0dd1bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12346b0c2ccb45e79109d97bf69a82b0",
            "placeholder": "​",
            "style": "IPY_MODEL_7f7432ac557f44c6adb65f9921a55ba6",
            "value": " 2.73k/2.73k [00:00&lt;00:00, 231kB/s]"
          }
        },
        "a4641f214bb04f9d957265a3f55235b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9af72a1d5504a6b9f1aa6cbe76f0054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab597e456de841a29f3b1ee212370619": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae3d3c7833794226bbb2e954f211e99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7162ca2a294c29ae4eedd8813e05a0",
              "IPY_MODEL_5e0d42f8b64d4d498f1872550fa03858",
              "IPY_MODEL_249a10b9a27743b6bf5c0a7044a6b594"
            ],
            "layout": "IPY_MODEL_38d431b89c3841d1a2be7490a1932578"
          }
        },
        "b1306c6ba2f446fdb964aa45514c29ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b15388e9eb2041f4b419323cd824ccb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3291aa83cc8420cac97ffb86af6998a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "becc1894cb024917b7c5d3196192fea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfbbd42afb74f66b8e908972fbc6dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4641f214bb04f9d957265a3f55235b0",
            "placeholder": "​",
            "style": "IPY_MODEL_a9af72a1d5504a6b9f1aa6cbe76f0054",
            "value": " 13600/13600 [00:00&lt;00:00, 99262.99 examples/s]"
          }
        },
        "d86ea8a6c29641f9a239e74eb69363ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dda305cbe2c94d0d9ffa6f957625563e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea53c31589b54f49b42dcd0f7e1d259f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead918248cbf43edbe030d55dc415748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8353bdfe5a24f029dd4d6dfbf7f711c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f853a28a6bdf4914bcc1169db0b49606": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb72dc50c4848f2a80f606b46918d49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dca08e0018b4472b74aadf2a03c2316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6fc846b91644da2841abbc2f7ab5697",
              "IPY_MODEL_4d11f8588cbc48aab724d849f62efd68",
              "IPY_MODEL_454dfb4ef4ba4c509a6d0fcdde470563"
            ],
            "layout": "IPY_MODEL_217ff7b01794405cbafbc0639e34b752"
          }
        },
        "f6fc846b91644da2841abbc2f7ab5697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bd43b0a4b3424193d17e26eb75d15b",
            "placeholder": "​",
            "style": "IPY_MODEL_2d4b6e63f199465fbc50306e4d5fddca",
            "value": "config.json: 100%"
          }
        },
        "4d11f8588cbc48aab724d849f62efd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c68a992107c4df18c9fdd46cc7290eb",
            "max": 670,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46a3a226d31a436180eaad37668af43a",
            "value": 670
          }
        },
        "454dfb4ef4ba4c509a6d0fcdde470563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5724ec35fa943ef824a753bc3514f1c",
            "placeholder": "​",
            "style": "IPY_MODEL_752a4a178be04d3dbbea32c2f19470a6",
            "value": " 670/670 [00:00&lt;00:00, 62.8kB/s]"
          }
        },
        "217ff7b01794405cbafbc0639e34b752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bd43b0a4b3424193d17e26eb75d15b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4b6e63f199465fbc50306e4d5fddca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c68a992107c4df18c9fdd46cc7290eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a3a226d31a436180eaad37668af43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5724ec35fa943ef824a753bc3514f1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752a4a178be04d3dbbea32c2f19470a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89ff1ec5547f45c9be372b5dfa83e49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48602ebc959c4aa1bfdbdc6d98ae866f",
              "IPY_MODEL_1fdedcc94d4f4094b2434cb8ef5a44fa",
              "IPY_MODEL_d5c3509488a84c68894515bdbfeaaa5c"
            ],
            "layout": "IPY_MODEL_6efbd2b0c1974c33b9075bbe55b8e41a"
          }
        },
        "48602ebc959c4aa1bfdbdc6d98ae866f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db819d3a7364a1c95d22ca268086f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_76b46ad52b544b75aca5b433493d2c07",
            "value": "model.safetensors: 100%"
          }
        },
        "1fdedcc94d4f4094b2434cb8ef5a44fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59297c0fec6f44a5bc5e892d269c7c6a",
            "max": 440443456,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050b7f4b669041c5bcc8e55f2f7c84c4",
            "value": 440443456
          }
        },
        "d5c3509488a84c68894515bdbfeaaa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad23a0f1b1f44058bcc11fa28939f59",
            "placeholder": "​",
            "style": "IPY_MODEL_097486830644436b93c10ac181de332f",
            "value": " 440M/440M [00:09&lt;00:00, 36.7MB/s]"
          }
        },
        "6efbd2b0c1974c33b9075bbe55b8e41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db819d3a7364a1c95d22ca268086f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b46ad52b544b75aca5b433493d2c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59297c0fec6f44a5bc5e892d269c7c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050b7f4b669041c5bcc8e55f2f7c84c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ad23a0f1b1f44058bcc11fa28939f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097486830644436b93c10ac181de332f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}