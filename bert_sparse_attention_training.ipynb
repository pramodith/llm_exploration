{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pramodith/llm_exploration/blob/bert_sparse_attention_training/bert_sparse_attention_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploring the affects of custom Sparse Attention\n",
        "In our prior notebook, we found that both encoder-only and decoder-only models offload a significant portion of their attention scores to **sink tokens**. We identified that these sink tokens tend to be either special tokens like **[CLS], [SEP]** or tokens corresponding to **punctuations**. The consistence display of this phenomenon across model architectures and inputs makes one question the relevance of dense self-attention.\n",
        "\n",
        "In this notebook we'll explore the performance of BERT by creating custom attention masks, which will be sparse in nature. We'll create a unique mask per each token, where all tokens attend to special tokens and the k tokens in their neighborhood. When visualized the tokens along a diagonal of size 2*k+1 and the first anad last tokens (in the case of BERT) being attended to. We'll also explore the effects of allowing dense attention in some layers and sparse attention in the rest.\n",
        "\n",
        "We'll assess the downstream performance of the models that leverage this type of custom attention mask on some commonly used datasets for benchmarking like [TBD]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBBUafqnJPeP",
        "outputId": "7954a634-0dd3-4089-a8ee-8d6abc45d712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (4.27.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.8.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.10.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: datasets in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (2.14.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (2.28.2)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: packaging in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (14.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from datasets) (1.24.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: colorama in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: accelerate in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (0.25.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (0.4.0)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (2.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (1.24.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.10.0)\n",
            "Requirement already satisfied: requests in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub->accelerate) (2.28.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (1.2.2)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: overrides in c:\\users\\pramo\\anaconda3\\envs\\promptriddler\\lib\\site-packages (7.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets\n",
        "%pip install accelerate -U\n",
        "%pip install scikit-learn\n",
        "%pip install overrides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "53fY5yW9JNUS"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "from functools import partial\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset, load_metric, load_from_disk, Dataset, Metric\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "from transformers import BertModel, BertForSequenceClassification, BertForMaskedLM\n",
        "from transformers.data.data_collator import _torch_collate_batch\n",
        "from transformers.models.bert.modeling_bert import BertEncoder, logger\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions, BaseModelOutputWithPoolingAndCrossAttentions\n",
        "from transformers.modeling_utils import ModuleUtilsMixin, warnings\n",
        "from typing import Any, Dict, Optional, Tuple, Union, List, Mapping\n",
        "from overrides import overrides\n",
        "from torch import Tensor\n",
        "from torch.nn.functional import pad\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_MITsQuJNUU",
        "outputId": "d419abb2-ba4e-4b1a-cc55-ca4805112114"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Defining the model, tokenizer and dataset\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "sample_text = \"Every night I lie in bed.\"\n",
        "glue_classification_tasks = [\"sst2\", \"cola\"]\n",
        "glue_nli_tasks = [\"mnli\", \"qnli\", \"rte\", \"wnli\", \"ax\"]\n",
        "glue_semantic_similarity_tasks = [\"mrpc\", \"qqp\", \"stsb\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Dataset Splits and Metrics to Evaluate Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ihbuJxkbJNUV"
      },
      "outputs": [],
      "source": [
        "def get_dataset(glue_task_name: str) -> Tuple[Dataset, Dataset, Dataset, Metric]:\n",
        "    \"\"\"\n",
        "    This function loads the dataset and metric for the given task name. \n",
        "    It also splits the dataset into train, dev and test sets.\n",
        "\n",
        "    Args:\n",
        "        glue_task_name (str): The name of the task to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Dataset, Dataset, Dataset, Metric]: The train, dev and test datasets, and the metric for the given task.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the dataset and metric\n",
        "    dataset = load_dataset('glue', glue_task_name)\n",
        "    metric = load_metric('glue', glue_task_name)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_dataset = dataset['train']\n",
        "    dev_dataset = dataset['validation']\n",
        "    test_dataset = dataset['test']\n",
        "\n",
        "    # Print a description of the dataset\n",
        "    print(\"Dataset Description: \", train_dataset.description)\n",
        "\n",
        "    # Print the label space\n",
        "    print(\"Label Space: \", train_dataset.features[\"label\"].names)\n",
        "    return train_dataset, dev_dataset, test_dataset, metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT26JWyDJNUW",
        "outputId": "172769e3-fb9d-49a1-efdc-1a7f23f963b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Description:  GLUE, the General Language Understanding Evaluation benchmark\n",
            "(https://gluebenchmark.com/) is a collection of resources for training,\n",
            "evaluating, and analyzing natural language understanding systems.\n",
            "\n",
            "\n",
            "Label Space:  ['negative', 'positive']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['sentence', 'label', 'idx'],\n",
              "    num_rows: 67349\n",
              "})"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset, dev_dataset, test_dataset, metric = get_dataset('sst2')\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "D8BS7cfJ9UNx"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred: Tuple) -> Dict:\n",
        "    \"\"\"\n",
        "    This function computes the metrics for the given task and is used by the Trainer class for evaluation.\n",
        "    \"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.argmax(axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Custom Bert Model to support 4-D attention masks\n",
        "HF doesn't support custom layerwise attention masks. By default it assumes that all layers use the same attention mask. However,we want to be able to experiment with using sparse attention in all the layers but also a hybrid of dense and sparse self attention split across layers.\n",
        "\n",
        "In order to support this functionality we'll need to override some functions and create Custom Bert Models.\n",
        "\n",
        "First we'll override the `forward` function of `BertEncoder` to accept 5-d attention masks. The 5-d mask corresponds to (Layer, Batch Size, Attention Head, Sequence length (from token), Sequence length (to token)). We assume that all attention heads share the same attention mask in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jk-pBQF5UBlI"
      },
      "outputs": [],
      "source": [
        "class CustomBertEncoder(BertEncoder):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "    @overrides\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        output_hidden_states: Optional[bool] = False,\n",
        "        return_dict: Optional[bool] = True,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attentions = () if output_attentions else None\n",
        "        all_cross_attentions = () if output_attentions and self.config.add_cross_attention else None\n",
        "\n",
        "        if self.gradient_checkpointing and self.training:\n",
        "            if use_cache:\n",
        "                logger.warning_once(\n",
        "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                )\n",
        "                use_cache = False\n",
        "\n",
        "        attention_mask_is_layerwise = False\n",
        "        \n",
        "        # Code added here\n",
        "        if attention_mask.dim() == 5:\n",
        "            attention_mask_is_layerwise = True\n",
        "\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            # Code added here\n",
        "            if attention_mask_is_layerwise:\n",
        "               attention_mask_to_use = attention_mask[i]\n",
        "            else:\n",
        "                attention_mask_to_use = attention_mask\n",
        "\n",
        "            layer_head_mask = head_mask[i] if head_mask is not None else None\n",
        "            past_key_value = past_key_values[i] if past_key_values is not None else None\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "                layer_outputs = self._gradient_checkpointing_func(\n",
        "                    layer_module.__call__,\n",
        "                    hidden_states,\n",
        "                    attention_mask_to_use,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = layer_module(\n",
        "                    hidden_states,\n",
        "                    attention_mask_to_use,\n",
        "                    layer_head_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    past_key_value,\n",
        "                    output_attentions,\n",
        "                )\n",
        "\n",
        "            hidden_states = layer_outputs[0]\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[-1],)\n",
        "            if output_attentions:\n",
        "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
        "                if self.config.add_cross_attention:\n",
        "                    all_cross_attentions = all_cross_attentions + (layer_outputs[2],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [\n",
        "                    hidden_states,\n",
        "                    next_decoder_cache,\n",
        "                    all_hidden_states,\n",
        "                    all_self_attentions,\n",
        "                    all_cross_attentions,\n",
        "                ]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_decoder_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attentions,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we'll override `get_extended_attention_mask` of the `BertModel` class to create a new dimension expanding 4-d attention masks to 5-d attention masks. The expanded dimension corresponds to attention heads as mentioned above since we assume that all attention heads use the same mask we just need to add a new dimension to the mask tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomBertModel(BertModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.encoder = CustomBertEncoder(config)\n",
        "\n",
        "    @overrides\n",
        "    def get_extended_attention_mask(\n",
        "        self, attention_mask: Tensor, input_shape: Tuple[int], device: torch.device = None, dtype: torch.float = None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Makes broadcastable attention and causal masks so that future and masked tokens are ignored.\n",
        "\n",
        "        Arguments:\n",
        "            attention_mask (`torch.Tensor`):\n",
        "                Mask with ones indicating tokens to attend to, zeros for tokens to ignore.\n",
        "            input_shape (`Tuple[int]`):\n",
        "                The shape of the input to the model.\n",
        "\n",
        "        Returns:\n",
        "            `torch.Tensor` The extended attention mask, with a the same dtype as `attention_mask.dtype`.\n",
        "        \"\"\"\n",
        "        if dtype is None:\n",
        "            dtype = self.dtype\n",
        "\n",
        "        if not (attention_mask.dim() == 2 and self.config.is_decoder):\n",
        "            # show warning only if it won't be shown in `create_extended_attention_mask_for_decoder`\n",
        "            if device is not None:\n",
        "                warnings.warn(\n",
        "                    \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n",
        "                )\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        # Code added here\n",
        "        if attention_mask.dim() == 4:\n",
        "            extended_attention_mask = attention_mask[:, :, None, :, :]\n",
        "        elif attention_mask.dim() == 3:\n",
        "            extended_attention_mask = attention_mask[:, None, :, :]\n",
        "        elif attention_mask.dim() == 2:\n",
        "            # Provided a padding mask of dimensions [batch_size, seq_length]\n",
        "            # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
        "            # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "            if self.config.is_decoder:\n",
        "                extended_attention_mask = ModuleUtilsMixin.create_extended_attention_mask_for_decoder(\n",
        "                    input_shape, attention_mask, device\n",
        "                )\n",
        "            else:\n",
        "                extended_attention_mask = attention_mask[:, None, None, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Wrong shape for input_ids (shape {input_shape}) or attention_mask (shape {attention_mask.shape})\"\n",
        "            )\n",
        "\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\n",
        "        # positions we want to attend and the dtype's smallest value for masked positions.\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\n",
        "        # effectively the same as removing these entirely.\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=dtype)  # fp16 compatibility\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * torch.finfo(dtype).min\n",
        "        return extended_attention_mask\n",
        "    \n",
        "    \"\"\"\n",
        "    @overrides\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
        "        r\n",
        "        encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
        "            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
        "            the model is configured as a decoder.\n",
        "        encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
        "            the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
        "            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
        "\n",
        "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
        "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
        "            `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
        "        use_cache (`bool`, *optional*):\n",
        "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
        "            `past_key_values`).\n",
        "        \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if self.config.is_decoder:\n",
        "            use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        else:\n",
        "            use_cache = False\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            self.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        batch_size, seq_length = input_shape\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
        "\n",
        "        if token_type_ids is None:\n",
        "            if hasattr(self.embeddings, \"token_type_ids\"):\n",
        "                buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
        "                buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
        "                token_type_ids = buffered_token_type_ids_expanded\n",
        "            else:\n",
        "                token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
        "        # ourselves in which case we just need to make it broadcastable to all heads.\n",
        "        extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
        "\n",
        "        # If a 2D or 3D attention mask is provided for the cross-attention\n",
        "        # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
        "        if self.config.is_decoder and encoder_hidden_states is not None:\n",
        "            encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
        "            encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
        "            if encoder_attention_mask is None:\n",
        "                encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
        "            encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
        "        else:\n",
        "            encoder_extended_attention_mask = None\n",
        "\n",
        "        # Prepare head mask if needed\n",
        "        # 1.0 in head_mask indicate we keep the head\n",
        "        # attention_probs has shape bsz x n_heads x N x N\n",
        "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
        "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
        "        head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            position_ids=position_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            past_key_values_length=past_key_values_length,\n",
        "        )\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask=extended_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_extended_attention_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
        "\n",
        "        if not return_dict:\n",
        "            return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
        "\n",
        "        return BaseModelOutputWithPoolingAndCrossAttentions(\n",
        "            last_hidden_state=sequence_output,\n",
        "            pooler_output=pooled_output,\n",
        "            past_key_values=encoder_outputs.past_key_values,\n",
        "            hidden_states=encoder_outputs.hidden_states,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "            cross_attentions=encoder_outputs.cross_attentions,\n",
        "        )\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create a custom bert model for sequence classification that uses the custom bert encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = CustomBertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o6mABgKyVD-3"
      },
      "outputs": [],
      "source": [
        "def torch_mask_tokens(tokenizer: AutoTokenizer, mlm_probability: float, inputs: Any, special_tokens_mask: Optional[Any] = None) -> Tuple[Any, Any]:\n",
        "    \"\"\"\n",
        "    Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "\n",
        "    labels = inputs.clone()\n",
        "    # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    if special_tokens_mask is None:\n",
        "        special_tokens_mask = [\n",
        "            tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "        ]\n",
        "        special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
        "    else:\n",
        "        special_tokens_mask = special_tokens_mask.bool()\n",
        "\n",
        "    probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `custom_tokenize` function tokenizes a given text and creates a custom attention mask for the BERT model. \n",
        "\n",
        "The function takes four arguments: a tokenizer, a text string, a distance integer (default is 2), and a batch_mode boolean (default is False). \n",
        "\n",
        "The function tokenizes the text and creates an attention mask with ones on the main diagonal. It then updates the attention mask based on the specified neighborhood distance. The function ensures that the first and last tokens (usually the CLS and SEP tokens in BERT) always attend to all other tokens and are attended to by all other tokens. \n",
        "\n",
        "If `batch_mode` is `True`, the function adds an extra dimension to the attention mask, input ids, and token type ids to accommodate batch processing. \n",
        "\n",
        "The function returns a dictionary containing the tokenized input ids, token type ids, and the custom attention mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "qPhmj3Zy9UNy"
      },
      "outputs": [],
      "source": [
        "def custom_tokenize(tokenizer: AutoTokenizer, text: str, distance:int=2, batch_mode=False) -> Dict:\n",
        "    \"\"\"\n",
        "    This function tokenizes the given text and returns the tokenized inputs along with the attention mask.\n",
        "\n",
        "    Args:\n",
        "        tokenizer (AutoTokenizer): The tokenizer to be used for tokenization.\n",
        "        text (str): The text to be tokenized.\n",
        "        distance (int, optional): The number of neigbhoring tokens that should be attended to.\n",
        "        batch_mode (bool, optional): If we need to add an extra dimension for batch processing.\n",
        "\n",
        "    Returns:\n",
        "        Dict: The tokenized inputs along with the attention mask.\n",
        "    \"\"\"\n",
        "    # Tokenize the texts\n",
        "    result = tokenizer(text, truncation=True, padding=False)\n",
        "    # Create attention mask with ones on the main diagonal\n",
        "    attention_mask = torch.eye(len(result[\"input_ids\"]), dtype=torch.long)\n",
        "\n",
        "    # Update attention mask for the specified neighborhood distance\n",
        "    attention_mask[abs(torch.arange(len(attention_mask))[:, None] - torch.arange(len(attention_mask))) <= distance] = 1\n",
        "\n",
        "    # Set the first row to 1 corresponding to the CLS token\n",
        "    attention_mask[0, :] = 1\n",
        "    # Always attend to CLS\n",
        "    attention_mask[:, 0] = 1\n",
        "    # Set the last row to 1 corresponding to the SEP token\n",
        "    attention_mask[-1, :] = 1\n",
        "    # Always attend to SEP\n",
        "    attention_mask[:, -1] = 1\n",
        "    # Add the attention mask to the result\n",
        "\n",
        "    if batch_mode:\n",
        "      result[\"attention_mask\"] = torch.LongTensor(attention_mask.unsqueeze(0))\n",
        "      result[\"input_ids\"] = torch.LongTensor(result[\"input_ids\"]).unsqueeze(0)\n",
        "      result[\"token_type_ids\"] = torch.LongTensor(result[\"token_type_ids\"]).unsqueeze(0)\n",
        "    else:\n",
        "      result[\"attention_mask\"] = torch.LongTensor(attention_mask)\n",
        "      result[\"input_ids\"] = torch.LongTensor(result[\"input_ids\"])\n",
        "      result[\"token_type_ids\"] = torch.LongTensor(result[\"token_type_ids\"])\n",
        "    # Map the labels to the tokenized inputs\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make sure our implementation is right by visualizing a heatmap of our attention scores. We should expect to see a sliding window of attention along the diagonal while the **[CLS]** and **[SEP]** tokens are allowed to attend to all tokens and all tokens are allowed to attend to the **[CLS]** and **[SEP]** tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOdvYb8DdHZN",
        "outputId": "a6d88dd4-f724-445e-a8a7-7adeeaf46e3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "test_custom_model = CustomBertForSequenceClassification.from_pretrained(model_name)\n",
        "inputs = custom_tokenize(tokenizer, sample_text, distance=1, batch_mode=True)\n",
        "output = test_custom_model(**inputs, output_attentions=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the attention scores for Layer 0, Batch 0, Head 0\n",
        "attention_scores = output.attentions[0][0,0].detach().numpy()\n",
        "\n",
        "# Get the tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(attention_scores, cmap='hot', interpolation='nearest')\n",
        "plt.colorbar(label='Attention Scores')\n",
        "plt.title('Attention Scores Heatmap')\n",
        "plt.xticks(range(len(tokens)), tokens, rotation=90)\n",
        "plt.yticks(range(len(tokens)), tokens)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! That's working, now let's make sure that masking also works when we send in a 4-d tensor. Where dimension 0 is the layer number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs[\"attention_mask\"] = inputs[\"attention_mask\"].unsqueeze(0).repeat(12,1,1,1)\n",
        "output_layerwise_mask = test_custom_model(**inputs, output_attentions=True)\n",
        "assert torch.allclose(output.attentions[0], output_layerwise_mask.attentions[0]), \"Attention scores have to be the same for the same attention mask even if it is repeated layerwise\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Layerwise Attention Masks\n",
        "The `get_layerwise_attention_mask` function is designed to create a layer-wise attention mask from a given input attention mask. This function is particularly useful when working with transformer models like BERT, where different layers might require different attention masks.\n",
        "\n",
        "Here are the parameters of the function:\n",
        "\n",
        "- `attention_mask` (Tensor): This is the input attention mask that you want to convert into a layer-wise attention mask. It should be a tensor.\n",
        "\n",
        "- `pad_token_pos` (int): This is the position of the padding token in the attention mask. The function uses this to set the range of full attention.\n",
        "\n",
        "- `total_num_layers` (int, optional): This is the total number of layers in the model. By default, it's set to 12, which is the number of layers in BERT-base models.\n",
        "\n",
        "- `full_attention_layers` (list, optional): This is a list of layer numbers that should have full attention. By default, it's an empty list, meaning no layers have full attention.\n",
        "\n",
        "The function returns a tensor which is the layer-wise attention mask. If `full_attention_layers` is not empty, the function repeats the attention mask for each layer and sets full attention for the specified layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zFflnnXJu_7B"
      },
      "outputs": [],
      "source": [
        "def get_layerwise_attention_mask(attention_mask: Tensor, pad_token_pos:int, total_num_layers:int=12, full_attention_layers=[]):\n",
        "  \"\"\"\n",
        "  Returns a layer-wise attention mask for a given input attention mask.\n",
        "\n",
        "  Args:\n",
        "    attention_mask (Tensor): The input attention mask.\n",
        "    pad_token_pos (int): The position of the padding token in the attention mask.\n",
        "    total_num_layers (int, optional): The total number of layers in the model. Defaults to 12.\n",
        "    full_attention_layers (list, optional): A list of layer numbers that should have full attention. Defaults to [].\n",
        "\n",
        "  Returns:\n",
        "    Tensor: The layer-wise attention mask.\n",
        "  \"\"\"\n",
        "  attention_mask = attention_mask.unsqueeze(0)\n",
        "  if full_attention_layers:\n",
        "    attention_mask = attention_mask.repeat(total_num_layers, 1, 1, 1)\n",
        "    for layer_num in full_attention_layers:\n",
        "      attention_mask[layer_num, :, : pad_token_pos, : pad_token_pos] = 1\n",
        "  return attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make sure that this is working as desired.\n",
        "This test case is validating the `get_layerwise_attention_mask` function. It checks three things:\n",
        "\n",
        "1. The function returns an attention mask of the correct shape (12, 1, 4, 4).\n",
        "2. The attention mask at layer 0 is the same as the input mask (all zeros).\n",
        "3. The attention mask at layer 2 is all ones, indicating full attention. \n",
        "\n",
        "If any of these conditions are not met, the test case fails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "0M2fGF1nv4Lr"
      },
      "outputs": [],
      "source": [
        "dummy_attn_mask = torch.zeros(1, 4, 4)\n",
        "layerwise_attn_mask = get_layerwise_attention_mask(dummy_attn_mask, 4, full_attention_layers=[2])\n",
        "assert layerwise_attn_mask.shape == (12, 1, 4, 4), f\"{layerwise_attn_mask.shape} is the wrong shape\"\n",
        "assert torch.allclose(layerwise_attn_mask[0], dummy_attn_mask), \"Masks at layer 0 should all be 0s\"\n",
        "assert torch.allclose(layerwise_attn_mask[2], torch.ones(1,4,4)), \"Masks at layer 1 should all be 1s\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Padding custom attention Masks\n",
        "\n",
        "The `custom_collate` function is a utility function designed to process a batch of data for training a transformer model like BERT. It performs several key tasks:\n",
        "\n",
        "1. **Padding**: It pads all sequences in the batch to the same length, using the provided `pad_token_id`.\n",
        "\n",
        "2. **Layer-wise Attention Mask**: It creates a layer-wise attention mask for each sequence in the batch. This is useful when different layers of the transformer model require different attention masks.\n",
        "\n",
        "3. **Masked Language Modeling**: If the `is_mlm` flag is set to `True`, it applies masked language modeling to the input sequences. This involves randomly masking some of the tokens in each sequence, with the goal of predicting the original token from its context. The probability of masking a token is controlled by the `mlm_probability` parameter.\n",
        "\n",
        "The function returns a dictionary containing the padded 'input_ids', the layer-wise 'attention_mask', 'token_type_ids', and 'labels' (if present in the batch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Zh1P5ttKfwgy"
      },
      "outputs": [],
      "source": [
        "\n",
        "def custom_collate(batch:List, pad_token_id:int, full_attention_layers:List=[], mlm_probability:float=0.15, is_mlm:bool=False):\n",
        "  \"\"\"\n",
        "  Custom collate function for DataLoader that pads sequences and creates layer-wise attention masks.\n",
        "\n",
        "  Args:\n",
        "    batch (list): List of dictionaries containing 'input_ids', 'attention_mask', 'token_type_ids', and optionally 'label'.\n",
        "    pad_token_id (int): The ID of the padding token.\n",
        "    full_attention_layers (list, optional): List of layers that should have full attention. Defaults to [].\n",
        "    mlm_probability (float, optional): Probability of masking a token for masked language modeling. Defaults to 0.15.\n",
        "    is_mlm (bool, optional): Whether to apply masked language modeling. Defaults to False.\n",
        "\n",
        "  Returns:\n",
        "    dict: A dictionary containing 'input_ids', 'attention_mask', 'token_type_ids', and 'labels' (if present in batch).\n",
        "  \"\"\"\n",
        "  input_ids = [torch.LongTensor(batch[i][\"input_ids\"]) for i in range(len(batch))]\n",
        "  attention_mask = [torch.LongTensor(batch[i][\"attention_mask\"]) for i in range(len(batch))]\n",
        "  token_type_ids = [torch.LongTensor(batch[i][\"token_type_ids\"]) for i in range(len(batch))]\n",
        "  if \"label\" in batch[0]:\n",
        "    label = torch.LongTensor([batch[i][\"label\"] for i in range(len(batch))])\n",
        "  #idx = [batch[i][\"idx\"] for i in range(len(batch))]\n",
        "  max_len = max([len(inp) for inp in input_ids])\n",
        "  padding_sizes = [max_len - len(inp) for inp in input_ids]\n",
        "  input_ids = pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n",
        "  token_type_ids = pad_sequence(token_type_ids, batch_first=True)\n",
        "  attention_mask = [get_layerwise_attention_mask(pad(attention_mask[i], (0, padding_sizes[i], 0, padding_sizes[i]), value=0), padding_sizes[i], full_attention_layers=full_attention_layers).squeeze(1) for i in range(len(batch))]\n",
        "  attention_mask = torch.stack(attention_mask)\n",
        "  if full_attention_layers:\n",
        "    attention_mask = attention_mask.permute(1,0,2,3)\n",
        "  else:\n",
        "    attention_mask = attention_mask.squeeze(1)\n",
        "\n",
        "  if is_mlm:\n",
        "    input_ids, label = torch_mask_tokens(tokenizer, mlm_probability, input_ids)\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_mask,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"labels\": label,\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPjtSFNUVD-5",
        "outputId": "12f3c0fe-1bd7-439c-ff9c-832c7ef8dd94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  1,   2,   3,   4,   0],\n",
              "         [  1,   2,   3, 103,   5]]),\n",
              " 'attention_mask': tensor([[[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]],\n",
              " \n",
              " \n",
              "         [[[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [0, 0, 0, 0, 0]],\n",
              " \n",
              "          [[1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0],\n",
              "           [1, 1, 1, 0, 0]]]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0]]),\n",
              " 'labels': tensor([[-100, -100, -100, -100, -100],\n",
              "         [-100, -100, -100,    4, -100]])}"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "custom_collate([{\"input_ids\":[1,2,3,4], \"attention_mask\":[[1,1,1,0],[1,1,1,0],[1,1,1,0],[1,1,1,0]], \"token_type_ids\":[0,0,0,0], \"label\":1}, {\"input_ids\":[1,2,3,4,5], \"attention_mask\":[[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0],[1,1,1,0,0]], \"token_type_ids\":[0,0,0,0,0], \"label\":1}], tokenizer.pad_token_id, full_attention_layers=[2,4], is_mlm=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJgT4Rqmu_Xo",
        "outputId": "8aa8d4e7-dfde-4f29-aa5f-1d6404253cc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12, 8, 3, 3])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.zeros(8,12,3,3)\n",
        "a.permute(1,0,2,3).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to encode the datasets for dense and sparse attention differently since we need to create custom attention masks for the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gYSzPIq4JNUW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 67349/67349 [00:08<00:00, 7845.44 examples/s] \n",
            "Map: 100%|██████████| 872/872 [00:00<00:00, 8091.02 examples/s]\n",
            "Map: 100%|██████████| 1821/1821 [00:00<00:00, 12536.71 examples/s]\n",
            "Map: 100%|██████████| 67349/67349 [00:42<00:00, 1589.06 examples/s]\n",
            "Map: 100%|██████████| 872/872 [00:00<00:00, 1257.83 examples/s]\n",
            "Map: 100%|██████████| 1821/1821 [00:01<00:00, 1312.94 examples/s]\n"
          ]
        }
      ],
      "source": [
        "# Encode the datasets that'll leverage dense attention\n",
        "train_dataset_dense_attention = train_dataset.map(lambda example: tokenizer(example['sentence'], truncation=True, padding=False), batched=True)\n",
        "dev_dataset_dense_attention = dev_dataset.map(lambda example: tokenizer(example['sentence'], truncation=True, padding=False), batched=True)\n",
        "test_dataset_dense_attention = test_dataset.map(lambda example: tokenizer(example['sentence'], truncation=True, padding=False), batched=True)\n",
        "\n",
        "# Encode the datasets that'll leverage sparse attention\n",
        "train_dataset_sparse_attention = train_dataset.map(lambda example: custom_tokenize(tokenizer, example[\"sentence\"]), batched=False)\n",
        "dev_dataset_sparse_attention = dev_dataset.map(lambda example: custom_tokenize(tokenizer, example[\"sentence\"]), batched=False)\n",
        "test_dataset_sparse_attention = test_dataset.map(lambda example: custom_tokenize(tokenizer, example[\"sentence\"]), batched=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWLRRH6W9UNy",
        "outputId": "4071e774-289c-4130-d93c-b84a2553805d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentence': 'hide new secretions from the parental units ',\n",
              " 'label': 0,\n",
              " 'idx': 0,\n",
              " 'input_ids': [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
              "  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],\n",
              "  [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
              "  [1, 0, 1, 1, 1, 1, 1, 0, 0, 1],\n",
              "  [1, 0, 0, 1, 1, 1, 1, 1, 0, 1],\n",
              "  [1, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
              "  [1, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
              "  [1, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
              "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset_sparse_attention[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training the model with dense attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuAngW-DJNUW"
      },
      "outputs": [],
      "source": [
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,            # total number of training steps\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=128,   # batch size for evaluation\n",
        "    warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer_dense_attention = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset_dense_attention,         # training dataset\n",
        "    eval_dataset=dev_dataset_dense_attention,       # evaluation dataset\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer, padding=True),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4v4QFQumB6B-",
        "outputId": "31a4d454-6861-4dbb-827c-e77a87496b86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3159' max='3159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3159/3159 05:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.113900</td>\n",
              "      <td>0.280868</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.252700</td>\n",
              "      <td>0.227146</td>\n",
              "      <td>0.912844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.226600</td>\n",
              "      <td>0.238781</td>\n",
              "      <td>0.909404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.221600</td>\n",
              "      <td>0.237614</td>\n",
              "      <td>0.912844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.196600</td>\n",
              "      <td>0.262964</td>\n",
              "      <td>0.885321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.183700</td>\n",
              "      <td>0.217739</td>\n",
              "      <td>0.919725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.183600</td>\n",
              "      <td>0.220342</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.180900</td>\n",
              "      <td>0.201191</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.168900</td>\n",
              "      <td>0.210163</td>\n",
              "      <td>0.923165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.157400</td>\n",
              "      <td>0.214784</td>\n",
              "      <td>0.920872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.131200</td>\n",
              "      <td>0.237604</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.103800</td>\n",
              "      <td>0.217165</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.274903</td>\n",
              "      <td>0.902523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.096400</td>\n",
              "      <td>0.233629</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.095600</td>\n",
              "      <td>0.232268</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.101800</td>\n",
              "      <td>0.235343</td>\n",
              "      <td>0.911697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.100500</td>\n",
              "      <td>0.241394</td>\n",
              "      <td>0.920872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.096300</td>\n",
              "      <td>0.251834</td>\n",
              "      <td>0.912844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.102300</td>\n",
              "      <td>0.242711</td>\n",
              "      <td>0.923165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.105100</td>\n",
              "      <td>0.237493</td>\n",
              "      <td>0.919725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.092400</td>\n",
              "      <td>0.254775</td>\n",
              "      <td>0.915138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.050900</td>\n",
              "      <td>0.321398</td>\n",
              "      <td>0.920872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.057800</td>\n",
              "      <td>0.288199</td>\n",
              "      <td>0.925459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.257654</td>\n",
              "      <td>0.923165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>0.312160</td>\n",
              "      <td>0.917431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.050400</td>\n",
              "      <td>0.294499</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.054600</td>\n",
              "      <td>0.269495</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.050600</td>\n",
              "      <td>0.273313</td>\n",
              "      <td>0.925459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.059800</td>\n",
              "      <td>0.266174</td>\n",
              "      <td>0.926606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>0.266399</td>\n",
              "      <td>0.924312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.050700</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.932339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3159, training_loss=0.11348400654842598, metrics={'train_runtime': 315.8455, 'train_samples_per_second': 639.702, 'train_steps_per_second': 10.002, 'total_flos': 4633893920893020.0, 'train_loss': 0.11348400654842598, 'epoch': 3.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_dense_attention.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "p7kiaNeRV2Ze",
        "outputId": "8e6910ee-8fd8-4dc3-c26e-52c2fef90ec8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.21478354930877686,\n",
              " 'eval_accuracy': 0.9208715596330275,\n",
              " 'eval_runtime': 0.3051,\n",
              " 'eval_samples_per_second': 2858.042,\n",
              " 'eval_steps_per_second': 22.943,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_dense_attention.evaluate(dev_dataset_dense_attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Training the model with sparse attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "hjzZIuMS9UNz",
        "outputId": "efb4003d-1c22-43d7-c8a3-4d772ee92db4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='3159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 301/3159 01:02 < 10:02, 4.75 it/s, Epoch 0.28/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.670200</td>\n",
              "      <td>0.599721</td>\n",
              "      <td>0.693807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.455000</td>\n",
              "      <td>0.412350</td>\n",
              "      <td>0.815367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m      2\u001b[0m trainer_sparse_attention \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,                 \u001b[38;5;66;03m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     10\u001b[0m   )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer_sparse_attention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1914\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2263\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2261\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2263\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2266\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3012\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3009\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3011\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3012\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3191\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3189\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3190\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   3193\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   3194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:458\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 458\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[41], line 15\u001b[0m, in \u001b[0;36mcustom_collate\u001b[0;34m(batch, pad_token_id, full_attention_layers, mlm_probability, is_mlm)\u001b[0m\n\u001b[1;32m     13\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m pad_sequence(input_ids, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39mpad_token_id)\n\u001b[1;32m     14\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m pad_sequence(token_type_ids, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m [get_layerwise_attention_mask(pad(attention_mask[i], (\u001b[38;5;241m0\u001b[39m, padding_sizes[i], \u001b[38;5;241m0\u001b[39m, padding_sizes[i]), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), padding_sizes[i], full_attention_layers\u001b[38;5;241m=\u001b[39mfull_attention_layers)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch))]\n\u001b[1;32m     16\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(attention_mask)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_attention_layers:\n",
            "Cell \u001b[0;32mIn[41], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m pad_sequence(input_ids, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39mpad_token_id)\n\u001b[1;32m     14\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m pad_sequence(token_type_ids, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m [\u001b[43mget_layerwise_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_attention_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_attention_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch))]\n\u001b[1;32m     16\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(attention_mask)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_attention_layers:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer_sparse_attention = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset_sparse_attention,         # training dataset\n",
        "    eval_dataset=dev_dataset_sparse_attention,           # evaluation dataset\n",
        "    data_collator=partial(custom_collate, pad_token_id=tokenizer.pad_token_id),\n",
        "    compute_metrics=compute_metrics\n",
        "  )\n",
        "\n",
        "trainer_sparse_attention.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "0Maf7a4gD_pP",
        "outputId": "aa686cd7-20ad-42ac-d1d4-dd715abb8bea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='3159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 168/3159 00:17 < 05:09, 9.65 it/s, Epoch 0.16/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.131900</td>\n",
              "      <td>0.282347</td>\n",
              "      <td>0.893349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.131900</td>\n",
              "      <td>0.298096</td>\n",
              "      <td>0.889908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2980963885784149, 'eval_accuracy': 0.8899082568807339}"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_sparse_attention.evaluate(dev_dataset_sparse_attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a model with hybrid dense+sparse attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SritogvJ1-PL",
        "outputId": "bd40e0d3-cc45-40a2-f514-53dd8b1263f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing CustomBertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'training_args' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[63], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m test_custom_model \u001b[38;5;241m=\u001b[39m CustomBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      3\u001b[0m trainer_sparse_layerwise_attention \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mtest_custom_model,\n\u001b[0;32m      5\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,                 \u001b[38;5;66;03m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     args\u001b[38;5;241m=\u001b[39m\u001b[43mtraining_args\u001b[49m,                  \u001b[38;5;66;03m# training arguments, defined above\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset_sparse_attention,         \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mdev_dataset_sparse_attention,           \u001b[38;5;66;03m# evaluation dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mpartial(custom_collate, pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id, full_attention_layers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]),\n\u001b[0;32m     10\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[0;32m     11\u001b[0m   )\n\u001b[0;32m     13\u001b[0m trainer_sparse_layerwise_attention\u001b[38;5;241m.\u001b[39mtrain()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'training_args' is not defined"
          ]
        }
      ],
      "source": [
        "test_custom_model = CustomBertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "trainer_sparse_layerwise_attention = Trainer(\n",
        "    model=test_custom_model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset_sparse_attention,         # training dataset\n",
        "    eval_dataset=dev_dataset_sparse_attention,           # evaluation dataset\n",
        "    data_collator=partial(custom_collate, pad_token_id=tokenizer.pad_token_id, full_attention_layers=[0,1,2,3]),\n",
        "    compute_metrics=compute_metrics\n",
        "  )\n",
        "\n",
        "trainer_sparse_layerwise_attention.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "p7wWn6Bm5oTn",
        "outputId": "194ab694-01a9-462f-fa99-dfc075145870"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2847082018852234,\n",
              " 'eval_accuracy': 0.8990825688073395,\n",
              " 'eval_runtime': 0.8041,\n",
              " 'eval_samples_per_second': 1084.416,\n",
              " 'eval_steps_per_second': 8.705,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_sparse_layerwise_attention.evaluate(dev_dataset_sparse_attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_X10Kq0ddln"
      },
      "source": [
        "## BERT Pre-training with Sparse Attention\n",
        "\n",
        "Let's pre-train a Bert model with sparse attention to validate if pre-training with sparse attention gives a boost to finetuning when using the same strategy rather than solely finetuning with sparse attention.\n",
        "\n",
        "We'll use the **openwebtext** dataset for pre-training, the original model wasn't pre-trained on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Qpk9ss5CVD-8"
      },
      "outputs": [],
      "source": [
        "def get_pretraining_dataset(dataset_name):\n",
        "    ds = load_dataset(dataset_name, split='train', streaming=True)\n",
        "    return ds.take(136000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the dataset is too large to load into memory, we'll use the streaming API to load a subset of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIt2jspSXWIC"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from datasets import Dataset\n",
        "\n",
        "def gen_from_iterable_dataset(iterable_ds):\n",
        "    yield from iterable_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMr1yCxSVD-8"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = get_pretraining_dataset(\"Skylion007/openwebtext\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert an `IterableDataset` to `Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNfz66C-Xf78"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = Dataset.from_generator(partial(gen_from_iterable_dataset, pretraining_train_dataset), features=pretraining_train_dataset.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikDNn8zdK4qu"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = pretraining_train_dataset.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3hZW_PrLNMp"
      },
      "outputs": [],
      "source": [
        "pretraining_dev_dataset = pretraining_train_dataset[\"test\"]\n",
        "pretraining_train_dataset = pretraining_train_dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional: Save the dataset to memory for faster loading in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "D_sKiTa-35r7",
        "outputId": "8d132cbb-2225-446c-aab7-f0c099d077fc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ca1a8b7047ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretraining_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./datasets/pretraining_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpretraining_dev_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_to_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./datasets/pretraining_dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pretraining_train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "pretraining_train_dataset.save_to_disk(\"./datasets/pretraining_train\")\n",
        "pretraining_dev_dataset.save_to_disk(\"./datasets/pretraining_dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBcFcwwq35r7"
      },
      "outputs": [],
      "source": [
        "pretraining_train_dataset = load_from_disk(\"./datasets/pretraining_train\")\n",
        "pretraining_dev_dataset = load_from_disk(\"./datasets/pretraining_dev\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULTf7G4AVD-8",
        "outputId": "c64ece6e-3e40-40c5-8258-3fded0c3f1f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 122400\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretraining_train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qncBl_WqYUnJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# pretraining_train_dataset = pretraining_train_dataset.map(lambda example: custom_tokenize(tokenizer, example[\"text\"]), batched=False)\n",
        "# pretraining_dev_dataset = pretraining_dev_dataset.map(lambda example: custom_tokenize(tokenizer, example[\"text\"]), batched=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the dataset is large we don't want to vectorize all of it into memory as we did for our downstream tasks. We'll create a custom Pytorch Dataset that vectorizes only the required items of the batch into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MYwoZ1-u35r8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pretraining_train_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m {k:v\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n\u001b[1;32m---> 19\u001b[0m pretraining_train_torch_dataset \u001b[38;5;241m=\u001b[39m PretrainingDataset(\u001b[43mpretraining_train_dataset\u001b[49m, tokenizer)\n\u001b[0;32m     20\u001b[0m pretraining_dev_torch_dataset \u001b[38;5;241m=\u001b[39m PretrainingDataset(pretraining_dev_dataset, tokenizer)\n\u001b[0;32m     22\u001b[0m pretraining_train_torch_dense_dataset \u001b[38;5;241m=\u001b[39m PretrainingDataset(pretraining_train_dataset, tokenizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pretraining_train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "class PretrainingDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset, tokenizer, mode=\"sparse\"):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      if self.mode == \"sparse\":\n",
        "        return custom_tokenize(self.tokenizer, self.dataset[idx][\"text\"])\n",
        "      else:\n",
        "        inputs = tokenizer(self.dataset[idx][\"text\"], return_tensors=\"pt\", truncation=True)\n",
        "        inputs = {k:v.squeeze(0) for k,v in inputs.items()}\n",
        "        return inputs\n",
        "\n",
        "pretraining_train_torch_dataset = PretrainingDataset(pretraining_train_dataset, tokenizer)\n",
        "pretraining_dev_torch_dataset = PretrainingDataset(pretraining_dev_dataset, tokenizer)\n",
        "\n",
        "pretraining_train_torch_dense_dataset = PretrainingDataset(pretraining_train_dataset, tokenizer, mode=\"dense\")\n",
        "pretraining_dev_torch_dense_dataset = PretrainingDataset(pretraining_dev_dataset, tokenizer, mode=\"dense\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll continue pre-training the original Bert Model using a Masked Language Modeling head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69Tx1ud-YN3",
        "outputId": "bd4363e8-05c0-450b-856a-df876d92cf7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "mlm_model = BertForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Fh-iENBHqu",
        "outputId": "dd3d4241-995a-48cc-cee3-10f6472aed00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[101, 7592, 102]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.encode(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll train for 500 steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U27PvFr8VD-8"
      },
      "outputs": [],
      "source": [
        "pretraining_args = TrainingArguments(\n",
        "    output_dir='./bert-sparse-sliding-window-attention',          # output directory\n",
        "    max_steps=500,            # total number of training steps\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_ratio=0.1,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    fp16=True,\n",
        "    #torch_compile=True, # optimizations\n",
        "    #optim=\"adamw_torch_fused\", # improved optimizer\n",
        "    gradient_checkpointing=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_steps=200,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_steps=100,\n",
        "    eval_accumulation_steps=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "pretrainer_dense_attention = Trainer(\n",
        "    model=mlm_model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=pretraining_args,                  # training arguments, defined above\n",
        "    train_dataset=pretraining_train_torch_dense_dataset,         # training dataset\n",
        "    eval_dataset=pretraining_dev_torch_dense_dataset,           # evaluation dataset\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the loss of the original Bert Model on the dev dataset. Note that this is the model that uses **dense attention**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "h6mbUl615DE1",
        "outputId": "688a1c90-1349-4c13-c627-8a5613e4d4fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 01:46]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.7092370986938477,\n",
              " 'eval_runtime': 107.939,\n",
              " 'eval_samples_per_second': 125.997,\n",
              " 'eval_steps_per_second': 1.973}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrainer_dense_attention.evaluate(pretraining_dev_torch_dense_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiIjinOgx_QA",
        "outputId": "707cae59-5a3d-4c66-e1f6-ef208a61642d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now create a CustomBertModel that uses the CustomBertEncoder that we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht2Bp2RTWHrm"
      },
      "outputs": [],
      "source": [
        "class CustomBertForMaskedLM(BertForMaskedLM):\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.bert = CustomBertModel(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEt-_3hGWIF8"
      },
      "outputs": [],
      "source": [
        "custom_mlm_model = CustomBertForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWPfr2FxWXcO"
      },
      "outputs": [],
      "source": [
        "pretrainer_sparse_layerwise_attention = Trainer(\n",
        "    model=custom_mlm_model,\n",
        "    tokenizer=tokenizer,                 # the instantiated 🤗 Transformers model to be trained\n",
        "    args=pretraining_args,                  # training arguments, defined above\n",
        "    train_dataset=pretraining_train_torch_dataset,         # training dataset\n",
        "    eval_dataset=pretraining_dev_torch_dataset,           # evaluation dataset\n",
        "    data_collator = partial(custom_collate, pad_token_id=tokenizer.pad_token_id, is_mlm=True),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "HVv7X6fc2bFC",
        "outputId": "a0c1684f-bc3d-4931-99ad-e9ac2c11633b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 01:58]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity before training : {'eval_loss': 4.9193434715271, 'eval_runtime': 119.7049, 'eval_samples_per_second': 113.613, 'eval_steps_per_second': 1.779}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loss before training : {pretrainer_sparse_layerwise_attention.evaluate(pretraining_dev_torch_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "vLM-HsqzWwWb",
        "outputId": "661588cf-a583-410c-e6fa-cd4b2fed9382"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 31:48, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.634400</td>\n",
              "      <td>3.035876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.104800</td>\n",
              "      <td>2.889886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.012300</td>\n",
              "      <td>2.828573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.961000</td>\n",
              "      <td>2.797679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.939900</td>\n",
              "      <td>2.782165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='426' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 08:21]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=3.130488464355469, metrics={'train_runtime': 1911.784, 'train_samples_per_second': 33.477, 'train_steps_per_second': 0.262, 'total_flos': 1.6961223131136e+16, 'train_loss': 3.130488464355469, 'epoch': 0.52})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrainer_sparse_layerwise_attention.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "YTBwgQu2ElPH",
        "outputId": "140f7305-be70-4251-80d9-93836a87d2ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 01:59]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity after training : {'eval_loss': 2.8012802600860596, 'eval_runtime': 119.7757, 'eval_samples_per_second': 113.546, 'eval_steps_per_second': 1.778, 'epoch': 0.52}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Perplexity after training : {pretrainer_sparse_layerwise_attention.evaluate(pretraining_dev_torch_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRmhjfwJYL9q"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLVA67z9Z8UL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
