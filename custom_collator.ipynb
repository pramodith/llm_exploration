{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "from typing import List\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataCollatorForCompletionOnlyLM(DataCollatorForCompletionOnlyLM):\n",
    "    def __init__(self, response_template: str, tokenizer: AutoTokenizer, ignore_token_ids: List[int], ignore_tokens_mask_prob: float = 0.8):\n",
    "        \"\"\"\n",
    "        A custom data collator that masks tokens before the response template and \n",
    "        the ignore token ids after the response template. This is useful for classification tasks or tasks \n",
    "        where the LM predicts a fixed/small number of tokens after the response template.\n",
    "\n",
    "        Args:\n",
    "            response_template (str): A string that indicates the start of an AI generated response.\n",
    "            tokenizer (AutoTokenizer): The tokenizer used to tokenize the input text.\n",
    "            ignore_token_ids (List[int]): A list of token ids that can be ignored by the model while computing the loss.\n",
    "            ignore_tokens_mask_prob (float, optional): The probability with which an ignore token will be masked (i.e. loss is ignored). \n",
    "                Defaults to 0.8.\n",
    "        \"\"\"\n",
    "        super().__init__(tokenizer = tokenizer, response_template = response_template)\n",
    "        self.ignore_token_ids = torch.tensor(ignore_token_ids, torch.long)\n",
    "        self.ignore_tokens_mask_prob = ignore_tokens_mask_prob\n",
    "\n",
    "    def torch_call(self, examples: List[List[int]]):\n",
    "        batch = super().torch_call(examples)\n",
    "        # Create a mask with the same shape as the input_ids tensor and probability ignore_tokens_mask_prob\n",
    "        mask = torch.bernoulli(torch.full_like(batch['labels'], self.ignore_tokens_mask_prob)).bool()\n",
    "        # Find the positions of the ignore tokens in the labels tensor\n",
    "        ignore_token_positions = torch.isin(batch['labels'], self.ignore_token_ids)\n",
    "        # Set the labels of the ignore tokens to -100 (i.e. ignore them in the loss computation)\n",
    "        batch['labels'][mask & ignore_token_positions] = -100\n",
    "        return batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta/Llama-3-\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PromptRiddler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
